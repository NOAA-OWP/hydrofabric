---
title: "Realizations and Views"
description: |
  "Multi realization data products from minimal data layers"
author:
  - name: "Mike Johnson"
    url: https://github.com/mikejohnson51
    affiliation: Lynker, NOAA-Affiliate
    affiliation_url: https://lynker.com
  - name: "Justin Singh"
    url: https://github.com/program--
    affiliation: Lynker, NOAA-Affiliate
    affiliation_url: https://lynker.com
output:
  distill::distill_article:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(glue)
```

# TL;DR

- `realization` -> identification and concepts 
- `view` -> representation and operations 

# Intro

The [NextGen Hydrofabric Data Model](https://noaa-owp.github.io/hydrofabric/articles/04-data-model-deep-dive.html) aims to support a multi-realization
view of the river network and landscape using the concepts outlined in the [OGC HY Features Standard](https://docs.ogc.org/is/14-111r6/14-111r6.html).

The data model we are proposing, and enforcing, is aimed to allow flexible realizations with minimal data I/O. It does this by

  1. Defining a **principle realization**,
  2. Storing multiple layers of data in a self contained data format.
  3. Using opaque identifiers to reference realizations of the same hydrologic unit across layers
  
> **_NOTE:_**  All layers in the GPKG are realizations of the hydrologic landscape. Ultimetly there is one **principle realization** that defines the principle unit (e.g. flowpath) of the hydrologic landscape per the _model application_ being targeted. Moreover, one is a **viewed realization** - that is - the one that is being operated on. These do not have to be the same.concpets of 

The definition of a **view** - which is outside of the HY Features spec - is needed when applying concrete representations of the abstract conceptual features. Fundamentally, the way the world is digitally represented dictates the types of operations, inquires, and analysis that can be done and aligning the aims of these analysis, with a view of the abstract hydrologic feature, is critical for efficiency. 

## NextGen

The notion of a HY Feature ready hydrofabric requires the ability to access a number of realizations. This is distinct from the
[reference fabric](02-design-deep-dive.html) which is intended to support the creation of data products that serve a range of modeling applications.
In its current state, NextGen requires a few realizations for model execution. This currently includes, but is likely not limited to, the following:

| | Task | Realization | Attributes | Example |
| - | ---------- | ----------- | ---------- | ----- |
| 1 | Forcing Engine | Divide complex **with** geometry | `divide_id`, `geometry` | Rescale gridded data to units of divide complex | 
| 2 | Rainfall Runoff Modeling | Divide complex **without** geometry | `divide_id`, `id` | Linking divide units to draining flowpath | 
| 3 | Routing | Flowpath network  | `id`, `toid` | Moving water from channel to channel | 
| 14 | Reporting | Location on River network coincident with features like a gage | `toid` | What is the flow at USGS gage XXX |

Here, we will show that the hydrofabric data model supports ALL of these tasks through clear examples that include the derivation process. Further, we will show how the `divides` view is comprehensive enough to support each of these tasks.

## Background

1. NextGen uses a `flowpath` --> `nexus` topology. This is a requirement of aggregating the divide complex to the desired
   spatial scale while avoiding a `many:1` `flowline` to `divide` relation.
   
 >  **_NOTE:_** In possible upcoming work with GID and FIM, we may relax that constraint by building out a `flowline` layer that would allow a `many:1` relationship _and_ a higher resolution flowline network. Such a step might also allow for a `fp` --> `fp` topology that is more consistent with the core of [t-route](https://github.com/NOAA-OWP/t-route). Until that time, water flows from a flowpath to a nexus, and more then one flowpath may contribute to any one nexus.

2. The need to store many representations of the hydrologic landscape, both spatial and aspatial is a database challenge. In the spatial community,
   a well established way to store both spatial and aspatial data layers (or _tables_) in a single database is
   the [OGC GeoPackage Format]((https://www.geopackage.org/)). This format provides a standard for spatial information
   on top of SQLite databases.

3. While the hydrofabric identifiers are prefixed to make them human-readable, they should
   **not** be parsed within code to infer something more. The exception to this, is that it may be used to quickly identify the **principle realization**.

4. These are the R based libraries that will be used in this example. All of them have Python or other language equivalents.

```{r, message = FALSE}
library(sf)      # spatial data access and manipulation
library(mapview) # interactive map creation
library(arrow)   # parquet read/write
library(dplyr)   # SQL syntax on data.frames

#> Some (R -> Python) equivalents for these packages are:
#> - sf      -> geopandas/shapely/Fiona
#> - map view -> folio
#> - arrow   -> pyarrow
#> - dplyr   -> pandas/polar
```

## NextGen Principle Realization

Due to the routing requirements of NextGen (Task #3), the connectivity of the flowpath network is the _principle realization_ of the
landscape and thus the primary realization of our hydrologic units. It is because of this, that the flowpath identification is given the`id` identifier. Anywhere that `id` is found in the HF Geo Package, it is in reference to our **principle realization** - that of the flowpaths.

The flexibility of the HY Features standard, and our implemented data model make it possible to consider the hydrofabric from different perspectives, any one of these is the **viewed realization** when being operated on. A viewed realization is in essence an application based  abstraction over the principle realization. Selecting a viewed realization must consider the fundamental operations needed - not just the principle use case. 

In our example, the flowpath realization is the principle realization, however the need for divide geometries in the forcing (and likely rainfall runoff task) dictate a divide view of the product for our operations. The divide realization of flowpaths are uniquely identified by a `divide_id`. 

> **_NOTE:_** While all `id`s are unique. There ARE instances where a divide does not have a draining flowpath, thus those divides have a corresponding `id` property equal to `NA`. These can be removed using the `has_flowline` boolean flag property if desired, as they are NOT part of the dendritic system.

## Build a subset

To help with this example, we create a cutout of the Poudre River Basin using the hydrofabric subsetter found [here](https://github.com/LynkerIntel/hfsubset) to extract a sample of the [CONUS NextGen Hydrofabric](https://nextgen-hydrofabric.s3.amazonaws.com/index.html). This basin is defined as the upstream area of the NWIS location `Gages=06752260`. The USGS Next Generation Monitoring Location Page for this site is [here](https://waterdata.usgs.gov/monitoring-location/06752260/) and the Geoconnex PID can be found [here](https://reference.geoconnex.us/collections/gages/items?provider_id=06752260)

```bash
mkdir poudre
cd poudre

hfsubset -l divides,nexus,flowpaths, network,flowpath_attributes,hydrolocations \
         -o ./poudre-subset.gpkg \
         -r "pre-release" \
         -t hl \
         "Gages-06752260"
```

### Did we create it?

```{r}
(f = list.files("poudre", pattern = ".gpkg", full.names = TRUE))
```

### What's in it?

```{r}
st_layers(f)
```


### Let's map it! 

```{r, echo = FALSE}
knitr::include_graphics("../man/figures/hydrofabric.png")
```

# Defining the network

The exhaustive `realization` set (e.g identification and concepts) of a given network are contained in the `network` layer. This layer has _no_ spatial information and is the link between all flowpath, divide, and nexus realizations contained within an area.

```{r}
(net = read_sf(f, "network"))
```
Notably, this file carries the **full** reference fabric, through manipulation, through data modeling steps. Here we see the "hf_source" (or reference fabric) was the NHDPlusV2. 

The resulting `r nrow(net)` row table stores the needed information for `r length(unique(net$divide_id))` divides, `r length(unique(net$id))` flowpaths and `r length(unique(net$toid))` nexus 

If a walk back to the source hf is not needed, a reduced set can be extracted, for example:

```{r}
select(net, id, toid, divide_id, hl_uri, vpu, areasqkm) %>% 
  distinct()
```

# Forcing (Task 1)

To generate the forcing mesh (currently using EMSF) the forcing workstream needs the divide complex geometries and associated
`divide_id` of each unit. These can be pulled directly from the `divides` layer!

```{r}
read_sf(f, "divides") %>% 
  select(divide_id) %>% 
  filter(divide_id %in% net$divide_id)
```
# Rainfall Runoff Modeling (Task 2)

The NextGen rainfall runoff modeling tasks require the ability to identify a unit of the divide complex, and its associated draining flowpath. From this, configuration files can be used to assign and/or build model formulations associated with a given `divide_id`.

While NextGen remains a primarily lumped basin model, operating at the divide scale, the _divide_ view is the ideal _viewed realization_. However, since we are not explicitly interested in geometries here, we drop them. 

```{r}
read_sf(f, "divides") %>%
  select(divide_id, id) %>%
  st_drop_geometry()
```

> **_NOTE:_** Had we used SQLite directly to access this layer, rather than reading the complete layer with `sf`, we could have avoided reading the geometry column entirely.

```{r}
read_sf(f, query = "SELECT divide_id, id FROM divides")
```

## Working across model formulations

Once divides are located, and models assigned, there is often a need to populate the configuration file with some pre-computed information. One example of this is operating the [NOAH OWP Modular](https://github.com/NOAA-OWP/noah-owp-modular) and [CFE ](https://github.com/NOAA-OWP/cfe) models which require a suite of divide-summarized data. This data lives adjacent to the core hydrofabric GPKG's but can be accessed using a set of `divide_id`(s).

For example, let's say we want CFE and NOAH OWP data for `cat-280570`, we can use the naming convention of our files, the network based VPU distinction, and general parquet/s3 access patterns.

```{r}
base = 's3://nextgen-hydrofabric/pre-release'

open_dataset(glue("{base}/nextgen_{unique(net$vpu)}_cfe_noahowp.parquet")) %>%
  filter(divide_id == "cat-280570") %>%
  collect()
```

# Routing (Task 3)

Routing is based on the flowpath to nexus connection described in the background section and requires water to move from flowpaths, into nexuses, into flowpaths. More then one flowpath can contribute to a nexus, however only one nexus can contribute to a flowpath.

A hard requirement of `ngen` is that the network remains dendritic (e.g a [DAG](https://en.wikipedia.org/wiki/Directed_acyclic_graph)).
We can ensure  the resultant flowpath topology, extracted from the divides view, is compliant:

```{r}
library(igraph); library(visNetwork)

g = select(net, id, toid) %>%
    graph_from_data_frame(directed = TRUE) 

is.dag(g)

visIgraph(g)
```

Much like the NOAH-OWP/CFE example, knowing the connectivity of the flowpath network is half of the challenge. To successful route water through it, a range of attributes need to be supplied. Currently, these are provided within the `flowpath_attributes` layer of the hydrofabric data model:

```{r}
read_sf("poudre/poudre-subset.gpkg", "flowpath_attributes") %>%
  filter(id %in% unique(net$id))
```

The `id` can be used to extract the complete/partial _flowpath view_ if and when its needed:

```{r}
fp = read_sf(f, "flowpaths") %>% 
  filter(id == net$id[1]) 

div = read_sf(f, "divides") %>% 
  filter(divide_id == net$divide_id[1])

mapview(div) + fp
```

# Reporting (Task 4)

The last task is one that is NOT well facilitated by the existing NWM and that is how do you find the locations of known Points of Interest (POIs).

For example, lets say we wanted to find the USGS gages present in the Poudre Basin. To do this we could search the hydrolocations view for instances of type `Gages`.

```{r}
(gages = filter(net, grepl("Gages", hl_uri)))
```

In total there are `r length(unique(gages))` gages in the Poudre River basin. If we want to map these, and their contributing flowpaths and divides, we simply need to walk across layers:

```{r}
# Divides are indexed by divide_id
(div = read_sf(f, "divides") %>%
   filter(divide_id %in% gages$divide_id))

# flowpaths are indexed by id
(fps = read_sf(f, "flowpaths") %>%
   filter(id %in% gages$id))

# Nexus locations are indexed by toid
(hl = read_sf(f, "nexus") %>%
   filter(id %in% gages$toid))

mapview() + hl + div + fps
```

# Conclusion

While there are many layers presented with a hydrofabric, all views can extracted through a combination of the network layer, and or through the "viewed" layer itself. This supplies everything needed to run ngen from start to finish, and allow introspection of the results!

It is able to do this through a clear implementation of HY Features concepts, within a detailed yet flexible data model. Taking advantage of this requires an understanding that:

  (1) the principle view of our data set is the flowpath network due to the topology requirements of both ngen and t-route. This means that flowpaths and nexus locations are uniquely identified by `id`, and divides are uniquely identified by `divide_id`.
  (2) viewing the divide "view" of the data still provides the ability to access the flowpath and nexus realizations by their identifiers,
  (3) auxiliary data can be built in relation to the appropriate realization (e.g. id, or divide_id) providing the ability for a larger data system to scaffold.

