[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 Mike Johnson Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/01-intro-deep-dive.html","id":"what-is-a-hydrofabric","dir":"Articles","previous_headings":"","what":"What is a hydrofabric?","title":"Introduction","text":"first question generally raised , “hydrofabric?” date, term used describe artifacts narrow set cartographic lines, way entire spatial data architecture needed map model flow water flood extents. purposes , hydrofabric base data allows NextGen run. provides: landscape flow network discritizations connectivity (topology) network features locations information reported (nexus’s) divide flowpath attributes needed support hydrologic modeling routing hydrofabric also establishes system linked data Web infrastructure can relate , extract , linked sources like: USGS Next Generation Monitoring Location Pages (e.g. ) Internet Water Geoconnex PID registry (e.g. ) climate-catalogs (e.g. ) landscape characteristic catalogs","code":""},{"path":"/articles/01-intro-deep-dive.html","id":"who-cares-about-a-hydrofabric","dir":"Articles","previous_headings":"What is a hydrofabric?","what":"Who cares about a hydrofabric?","title":"Introduction","text":"Discritizing land surface computational elements fundamental modeling tasks. Without , distributed lumped models way apply needed model formulations computer science applications achieve meaningful results. Therefore anyone cares science application water resource modeling care underlying data drives locations forecasts made, attributes inform model, spatial elements formulation valid. However, describing earths surface - particularly continental scales - tricky task. Automated techniques can get us long way representation, however modeling task hand local knowledge used developing authoritative product. time, local knowledge collected number places, never centralized. , one products (like NHDPlus) used guide modeling task even cases resolution, representation well suited. aim NOAAs work space develop federal reference fabric support flavors modeling, national instance reference fabric support heterogeneous model application. Equally important software tools support flexibility community uptake; data models support interoperability, community engagement, long term stability; reference data set quality assurances one uses product getting well vetted resource able play nicely growing Ngen framework.","code":""},{"path":"/articles/01-intro-deep-dive.html","id":"current-version","dir":"Articles","previous_headings":"","what":"Current Version:","title":"Introduction","text":"date NextGen hydrofabric resources can accessed public facing Lynker Spatial account. practice strive develop products take advantage following:","code":""},{"path":[]},{"path":"/articles/01-intro-deep-dive.html","id":"formats","dir":"Articles","previous_headings":"Current Version: > Leading data science","what":"Formats:","title":"Introduction","text":"GPKG Arrow/Parquet Tables","code":""},{"path":"/articles/01-intro-deep-dive.html","id":"access-patterns","dir":"Articles","previous_headings":"Current Version: > Leading data science","what":"Access Patterns:","title":"Introduction","text":"GDAL VSI SQLITE Arrow","code":""},{"path":"/articles/01-intro-deep-dive.html","id":"distribution-system","dir":"Articles","previous_headings":"Current Version: > Leading data science","what":"Distribution System","title":"Introduction","text":"s3 (AWS)","code":""},{"path":"/articles/01-intro-deep-dive.html","id":"hydroscience-conceptual-models-web-infastrucutre","dir":"Articles","previous_headings":"Current Version:","what":"Hydroscience Conceptual Models & Web Infastrucutre","title":"Introduction","text":"hydrofabric features grounded OGC HY Feature conceptual model.  Mainstems logical model OGC Engineering Report “Hydrologic Modeling River Corridor Applications HY_Features Concepts” Network Linked Data Index (NLDI) , Geoconnex Registry lynker-spatial [hydrolocation inventory]","code":""},{"path":"/articles/01-intro-deep-dive.html","id":"formal-realization-representations","dir":"Articles","previous_headings":"Current Version:","what":"Formal Realization Representations","title":"Introduction","text":"HY Features conceptual model conflated Simple Feature Access Spatial Data model provide logical model feature realizations represented hydrofabric data model.","code":""},{"path":"/articles/01-intro-deep-dive.html","id":"software","dir":"Articles","previous_headings":"","what":"Software","title":"Introduction","text":"Extracting subsets primary hydrofabric data product require code, however, eager build, modify expand existing products Hydrofabric provides easy install variety hydroscience, data science, spatial libraries needed. Attaching library, similar tidyverse, installs loads set software designed manipulate, modify, describe, process, quantify hydrologic networks land surface attributes: library(hydrofabric) load core packages (alphabetical): climateR accessing federated data stores parameter attributes estimation hfsubsetR cloud-based hydrofabric subsetting hydrofab tool set “fabricating” multiscale hydrofabrics ngen.hydrofab NextGen extensions hydrofab nhdplusTools network manipulation zonal catchment parameter estimation Additionally load key geospatial data science libraries: dplyr (data.frames) sf (vector) terra (raster)","code":"remotes::install_github(\"NOAA-OWP/hydrofabric\") library(hydrofabric) ## ── Attaching packages ───────────────────────────────────── hydrofabric 0.1.0 ── ## ✔ dplyr         1.1.4      ✔ zonal         0.0.3  ## ✔ climateR      0.3.5      ✔ hfsubsetR     0.0.9  ## ✔ nhdplusTools  1.2.0      ✔ ngen.hydrofab 0.0.4  ## ✔ hydrofab      0.5.2      ✔ terra         1.7.78 ## ── Conflicts ──────────────────────────────────────── hydrofabric_conflicts() ── ## ✖ terra::plot() masks climateR::plot() ##  ## Attaching package: 'hydrofabric' ## The following objects are masked _by_ 'package:hydrofab': ##  ##     append_style, hf_dm"},{"path":"/articles/01_intro-deep-dive.html","id":"what-is-a-hydrofabric","dir":"Articles","previous_headings":"","what":"What is a hydrofabric?","title":"NOAA's Enterprise Hydrofabric System","text":"first question generally raised , “”hydrofabric”?” date, term used describe artifacts narrow set cartographic lines, way entire spatial data architecture needed map model flow water flood extents. hydrofabric foundation base data allows NextGen run provides landscape flow network discritizations provides connectivity (topology) network features defines locations information reported (nexus’s) hydrofabric also establishes system linked data Web infrastructure Systems like USGS Next Generation Monitoring Location Pages (e.g. ) Internet Water Geoconnex PID registry (e.g. ) climate-catalogs (e.g. )  date hydrofabric data can accessed ","code":""},{"path":"/articles/01_intro-deep-dive.html","id":"who-cares-about-a-hydrofabric","dir":"Articles","previous_headings":"What is a hydrofabric?","what":"Who cares about a hydrofabric?","title":"NOAA's Enterprise Hydrofabric System","text":"Discritizing land surface computational elements fundamental modeling tasks. Without , distributed lumped models way apply needed model formulations computer science applications achieve meaningful results. Therefore anyone cares science application water resource modeling care underlying data drives locations forecasts made, attributes inform model, spatial elements formulation valid. However, describing earths surface - particularly continental scales - tricky task. Automated techniques can get us long way representation, however modeling task hand local knowledge used developing authoritative product. time, local knowledge collected number places, never centralized. , one products (like NHDPlus) used guide modeling task even cases resolution, representation well suited. aim NOAAs work space develop federal reference fabric support flavors modeling, national instance reference fabric support heterogeneous model application. Equally important software tools support flexibility community uptake; data models support interoperability, community engagement, long term stability; reference data set quality assurances one uses product getting well vetted resource able play nicely growing Ngen framework.","code":""},{"path":[]},{"path":[]},{"path":"/articles/01_intro-deep-dive.html","id":"formats","dir":"Articles","previous_headings":"Built Using… > Leading data science","what":"Formats:","title":"NOAA's Enterprise Hydrofabric System","text":"GPKG Arrow/Parquet Tables","code":""},{"path":"/articles/01_intro-deep-dive.html","id":"access-patterns","dir":"Articles","previous_headings":"Built Using… > Leading data science","what":"Access Patterns:","title":"NOAA's Enterprise Hydrofabric System","text":"GDAL VSI SQLITE Arrow","code":""},{"path":"/articles/01_intro-deep-dive.html","id":"distribution-system","dir":"Articles","previous_headings":"Built Using… > Leading data science","what":"Distribution System","title":"NOAA's Enterprise Hydrofabric System","text":"s3 (AWS) ScienceBase","code":""},{"path":"/articles/01_intro-deep-dive.html","id":"hydroscience-conceptual-models","dir":"Articles","previous_headings":"Built Using…","what":"Hydroscience Conceptual Models","title":"NOAA's Enterprise Hydrofabric System","text":"hydrofabric features grounded OGC HY Feature conceptual model.","code":""},{"path":"/articles/01_intro-deep-dive.html","id":"formal-realization-representations","dir":"Articles","previous_headings":"Built Using…","what":"Formal Realization Representations","title":"NOAA's Enterprise Hydrofabric System","text":"conceptual model laid HY Features conflated Simple Feature Access Spatial Data model provide logical model feature realizations represented hydrofabric data model.","code":""},{"path":"/articles/01_intro-deep-dive.html","id":"whats-to-follow","dir":"Articles","previous_headings":"","what":"What’s to follow:","title":"NOAA's Enterprise Hydrofabric System","text":"basic software package working products design make system two primary processes processes network manipulation - refactoring aggregating fundamental data model used hydrofabrics extract subsets data needs (time permitting) access build landscape characteristics workshop illustrate toolset working established reference fabric create Ngen ready data products. following steps walk concepts tools building Ngen ready dataset, outputs look like, might interact . Attaching library, similar tidyverse, installs loads canon software designed manipulate, modify, describe, process, quantify hydrologic networks land surface attributes: includes following:","code":"remotes::install_github(\"NOAA-OWP/hydrofabric\") library(hydrofabric) ## ── Attaching packages ────────────────────────────────────── hydrofabric0.0.6 ── ## ✔ dplyr         1.1.2      ✔ nhdplusTools  0.6.2  ## ✔ terra         1.7.21     ✔ hydrofab      0.5.0  ## ✔ ngen.hydrofab 0.0.3      ✔ zonal         0.0.2  ## ✔ climateR      0.3.0      ✔ glue          1.6.2 ## ── Conflicts ──────────────────────────────────────── hydrofabric_conflicts() ── ## ✖ terra::intersect() masks dplyr::intersect() ## ✖ glue::trim()       masks terra::trim() ## ✖ terra::union()     masks dplyr::union() ##  ## Attaching package: 'hydrofabric' ## The following object is masked _by_ 'package:hydrofab': ##  ##     subset_network"},{"path":"/articles/01_intro-deep-dive.html","id":"todays-context","dir":"Articles","previous_headings":"","what":"Today’s Context","title":"NOAA's Enterprise Hydrofabric System","text":"Everyone asked come USGS Gage ID mind. example, use NWIS gage=06752260. sits Cache La Poudre River FORT COLLINS, CO USGS Next Generation Monitoring Location Page : https://waterdata.usgs.gov/monitoring-location/06752260/ Geoconnex PID can found : https://reference.geoconnex.us/collections/gages/items?provider_id=06752260","code":"xx = dataRetrieval::findNLDI(nwis = '06752260', find = c(\"flowlines\", \"basin\"), nav = \"UM\", distance_km = 1000)  mapview(xx)"},{"path":"/articles/02-design-deep-dive.html","id":"how-do-we-arrive-at-the-nextgen-hydrofabric","dir":"Articles","previous_headings":"","what":"How do we arrive at the NextGen Hydrofabric?","title":"The Reference Fabric","text":"NextGen model engine intended model agnostic. hydrofabric meant Model Application Agnostic. means hydrofabric able support modeling needs applications like: NOAA NextGen (infinite flavors); USGS NHM; USGS SPARROW model; eventually NOAA FIM.","code":""},{"path":"/articles/02-design-deep-dive.html","id":"the-usgs-noaa-reference-fabric","dir":"Articles","previous_headings":"","what":"The USGS-NOAA Reference Fabric","title":"The Reference Fabric","text":"single system serve many - often distinct - modeling applications, needs set reference (analogous coordinate reference system (CRS)) reference system must provide maximum (e.g. smallest discretization) set features “allowable” interrelated model applications. Right now, NHDPlusV2 (modifications) future move NHDHighRes 3DHP practice, reference fabrics can built hydrographies (e.g. NGA TDX MERIT) reference fabric key providing persistent identification (PID) durable data integration model interoperability development product collaborative venture USGS Water Mission Area, NOAA Office Water Prediction, Lynker.  documented ","code":""},{"path":[]},{"path":"/articles/02-design-deep-dive.html","id":"reference-fabric","dir":"Articles","previous_headings":"The USGS-NOAA Reference Fabric > The 3 pillars of a Reference Fabric","what":"1. Reference Fabric","title":"The Reference Fabric","text":"Simple, valid, representations flowpath divide features Must derived source hydrographic dataset (e.g. NHDPlusV2, Dihydro) Currently, built NHDPlusV2 features Waterbodies simplified, islands dissolved, unioned GNIS_ID.  Catchments simplified, DEM fragments dissolved proper adjoining catchments.  Flowpaths ensured digitized upstream downstream burn line events substituted NHDFlowlines headwater catchments data products can foundhere","code":""},{"path":"/articles/02-design-deep-dive.html","id":"reference-topology","dir":"Articles","previous_headings":"The USGS-NOAA Reference Fabric > The 3 pillars of a Reference Fabric","what":"2. Reference Topology","title":"The Reference Fabric","text":"Since release, NHDPlus topology value added attributes stable Local groups agencies made modifications never made back primary source Improvements made USGS, OWP, NCAR others integrated provide updated network connectivity. data product can found described upcoming article “Generating reference flow network improved connectivity support durable data integration reproducibility coterminous US” {press EMS}","code":""},{"path":[]},{"path":"/articles/02-design-deep-dive.html","id":"corrected-divergence-priorities","dir":"Articles","previous_headings":"The USGS-NOAA Reference Fabric > The 3 pillars of a Reference Fabric > 2. Reference Topology","what":"Corrected divergence priorities","title":"The Reference Fabric","text":"Ultimately changed network shown areas total drainage area 10% different original NHDPlusV2 Network.","code":""},{"path":"/articles/02-design-deep-dive.html","id":"community-points-of-interest-poi","dir":"Articles","previous_headings":"The USGS-NOAA Reference Fabric > The 3 pillars of a Reference Fabric","what":"3. Community Points of Interest (POI)","title":"The Reference Fabric","text":"Points Interest (POIs) hydrologic modeling collected variety published data sources. include ones like Army Corp National Inventory Dams USGS Gages III gage database POIs become hydrolocations outflow linked flowpath robust hydrologic indexing scheme. NOTE: locations deemed high general interest. guarantee gages, dams, thermoelectric plants community set.","code":""},{"path":"/articles/02-design-deep-dive.html","id":"what-is-a-vpu","dir":"Articles","previous_headings":"","what":"What is a VPU?","title":"The Reference Fabric","text":"VPU Vector Processing Unit. USGS determined regions designing NHDPlusV2. Since work builds NHDPlusV2, adopt processing units.  hydrographic networks VPU-esque discritizations. key source hydrofabric discritization can retained manipulation process. show tiling drainage basin approaches MERIT-hydro, BasinMaker, NGA’s TDX-hydro. caption","code":"## Warning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not ## give correct results for longitude/latitude data"},{"path":"/articles/02-design-deep-dive.html","id":"getting-the-reference-fabric","dir":"Articles","previous_headings":"","what":"Getting the reference fabric","title":"The Reference Fabric","text":"reference products live Lynker Spatial s3 account. can accessed web interface, downloaded, interfaced arrow. hydrofab::get_hydrofabric() utility download current geofabric Vector Processing Unit (VPU). example, lets use Geonconnex reference features identify location Fort Collins gage. location can joined set VPU boundaries severed nhdplusTools find correct VPU. requested file already exists, file path returned. Ok! , idea reference fabric , made, can get ! next stage learn manipulate reference fabric unique model applications.","code":"(gage = open_dataset('s3://lynker-spatial/hydrofabric/v2.2/conus_hl') |>    select(\"vpuid\", 'hl_reference', \"hl_link\") %>%    filter(hl_link == '06752260') %>%    collect()) ## # A tibble: 2 × 3 ##   vpuid hl_reference   hl_link  ##   <chr> <chr>          <chr>    ## 1 10L   Gages          06752260 ## 2 10L   usgs_site_code 06752260 reference_gpkg = get_vpu_fabric(vpu = gage$vpuid[1],                                 outfile = glue(\"tutorial/vpu_{gage$vpuid[1]}.gpkg\")) ## Warning in get_vpu_fabric(vpu = gage$vpuid[1], outfile = ## glue(\"tutorial/vpu_{gage$vpuid[1]}.gpkg\")): tutorial/vpu_10L.gpkg already ## exists and overwrite is FALSE"},{"path":"/articles/02-design.html","id":"how-do-we-arrive-at-the-nextgen-hydrofabric","dir":"Articles","previous_headings":"","what":"How do we arrive at the NextGen Hydrofabric?","title":"NOAA's Enterprise Hydrofabric System","text":"NextGen model engine intended model agnostic. hydrofabric meant Model Application Agnostic. means hydrofabric able support modeling needs applications like: NOAA NextGen (infinite flavors); USGS NHM; USGS SPPARROW model; eventually NOAA FIM.","code":""},{"path":"/articles/02-design.html","id":"the-usgs-noaa-reference-fabric","dir":"Articles","previous_headings":"","what":"The USGS-NOAA Reference Fabric","title":"NOAA's Enterprise Hydrofabric System","text":"single system serve many - often distinct - modeling applications, needs set reference system. (analogous coordinate reference system (CRS)) reference system must provide maximum (e.g. smallest discretization) set features “allowable” interrelated model applications. Right now, NHDPlusV2 (modifications) future move NHDHighRes 3DHP practice, reference fabrics can built hydrographies (e.g. NGA TDX MERIT) refernence fabric key providing persistent identification (PID) durable data integration model interoprobility development product collaborative venture USGS Water Mission Area, NOAA Office Water Prediction, Lynker.  documented ","code":""},{"path":"/articles/02-design.html","id":"the-3-pillars-of-a-reference-fabric","dir":"Articles","previous_headings":"The USGS-NOAA Reference Fabric","what":"The 3 pillars of a Reference Fabric","title":"NOAA's Enterprise Hydrofabric System","text":"https://www.sciencebase.gov/catalog/item/60be0e53d34e86b93891012b","code":""},{"path":"/articles/02-design.html","id":"reference-features","dir":"Articles","previous_headings":"The USGS-NOAA Reference Fabric","what":"1. Reference Features","title":"NOAA's Enterprise Hydrofabric System","text":"Simple, valid, representations flowpath divide features Must derived source hydrographic dataset (e.g. NHDPLus, ) Currently, built NHDPlusV2 features Waterbodies simplified, islands dissolved, unioned GNIS_ID. Flowlines ensured digitized upsteam downstream Catchments simplifed, DEM fragments dissolved proper adjoing catchments. data products can found ","code":""},{"path":"/articles/02-design.html","id":"reference-topology","dir":"Articles","previous_headings":"The USGS-NOAA Reference Fabric","what":"2. Reference Topology","title":"NOAA's Enterprise Hydrofabric System","text":"Since first release, NHDPlus topology value added attributes stable Local groups agencies made modifications never made back primary source Improvements made USGS, OWP, NCAR integrated provide updated network connectivity. data products can found    “Generating reference flow network improved connectivity support durable data integration reproducibility coterminous US” {press}","code":""},{"path":"/articles/02-design.html","id":"reference-pois","dir":"Articles","previous_headings":"The USGS-NOAA Reference Fabric","what":"3. Reference POIs","title":"NOAA's Enterprise Hydrofabric System","text":"Collected variety published data sources POIs become hydrolocations outflow linked flowpath.","code":"## Driver: GPKG  ## Available layers: ##             layer_name geometry_type features fields             crs_name ## 1 refactored_flowpaths   Line String    41117      7 NAD83 / Conus Albers ## 2   refactored_divides Multi Polygon    41115      4 NAD83 / Conus Albers ## 3        split_divides Multi Polygon      569      2 NAD83 / Conus Albers ## 4          mapped_POIs         Point     3496     22 NAD83 / Conus Albers ## 5         lookup_table            NA    65370      4                 <NA> ## 6    catchment_network            NA    41117      5                 <NA>"},{"path":"/articles/02-design.html","id":"what-is-a-vpu","dir":"Articles","previous_headings":"","what":"What is a VPU?","title":"NOAA's Enterprise Hydrofabric System","text":"VPU Vector Processing Unit. USGS determined regions designing NHDPlusV2. Since work builds NHDPlusV2, adopt processing units.","code":"ggplot(data = vpu_boundaries[1:21,]) +    geom_sf(data = vpu_boundaries[1:21,]) +    geom_sf_label(aes(label = VPUID)) +    theme_void() ## Warning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not ## give correct results for longitude/latitude data"},{"path":"/articles/02-design.html","id":"getting-the-reference-fabric","dir":"Articles","previous_headings":"","what":"Getting the reference fabric","title":"NOAA's Enterprise Hydrofabric System","text":"reference products live ScienceBase. can accessed web interface can downloaded programatically. hydrofab::get_hydrofabric() utility download current geofabric Vector Processing Unit (VPU). requested file already exists, file path returned. example, lets use Geonconnex reference featrues identify location Fort Collins, CO gage. locations can joined set VPU boundaries severed nhdplusTools find correct VPU. can download reference fabric VPU=10L assigned base directory, explore layers contained within:","code":"gage = read_sf('https://reference.geoconnex.us/collections/gages/items?provider_id=06752260')  gage = st_join(gage, st_transform(vpu_boundaries, st_crs(gage)))  (gage$VPUID) ## [1] \"10L\" base <- \"tmp-data\" dir.create(base) ## Warning in dir.create(base): 'tmp-data' already exists reference_gpkg = get_hydrofabric(VPU = \"01\",                                   type = \"refactor\",                                  dir = base,                                  overwrite = TRUE) ##    |                                                                               |                                                                      |   0%   |                                                                               |                                                                      |   1%   |                                                                               |=                                                                     |   1%   |                                                                               |=                                                                     |   2%   |                                                                               |==                                                                    |   2%   |                                                                               |==                                                                    |   3%   |                                                                               |==                                                                    |   4%   |                                                                               |===                                                                   |   4%   |                                                                               |===                                                                   |   5%   |                                                                               |====                                                                  |   5%   |                                                                               |====                                                                  |   6%   |                                                                               |=====                                                                 |   6%   |                                                                               |=====                                                                 |   7%   |                                                                               |=====                                                                 |   8%   |                                                                               |======                                                                |   8%   |                                                                               |======                                                                |   9%   |                                                                               |=======                                                               |   9%   |                                                                               |=======                                                               |  10%   |                                                                               |=======                                                               |  11%   |                                                                               |========                                                              |  11%   |                                                                               |========                                                              |  12%   |                                                                               |=========                                                             |  12%   |                                                                               |=========                                                             |  13%   |                                                                               |=========                                                             |  14%   |                                                                               |==========                                                            |  14%   |                                                                               |==========                                                            |  15%   |                                                                               |===========                                                           |  15%   |                                                                               |===========                                                           |  16%   |                                                                               |============                                                          |  16%   |                                                                               |============                                                          |  17%   |                                                                               |============                                                          |  18%   |                                                                               |=============                                                         |  18%   |                                                                               |=============                                                         |  19%   |                                                                               |==============                                                        |  19%   |                                                                               |==============                                                        |  20%   |                                                                               |==============                                                        |  21%   |                                                                               |===============                                                       |  21%   |                                                                               |===============                                                       |  22%   |                                                                               |================                                                      |  22%   |                                                                               |================                                                      |  23%   |                                                                               |================                                                      |  24%   |                                                                               |=================                                                     |  24%   |                                                                               |=================                                                     |  25%   |                                                                               |==================                                                    |  25%   |                                                                               |==================                                                    |  26%   |                                                                               |===================                                                   |  26%   |                                                                               |===================                                                   |  27%   |                                                                               |===================                                                   |  28%   |                                                                               |====================                                                  |  28%   |                                                                               |====================                                                  |  29%   |                                                                               |=====================                                                 |  29%   |                                                                               |=====================                                                 |  30%   |                                                                               |=====================                                                 |  31%   |                                                                               |======================                                                |  31%   |                                                                               |======================                                                |  32%   |                                                                               |=======================                                               |  32%   |                                                                               |=======================                                               |  33%   |                                                                               |=======================                                               |  34%   |                                                                               |========================                                              |  34%   |                                                                               |========================                                              |  35%   |                                                                               |=========================                                             |  35%   |                                                                               |=========================                                             |  36%   |                                                                               |==========================                                            |  36%   |                                                                               |==========================                                            |  37%   |                                                                               |==========================                                            |  38%   |                                                                               |===========================                                           |  38%   |                                                                               |===========================                                           |  39%   |                                                                               |============================                                          |  39%   |                                                                               |============================                                          |  40%   |                                                                               |============================                                          |  41%   |                                                                               |=============================                                         |  41%   |                                                                               |=============================                                         |  42%   |                                                                               |==============================                                        |  42%   |                                                                               |==============================                                        |  43%   |                                                                               |==============================                                        |  44%   |                                                                               |===============================                                       |  44%   |                                                                               |===============================                                       |  45%   |                                                                               |================================                                      |  45%   |                                                                               |================================                                      |  46%   |                                                                               |=================================                                     |  46%   |                                                                               |=================================                                     |  47%   |                                                                               |=================================                                     |  48%   |                                                                               |==================================                                    |  48%   |                                                                               |==================================                                    |  49%   |                                                                               |===================================                                   |  49%   |                                                                               |===================================                                   |  50%   |                                                                               |===================================                                   |  51%   |                                                                               |====================================                                  |  51%   |                                                                               |====================================                                  |  52%   |                                                                               |=====================================                                 |  52%   |                                                                               |=====================================                                 |  53%   |                                                                               |=====================================                                 |  54%   |                                                                               |======================================                                |  54%   |                                                                               |======================================                                |  55%   |                                                                               |=======================================                               |  55%   |                                                                               |=======================================                               |  56%   |                                                                               |========================================                              |  56%   |                                                                               |========================================                              |  57%   |                                                                               |========================================                              |  58%   |                                                                               |=========================================                             |  58%   |                                                                               |=========================================                             |  59%   |                                                                               |==========================================                            |  59%   |                                                                               |==========================================                            |  60%   |                                                                               |==========================================                            |  61%   |                                                                               |===========================================                           |  61%   |                                                                               |===========================================                           |  62%   |                                                                               |============================================                          |  62%   |                                                                               |============================================                          |  63%   |                                                                               |============================================                          |  64%   |                                                                               |=============================================                         |  64%   |                                                                               |=============================================                         |  65%   |                                                                               |==============================================                        |  65%   |                                                                               |==============================================                        |  66%   |                                                                               |===============================================                       |  66%   |                                                                               |===============================================                       |  67%   |                                                                               |===============================================                       |  68%   |                                                                               |================================================                      |  68%   |                                                                               |================================================                      |  69%   |                                                                               |=================================================                     |  69%   |                                                                               |=================================================                     |  70%   |                                                                               |=================================================                     |  71%   |                                                                               |==================================================                    |  71%   |                                                                               |==================================================                    |  72%   |                                                                               |===================================================                   |  72%   |                                                                               |===================================================                   |  73%   |                                                                               |===================================================                   |  74%   |                                                                               |====================================================                  |  74%   |                                                                               |====================================================                  |  75%   |                                                                               |=====================================================                 |  75%   |                                                                               |=====================================================                 |  76%   |                                                                               |======================================================                |  76%   |                                                                               |======================================================                |  77%   |                                                                               |======================================================                |  78%   |                                                                               |=======================================================               |  78%   |                                                                               |=======================================================               |  79%   |                                                                               |========================================================              |  79%   |                                                                               |========================================================              |  80%   |                                                                               |========================================================              |  81%   |                                                                               |=========================================================             |  81%   |                                                                               |=========================================================             |  82%   |                                                                               |==========================================================            |  82%   |                                                                               |==========================================================            |  83%   |                                                                               |==========================================================            |  84%   |                                                                               |===========================================================           |  84%   |                                                                               |===========================================================           |  85%   |                                                                               |============================================================          |  85%   |                                                                               |============================================================          |  86%   |                                                                               |=============================================================         |  86%   |                                                                               |=============================================================         |  87%   |                                                                               |=============================================================         |  88%   |                                                                               |==============================================================        |  88%   |                                                                               |==============================================================        |  89%   |                                                                               |===============================================================       |  89%   |                                                                               |===============================================================       |  90%   |                                                                               |===============================================================       |  91%   |                                                                               |================================================================      |  91%   |                                                                               |================================================================      |  92%   |                                                                               |=================================================================     |  92%   |                                                                               |=================================================================     |  93%   |                                                                               |=================================================================     |  94%   |                                                                               |==================================================================    |  94%   |                                                                               |==================================================================    |  95%   |                                                                               |===================================================================   |  95%   |                                                                               |===================================================================   |  96%   |                                                                               |====================================================================  |  96%   |                                                                               |====================================================================  |  97%   |                                                                               |====================================================================  |  98%   |                                                                               |===================================================================== |  98%   |                                                                               |===================================================================== |  99%   |                                                                               |======================================================================|  99%   |                                                                               |======================================================================| 100%"},{"path":"/articles/02-design.html","id":"working-with-the-geopackages","dir":"Articles","previous_headings":"","what":"Working with the Geopackages","title":"NOAA's Enterprise Hydrofabric System","text":"geopackage critical file format sharing type data (1) self containing (2) compact (3) language agnostic. two broad paths accessing data. first GDAL based approach (R using sf, python Fiona geopandas works well). second SQLite database (R, RSQLite/DBI/dplyr):","code":"# Read Options pacman::p_load(sf, DBI, RSQLite, dplyr)  ### 1. GDAL/geopackage st_layers(reference_gpkg) ## Driver: GPKG  ## Available layers: ##             layer_name geometry_type features fields             crs_name ## 1 refactored_flowpaths   Line String    41117      7 NAD83 / Conus Albers ## 2   refactored_divides Multi Polygon    41115      4 NAD83 / Conus Albers ## 3        split_divides Multi Polygon      569      2 NAD83 / Conus Albers ## 4          mapped_POIs         Point     3496     22 NAD83 / Conus Albers ## 5         lookup_table            NA    65370      4                 <NA> ## 6    catchment_network            NA    41117      5                 <NA> nex = read_sf(reference_gpkg, \"mapped_POIs\") head(nex) ## Simple feature collection with 6 features and 22 fields ## Geometry type: POINT ## Dimension:     XY ## Bounding box:  xmin: 2009569 ymin: 2883035 xmax: 2029956 ymax: 2967498 ## Projected CRS: NAD83 / Conus Albers ## # A tibble: 6 × 23 ##         ID    toID set   identifier COMID Type_HUC12 Type_Gages Type_TE Type_NID ##      <dbl>   <dbl> <chr>      <int> <chr> <chr>      <chr>      <chr>   <chr>    ## 1 10000000  1.00e7 1004…          1 7170… 010100020… NA         NA      NA       ## 2 10000011  1.00e7 1000…          2 7179… 010100020… NA         NA      NA       ## 3 10000043  1.00e7 1000…          3 7189… 010100020… NA         NA      NA       ## 4 10000053  1.00e7 1000…          4 7184… 010100020… NA         NA      NA       ## 5 10000070  1.00e7 1000…          5 7200… 010100020… NA         NA      NA       ## 6 10000079  1.00e7 1000…          6 7200… 010100020… NA         NA      NA       ## # ℹ 14 more variables: Type_WBIn <chr>, Type_WBOut <chr>, Type_Conf <chr>, ## #   Type_Term <chr>, Type_Elev <chr>, Type_Travel <chr>, nexus <chr>, ## #   snapped <lgl>, TotDASqKM <dbl>, DnHydroseq <int>, type <chr>, ## #   member_COMID <chr>, Type_Con <dbl>, geom <POINT [m]> ### 2. SQLite/Database db <- dbConnect(SQLite(), reference_gpkg) dbListTables(db) ##  [1] \"catchment_network\"                      ##  [2] \"gpkg_contents\"                          ##  [3] \"gpkg_extensions\"                        ##  [4] \"gpkg_geometry_columns\"                  ##  [5] \"gpkg_ogr_contents\"                      ##  [6] \"gpkg_spatial_ref_sys\"                   ##  [7] \"gpkg_tile_matrix\"                       ##  [8] \"gpkg_tile_matrix_set\"                   ##  [9] \"lookup_table\"                           ## [10] \"mapped_POIs\"                            ## [11] \"refactored_divides\"                     ## [12] \"refactored_flowpaths\"                   ## [13] \"rtree_mapped_POIs_geom\"                 ## [14] \"rtree_mapped_POIs_geom_node\"            ## [15] \"rtree_mapped_POIs_geom_parent\"          ## [16] \"rtree_mapped_POIs_geom_rowid\"           ## [17] \"rtree_refactored_divides_geom\"          ## [18] \"rtree_refactored_divides_geom_node\"     ## [19] \"rtree_refactored_divides_geom_parent\"   ## [20] \"rtree_refactored_divides_geom_rowid\"    ## [21] \"rtree_refactored_flowpaths_geom\"        ## [22] \"rtree_refactored_flowpaths_geom_node\"   ## [23] \"rtree_refactored_flowpaths_geom_parent\" ## [24] \"rtree_refactored_flowpaths_geom_rowid\"  ## [25] \"rtree_split_divides_geom\"               ## [26] \"rtree_split_divides_geom_node\"          ## [27] \"rtree_split_divides_geom_parent\"        ## [28] \"rtree_split_divides_geom_rowid\"         ## [29] \"split_divides\"                          ## [30] \"sqlite_sequence\" fpa = collect(tbl(db, \"mapped_POIs\"))  head(fpa) ## # A tibble: 6 × 24 ##     fid       geom       ID    toID set   identifier COMID Type_HUC12 Type_Gages ##   <int>     <blob>    <dbl>   <dbl> <chr>      <int> <chr> <chr>      <chr>      ## 1     1 <raw 29 B> 10000000  1.00e7 1004…          1 7170… 010100020… NA         ## 2     2 <raw 29 B> 10000011  1.00e7 1000…          2 7179… 010100020… NA         ## 3     3 <raw 29 B> 10000043  1.00e7 1000…          3 7189… 010100020… NA         ## 4     4 <raw 29 B> 10000053  1.00e7 1000…          4 7184… 010100020… NA         ## 5     5 <raw 29 B> 10000070  1.00e7 1000…          5 7200… 010100020… NA         ## 6     6 <raw 29 B> 10000079  1.00e7 1000…          6 7200… 010100020… NA         ## # ℹ 15 more variables: Type_TE <chr>, Type_NID <chr>, Type_WBIn <chr>, ## #   Type_WBOut <chr>, Type_Conf <chr>, Type_Term <chr>, Type_Elev <chr>, ## #   Type_Travel <chr>, nexus <chr>, snapped <int>, TotDASqKM <dbl>, ## #   DnHydroseq <int>, type <chr>, member_COMID <chr>, Type_Con <dbl> dbDisconnect(db)"},{"path":[]},{"path":"/articles/03-processing-deep-dive.html","id":"getting-the-reference-fabric","dir":"Articles","previous_headings":"","what":"Getting the reference fabric","title":"Network Manipulation","text":"reference (precomputed) refactored data products live ScienceBase. can accessed web interface can downloaded programatically. hydrofab::get_hydrofabric() utility download current geofabric Vector Processing Unit (VPU). Options include downloading “refactored” (default) “reference” data. requested file already exists, file path returned.","code":""},{"path":"/articles/03-processing-deep-dive.html","id":"example","dir":"Articles","previous_headings":"Getting the reference fabric","what":"Example","title":"Network Manipulation","text":"Define terminal location interest Subset upstream reference fabric using hydrofab::subset_reference","code":"library(hydrofabric) using_local_example = \"/Users/mjohnson/hydrofabric\"  # Define starting feature by source and ID (gage = list(featureSource = \"nwis\", featureID = \"06752260\"))  # Use subset_network to build a reference subset hf = hfsubsetR::get_subset(nldi_feature = gage,                             source  = using_local_example,                             outfile = \"tutorial/poudre.gpkg\",                            overwrite = FALSE) d = read_hydrofabric(\"tutorial/poudre.gpkg\")  pois = open_dataset(glue(\"{using_local_example}/v2.2/conus_hl\")) %>%    filter(hf_id %in% d$flowpaths$id, hl_source == 'GFv20') %>%    collect() %>%    st_as_sf(coords = c(\"X\", \"Y\"), crs = 5070)"},{"path":[]},{"path":"/articles/03-processing-deep-dive.html","id":"concept","dir":"Articles","previous_headings":"1) Running the Process: Refactoring","what":"Concept","title":"Network Manipulation","text":"Refactoring geoprocessing workflow seeks Split large long catchments uniform catchment size distribution collapse catchment topology eliminate small catchments key network resolution lost! means total path length network going , comes . workflow can parameterized using three primary values: might also areas want avoid, , enforce splitting event. can defined following values: POI definition selection model application specific. , ignore aspect. information network, refactor can refactor flowpath network. order reconcile catchment network,set flow accumulation (FAC) flow direction (FDR) grids must provided. reference fabric (e.g. NHDPlusV2), supply national VRT can accessed : s3://nextgen-hydrofabric/DEM-products/{product}.vrt (gridded products) can found ","code":""},{"path":"/articles/03-processing-deep-dive.html","id":"example-1","dir":"Articles","previous_headings":"1) Running the Process: Refactoring","what":"Example","title":"Network Manipulation","text":"","code":"refactored = refactor(hf,                       split_flines_meters = 10000,                        collapse_flines_meters = 1000,                        collapse_flines_main_meters = 1000,                       pois = pois,                       fac = '/vsis3/lynker-spatial/gridded-resources/fac.vrt',                       fdr = '/vsis3/lynker-spatial/gridded-resources/fdr.vrt',                       outfile = \"tutorial/refactor.gpkg\")"},{"path":"/articles/03-processing-deep-dive.html","id":"outputs","dir":"Articles","previous_headings":"1) Running the Process: Refactoring","what":"Outputs","title":"Network Manipulation","text":"get high level understanding happened “refactor”, can look length distributions:  area distributions:  Lastly, look feature count network:  Finally, can zoom layer network see changes exist. figure , white edges represent reference catchment network, black edges represent refactored network Since refactoring requires preservation flowpath network, blue lines representative reference refactored network caveat broken different places.","code":""},{"path":"/articles/03-processing-deep-dive.html","id":"running-the-process-aggregating","dir":"Articles","previous_headings":"","what":"2. Running the Process: Aggregating","title":"Network Manipulation","text":"Aggregation primarily divide oriented workflow. collapses network provide new discretization. Two aggregation methods: POIs - define network outlets (NHM SPARROW) statistical distribution, w/o enforced POIs (NextGen).  , hydrolocation POINT layer can passed help direct aggregation, simplicity ignored :","code":""},{"path":"/articles/03-processing-deep-dive.html","id":"example-2","dir":"Articles","previous_headings":"2. Running the Process: Aggregating","what":"Example","title":"Network Manipulation","text":"","code":"hydrolocations = read_sf(\"tutorial/refactored.gpkg\", 'lookup_table') %>%    inner_join(pois, by = c(\"NHDPlusV2_COMID\" = \"hf_id\")) %>%    select(poi_id, NHDPlusV2_COMID, id = reconciled_ID) %>%    distinct()  aggregate_to_distribution(gpkg = \"tutorial/refactored.gpkg\",                           hydrolocations = mutate(pois, id = hf_id),                           ideal_size_sqkm = 10,                            min_length_km = 1,                            min_area_sqkm = 3,                            outfile = \"tutorial/aggregated.gpkg\",                            overwrite = TRUE)"},{"path":"/articles/03-processing-deep-dive.html","id":"outputs-1","dir":"Articles","previous_headings":"2. Running the Process: Aggregating","what":"Outputs","title":"Network Manipulation","text":"get high level understanding happens “refactor”, can look length distributions:  area distributions:  Finally, can zoom layer network see changes exist. left-hand figure , white edges represent reference catchment network, black edges represent refactored network, red represnet aggregated network right-hand figure, can see blue flowlines (reference refactor) prunned aggregation process.  Lastly, can look cumulative network traits fabric:","code":"r = read_hydrofabric(\"tutorial/aggregated.gpkg\") mapview::mapview(r) + pois"},{"path":"/articles/03-processing-deep-dive.html","id":"full-run-through","dir":"Articles","previous_headings":"","what":"Full Run-through","title":"Network Manipulation","text":"network manipulations, fundamental network traits change. requires utilities rapidly efficiently recompute key network metric. nhdplusTools package provides option regenerate fly using graph algorithms logic (see Blodget et al (2023)) return get_sorted() utility subsetting section","code":"hf = get_subset(nldi_feature = list(featureSource = \"nwis\", featureID = \"06752260\"),                  source = \"/Users/mjohnson/hydrofabric\",                 outfile = \"tutorial/poudre.gpkg\") |>      refactor(fac = '/vsis3/lynker-spatial/gridded-resources/fac.vrt',               fdr = '/vsis3/lynker-spatial/gridded-resources/fdr.vrt',               outfile = \"tutorial/refactor.gpkg\") |>      aggregate_to_distribution(outfile = \"tutorial/aggregate.gpkg\") nhdplusTools::add_plus_network_attributes() nhdplusTools::get_streamorder() nhdplusTools::calculate_total_drainage_area() nhdplusTools::get_sorted()"},{"path":"/articles/04-applying-nextgen-model.html","id":"nextgen","dir":"Articles","previous_headings":"","what":"NextGen","title":"Applying NextGen Structure","text":"network aggregated scale matching desired hydrologic processes need turn something NextGen can use (modeling task)","code":""},{"path":"/articles/04-applying-nextgen-model.html","id":"divergent-topology","dir":"Articles","previous_headings":"NextGen","what":"Divergent Topology","title":"Applying NextGen Structure","text":"NextGen operates [flowpath --> nexus] vs [flowpath --> flowpath] topology due HY Features conceptual catchment 1 inflow draining 1 outflow. example can seen :","code":""},{"path":"/articles/04-applying-nextgen-model.html","id":"character-based-indentification","dir":"Articles","previous_headings":"NextGen","what":"Character based indentification","title":"Applying NextGen Structure","text":"NextGen requires integer based identification, like described data model, prefixed character string defining feature Right now, following prefixs used distinguish types model features. following function (1) identifies nexus locations, (2) moves needed (3) applies schema features. can see results opening hydrofabric adding map!","code":"ngen = 'tutorial/nextgen.gpkg'  unlink(ngen)  ngen <- apply_nexus_topology(\"tutorial/aggregated.gpkg\", export_gpkg = 'tutorial/nextgen.gpkg') mapview::mapview(read_hydrofabric(ngen)) + read_sf(ngen, \"nexus\")"},{"path":"/articles/04-applying-nextgen-model.html","id":"extending-nwm-attributes","dir":"Articles","previous_headings":"NextGen","what":"Extending NWM attributes","title":"Applying NextGen Structure","text":"core utilities provide series flowpath, divide, nexuses. However, information needed run /NextGen formulations. include following:","code":"sf::st_layers(ngen) #> Driver: GPKG  #> Available layers: #>       layer_name geometry_type features fields             crs_name #> 1      flowpaths   Line String      396     10 NAD83 / Conus Albers #> 2        divides       Polygon      396      9 NAD83 / Conus Albers #> 3          nexus         Point      173      4 NAD83 / Conus Albers #> 4 hydrolocations            NA       42      3                 <NA> #> 5        network            NA     1308     14                 <NA>"},{"path":"/articles/04-applying-nextgen-model.html","id":"lake-attributes","dir":"Articles","previous_headings":"NextGen > Extending NWM attributes","what":"Lake Attributes","title":"Applying NextGen Structure","text":"WBOut Hydrolocations mapped NHDPlusWaterBody COMIDs used NWM.","code":""},{"path":"/articles/04-applying-nextgen-model.html","id":"flowpath-attributes","dir":"Articles","previous_headings":"NextGen","what":"Flowpath Attributes","title":"Applying NextGen Structure","text":"Flowpath attributes extracted Routelink file values length averaged portion length makes refactored/aggregated network example, 75m flowline roughness 0.05 25m flowline roughness 0.2 Flowpaths attributes lake parameters can added pointing set NWM domain files like found ","code":"(n = (.75 * .05) + (.25 * .2)) #> [1] 0.0875 add_flowpath_attributes(ngen, source = \"/Users/mjohnson/hydrofabric\") #> [1] \"tutorial/nextgen.gpkg\" read_sf(ngen, \"flowpath_attributes\") #> # A tibble: 396 × 12 #>    id     rl_Qi_m3s rl_MusX   rl_n  rl_So rl_ChSlp rl_BtmWdth_m rl_Kchan_mmhr #>    <chr>      <dbl>   <dbl>  <dbl>  <dbl>    <dbl>        <dbl>         <dbl> #>  1 wb-1           0     0.2 0.06   0.0197    0.517         3.91             0 #>  2 wb-10          0     0.2 0.0565 0.0481    0.420         9.14             0 #>  3 wb-100         0     0.2 0.06   0.0971    0.641         2.33             0 #>  4 wb-101         0     0.2 0.06   0.064     0.634         2.39             0 #>  5 wb-102         0     0.2 0.06   0.0726    0.628         2.45             0 #>  6 wb-103         0     0.2 0.06   0.0552    0.679         2.05             0 #>  7 wb-104         0     0.2 0.06   0.0397    0.656         2.33             0 #>  8 wb-105         0     0.2 0.06   0.0596    0.610         2.61             0 #>  9 wb-106         0     0.2 0.06   0.0453    0.584         3.01             0 #> 10 wb-108         0     0.2 0.06   0.114     0.722         1.79             0 #> # ℹ 386 more rows #> # ℹ 4 more variables: rl_nCC <dbl>, rl_TopWdthCC_m <dbl>, rl_TopWdth_m <dbl>, #> #   length_m <dbl>"},{"path":"/articles/04-applying-nextgen-model.html","id":"themeing","dir":"Articles","previous_headings":"NextGen > Flowpath Attributes","what":"Themeing","title":"Applying NextGen Structure","text":"option, QGIS QML theming files can added gpkg. default themeing files come hydrofabric can specified/added append_styles utility desired layer_names QGIS, double clicking gpkg file allow select layers load.","code":"append_style(ngen,layer_names = c(\"nexus\", \"hydrolocations\", \"flowpaths\", \"divides\", \"lakes\"))"},{"path":"/articles/04-data-model-deep-dive.html","id":"data-model","dir":"Articles","previous_headings":"","what":"Data Model","title":"The NextGen Hydrofabic Data Model","text":"rigorous data model developed provide minimal, yet efficient, types data needed modeling, hydrofabric subsetting, cross walking, indexing. Much design stems OGC report modifications made NextGen modelling application. current data model contains 7 data layers anticipated 8th water bodies. 5 spatial 2 -spatial highlighting value geopackage model:","code":""},{"path":"/articles/04-data-model-deep-dive.html","id":"divides","dir":"Articles","previous_headings":"","what":"1. Divides","title":"The NextGen Hydrofabic Data Model","text":"Divides represent incremental area draining flowpath. one-dimensional, hydrology-specific realization holistic catchment. Geometrically, divide edge bounded inflow outflow nodes forming POLYGON","code":""},{"path":"/articles/04-data-model-deep-dive.html","id":"divide-type","dir":"Articles","previous_headings":"1. Divides","what":"Divide Type","title":"The NextGen Hydrofabic Data Model","text":"Divides provide continuous coverage modeling domain. majority domain dendritic, areas divide flow, , flow divide. example: coastal divide area, flowpath. internally draining region (sink) area, flow path artificial path (canal) flowpath, associated drainage area divide flowpath representation exisit, 1:1 relationship meaning one flowpath representation divide. case numeric ID future, support ability 1:many divide:*flowline* representations","code":"divides = read_sf(poudre, \"divides\") mapview(divides[5,])"},{"path":"/articles/04-data-model-deep-dive.html","id":"flowpaths","dir":"Articles","previous_headings":"","what":"2. Flowpaths","title":"The NextGen Hydrofabic Data Model","text":"flowpath references path moving particle water flowpath can represented edge bounded inflow outflow nodes, associated left-bank right-bank sub-catchment faces. Geometrically, flowpath LINESTRING connecting inflow outflow level sinuosity representation flowpath can change per modeling application straight line “infinity” sinuous","code":"# Read in all flowpaths flowpaths = read_sf(poudre, \"flowpaths\")  # Define outflow outflow  =  slice_max(flowpaths, hydroseq)   mapview(outflow) +    filter(divides, divide_id == outflow$divide_id)"},{"path":"/articles/04-data-model-deep-dive.html","id":"durable-integration","dir":"Articles","previous_headings":"2. Flowpaths","what":"Durable Integration","title":"The NextGen Hydrofabic Data Model","text":"Many fields hydrofabric designed remain resilient refactor/aggregation process. Many related network indexing integration primary one mainstem identifier intended remain persistent across network manipulations data model described detail video Anything mapped shared mainstem ID (observations, models, etc) can shared across realizations become “durable”","code":"# Mainstem Persistent Identifier (pid = glue(\"https://geoconnex.us/ref/mainstems/{outflow$mainstem}\")) ## https://geoconnex.us/ref/mainstems/352913 # Geonconnex PID mainstem read for URL geoconnex_mainstem = read_sf(pid)  # Mainstem defined by membership of the outlets hf_mainstem = filter(flowpaths, mainstem == outflow$mainstem)  # View mapview(geoconnex_mainstem) +    mapview(hf_mainstem, color = \"red\")"},{"path":"/articles/04-data-model-deep-dive.html","id":"nexus","dir":"Articles","previous_headings":"","what":"3. Nexus","title":"The NextGen Hydrofabic Data Model","text":"nexus provides conceptual outlet water contained catchment. locations NextGen exchange information! defined POIs Others defined locations network 1:1 inflow outflow occur Every catchment flows hydro nexus, conversely every location hydrologic system can thought hydro nexus drains catchment(s).","code":""},{"path":"/articles/04-data-model-deep-dive.html","id":"consequense-of-network-aggregation","dir":"Articles","previous_headings":"3. Nexus","what":"Consequense of Network Aggregation","title":"The NextGen Hydrofabic Data Model","text":"one divide/flowpath (e.g. catchment) can contribute single nexus:","code":"count = sort(table(divides$toid), decreasing= TRUE)   (example = names(count[count == 3][1])) ## [1] \"nex-278677\" (sub_divides = filter(divides, toid == example)) ## Simple feature collection with 3 features and 9 fields ## Geometry type: MULTIPOLYGON ## Dimension:     XY ## Bounding box:  xmin: -822945 ymin: 1992135 xmax: -814845 ymax: 1998225 ## Projected CRS: NAD83 / Conus Albers ## # A tibble: 3 × 10 ##   divide_id  toid      type  ds_id areasqkm id    lengthkm tot_drainage_areasqkm ## * <chr>      <chr>     <chr> <dbl>    <dbl> <chr>    <dbl>                 <dbl> ## 1 cat-278676 nex-2786… netw…    NA     8.76 wb-2…     5.79                212.   ## 2 cat-302482 nex-2786… netw…    NA    10.8  wb-3…     5.93                 10.8  ## 3 cat-307410 nex-2786… netw…    NA     4.60 wb-3…     3.97                  4.60 ## # ℹ 2 more variables: has_flowline <int>, geom <MULTIPOLYGON [m]>"},{"path":"/articles/04-data-model-deep-dive.html","id":"hydrolocations","dir":"Articles","previous_headings":"","what":"4. Hydrolocations","title":"The NextGen Hydrofabic Data Model","text":"hydrolocation can define location hydrologic significance located “” hydrologic network given dataset, hydrolocations may may associated hydrologic nexus catchment feature. cases, hydro locations typically linearly-referenced defined set flowpaths. Topologically, hydro-location can understood inlet outlet node located end flowpath edge. NextGen design, subset community POIs, treated hydrolocations network refactored aggregated “”. Collectively can help find, link data!","code":"hl = filter(hydrolocations, id == outflow$toid)  filter(hydrolocations, hl_uri == \"Gages-06752260\") ## Simple feature collection with 1 feature and 6 fields ## Geometry type: POINT ## Dimension:     XY ## Bounding box:  xmin: -760037.4 ymin: 1989138 xmax: -760037.4 ymax: 1989138 ## Projected CRS: NAD83 / Conus Albers ## # A tibble: 1 × 7 ##   hl_id hl_reference hl_link  hl_uri hl_position id               geometry ## * <chr> <chr>        <chr>    <chr>  <chr>       <chr>         <POINT [m]> ## 1 8118  Gages        06752260 Gages… outflow     nex-… (-760037.4 1989138) glimpse(hl) ## Rows: 1 ## Columns: 7 ## $ hl_id        <chr> \"8118\" ## $ hl_reference <chr> \"Gages\" ## $ hl_link      <chr> \"06752260\" ## $ hl_uri       <chr> \"Gages-06752260\" ## $ hl_position  <chr> \"outflow\" ## $ id           <chr> \"nex-278699\" ## $ geometry     <POINT [m]> POINT (-760037.4 1989138) (pid = glue('https://reference.geoconnex.us/collections/{tolower(hl$hl_reference)}/items?provider_id={hl$hl_link}')) ## https://reference.geoconnex.us/collections/gages/items?provider_id=06752260 pid = read_sf(pid)  glimpse(pid) ## Rows: 1 ## Columns: 13 ## $ id                   <chr> \"1015611\" ## $ fid                  <int> 70633 ## $ name                 <chr> \"CACHE LA POUDRE RIVER AT FORT COLLINS, CO\" ## $ subjectof            <chr> \"https://waterdata.usgs.gov/monitoring-location/0… ## $ provider_id          <chr> \"06752260\" ## $ nhdpv2_reach_measure <dbl> 46.32248 ## $ mainstem_uri         <chr> \"https://geoconnex.us/ref/mainstems/352913\" ## $ description          <chr> \"USGS NWIS Stream/River/Lake Site 06752260: CACHE… ## $ uri                  <chr> \"https://geoconnex.us/ref/gages/1015611\" ## $ provider             <chr> \"https://waterdata.usgs.gov\" ## $ nhdpv2_reachcode     <chr> \"10190007000017\" ## $ nhdpv2_comid         <dbl> 2900003 ## $ geometry             <POINT [°]> POINT (-105.0692 40.58808) #Use the hl_link to extract this weeks rain event instFlow <- dataRetrieval::readNWISdata(   sites = hl$hl_link, service = \"iv\",   parameterCd = \"00060\",   startDate = \"2023-05-10\" )  # Use PID COMID to extract the 42 year NWM flow record nwm21 = nwmTools::readNWMdata(comid = pid$nhdpv2_comid)"},{"path":"/articles/04-data-model-deep-dive.html","id":"multiplicity","dir":"Articles","previous_headings":"4. Hydrolocations","what":"Multiplicity","title":"The NextGen Hydrofabic Data Model","text":"data design hydrolocation location layer intends represent realization POI independently. means can shared hl_id id (nexus location) distinct hl_reference, hl_link","code":"(poi = filter(hydrolocations, hl_id == 7253)) ## Simple feature collection with 3 features and 6 fields ## Geometry type: POINT ## Dimension:     XY ## Bounding box:  xmin: -768368.2 ymin: 1991210 xmax: -768368.2 ymax: 1991210 ## Projected CRS: NAD83 / Conus Albers ## # A tibble: 3 × 7 ##   hl_id hl_reference hl_link  hl_uri hl_position id               geometry ## * <chr> <chr>        <chr>    <chr>  <chr>       <chr>         <POINT [m]> ## 1 7253  HUC12        1019000… HUC12… outflow     nex-… (-768368.2 1991210) ## 2 7253  NID          CO01659… NID-C… outflow     nex-… (-768368.2 1991210) ## 3 7253  WBOut        2897349  WBOut… outflow     nex-… (-768368.2 1991210)"},{"path":"/articles/04-data-model-deep-dive.html","id":"rigorous-community-poi-mapping","dir":"Articles","previous_headings":"4. Hydrolocations","what":"Rigorous community POI mapping","title":"The NextGen Hydrofabic Data Model","text":"geoconnex PID can provide location source data. can see community POI moved slightly integrate reference network:","code":"geoconnex = read_sf('https://reference.geoconnex.us/collections/dams/items?provider_id=CO01659')  mapview(geoconnex, color = \"red\") + poi"},{"path":"/articles/04-data-model-deep-dive.html","id":"network","dir":"Articles","previous_headings":"","what":"5. Network","title":"The NextGen Hydrofabic Data Model","text":"network layer tabular spatial information provides ultimate cross walk NextGen fabric, source hydrofabric, mapped hydrolocations. network key hydroindexing, data query, network subsetting.","code":""},{"path":"/articles/04-data-model-deep-dive.html","id":"example","dir":"Articles","previous_headings":"5. Network","what":"Example:","title":"The NextGen Hydrofabic Data Model","text":"NextGen ID near ? Lets say lived location Laporte, CO can use NLDI map reference fabric point, search reference fabric hf_id merged current network:","code":"pt = st_sfc(st_point(c(-105.14044,  40.62949)), crs = 4326) mapview(pt) (x = findNLDI(location = pt)) ## $origin ## Simple feature collection with 1 feature and 3 fields ## Geometry type: LINESTRING ## Dimension:     XY ## Bounding box:  xmin: -105.1512 ymin: 40.61313 xmax: -105.1206 ymax: 40.62606 ## Geodetic CRS:  WGS 84 ## # A tibble: 1 × 4 ##   sourceName    identifier comid                                        geometry ##   <chr>         <chr>      <chr>                                <LINESTRING [°]> ## 1 NHDPlus comid 2899849    2899849 (-105.1512 40.62592, -105.1489 40.62606, -10… (n = filter(read_sf(poudre, \"network\"), hf_id == x$origin$comid)) ## # A tibble: 1 × 15 ##   id       toid  divide_id ds_id mainstem hl_id hydroseq hl_uri hf_source  hf_id ##   <chr>    <chr> <chr>     <dbl>    <int> <chr>    <int> <chr>  <chr>      <dbl> ## 1 wb-2786… nex-… cat-2786…    NA   352913 NA       11625 NA     NHDPlusV2 2.90e6 ## # ℹ 5 more variables: lengthkm <dbl>, areasqkm <dbl>, ## #   tot_drainage_areasqkm <dbl>, type <chr>, vpu <chr> mapview(filter(flowpaths, id == n$id)) +    filter(divides, divide_id == n$divide_id) +   filter(nexus, id == n$toid) +    pt"},{"path":"/articles/04-data-model-deep-dive.html","id":"flowpath-attributes","dir":"Articles","previous_headings":"","what":"6. Flowpath Attributes","title":"The NextGen Hydrofabic Data Model","text":"Flowpath attributes extracted NWM Routelink file. network layer used “length weight average” attributes new network.","code":""},{"path":"/articles/04-data-model-deep-dive.html","id":"lakes","dir":"Articles","previous_headings":"","what":"7. Lakes","title":"The NextGen Hydrofabic Data Model","text":"Lake attributes extracted NWM Lake file file. network layer used “length weight average” attributes new network.","code":"lakes = read_sf(poudre, \"lakes\") %>%    filter(hl_id == 7253) %>%    glimpse() ## Rows: 1 ## Columns: 18 ## $ id           <chr> \"nex-287191\" ## $ toid         <chr> \"wb-287191\" ## $ hl_id        <chr> \"7253\" ## $ hl_reference <chr> \"WBOut\" ## $ hl_link      <dbl> 2897349 ## $ hl_uri       <chr> \"WBOut-2897349\" ## $ Dam_Length   <dbl> 10 ## $ ifd          <dbl> 0.9 ## $ LkArea       <dbl> 6.87471 ## $ LkMxE        <dbl> 1678.71 ## $ OrificeA     <dbl> 1 ## $ OrificeC     <dbl> 0.1 ## $ OrificeE     <dbl> 1625.35 ## $ time         <dbl> 0 ## $ WeirC        <dbl> 0.4 ## $ WeirE        <dbl> 1670.706 ## $ WeirL        <dbl> 10 ## $ geom         <POINT> POINT (-768368.2 1991210)"},{"path":"/articles/04-data-model-deep-dive.html","id":"layer-style","dir":"Articles","previous_headings":"","what":"8. Layer Style","title":"The NextGen Hydrofabic Data Model","text":"open hydrofabric gpkg created many hydrofab tools, find load consistent symbology. symbologies saved Geopackage using hydrofab::append_style() Built reference QGIS QML files.","code":"read_sf(poudre, \"layer_styles\") %>%  glimpse() ## Rows: 5 ## Columns: 12 ## $ f_table_catalog   <chr> \"\", \"\", \"\", \"\", \"\" ## $ f_table_schema    <chr> \"\", \"\", \"\", \"\", \"\" ## $ f_table_name      <chr> \"divides\", \"nexus\", \"flowpaths\", \"hydrolocations\", \"… ## $ f_geometry_column <chr> \"geom\", \"geom\", \"geom\", \"geom\", \"geom\" ## $ styleName         <chr> \"divides__hydrofabric_style\", \"nexus__hydrofabric_st… ## $ styleQML          <chr> \"<!DOCTYPE qgis PUBLIC 'http://mrcc.com/qgis.dtd' 'S… ## $ styleSLD          <chr> \"\", \"\", \"\", \"\", \"\" ## $ useAsDefault      <lgl> TRUE, TRUE, TRUE, TRUE, TRUE ## $ description       <chr> \"Generated for hydrofabric\", \"Generated for hydrofab… ## $ owner             <chr> \"\", \"\", \"\", \"\", \"\" ## $ ui                <lgl> NA, NA, NA, NA, NA ## $ update_time       <dttm> 2023-10-12 12:53:35, 2023-10-12 12:53:35, 2023-10-12… a = system.file(\"qml\", \"divides.qml\", package = \"hydrofab\")  readLines(a)[1:20] ##  [1] \"<!DOCTYPE qgis PUBLIC 'http://mrcc.com/qgis.dtd' 'SYSTEM'>\"                                                                              ##  [2] \"<qgis version=\\\"3.22.6-Białowieża\\\" styleCategories=\\\"Symbology\\\">\"                                                                      ##  [3] \"  <renderer-v2 enableorderby=\\\"0\\\" attr=\\\"type\\\" forceraster=\\\"0\\\" type=\\\"categorizedSymbol\\\" symbollevels=\\\"0\\\" referencescale=\\\"-1\\\">\" ##  [4] \"    <categories>\"                                                                                                                        ##  [5] \"      <category symbol=\\\"0\\\" value=\\\"coastal\\\" label=\\\"coastal\\\" render=\\\"true\\\"/>\"                                                      ##  [6] \"      <category symbol=\\\"1\\\" value=\\\"network\\\" label=\\\"network\\\" render=\\\"true\\\"/>\"                                                      ##  [7] \"      <category symbol=\\\"2\\\" value=\\\"internal\\\" label=\\\"internal\\\" render=\\\"true\\\"/>\"                                                    ##  [8] \"      <category symbol=\\\"4\\\" value=\\\"terminal\\\" label=\\\"terminal\\\" render=\\\"true\\\"/>\"                                                    ##  [9] \"    <\/categories>\"                                                                                                                       ## [10] \"    <symbols>\"                                                                                                                           ## [11] \"      <symbol name=\\\"0\\\" force_rhr=\\\"0\\\" clip_to_extent=\\\"1\\\" alpha=\\\"1\\\" type=\\\"fill\\\">\"                                                ## [12] \"        <data_defined_properties>\"                                                                                                       ## [13] \"          <Option type=\\\"Map\\\">\"                                                                                                         ## [14] \"            <Option name=\\\"name\\\" value=\\\"\\\" type=\\\"QString\\\"/>\"                                                                         ## [15] \"            <Option name=\\\"properties\\\"/>\"                                                                                               ## [16] \"            <Option name=\\\"type\\\" value=\\\"collection\\\" type=\\\"QString\\\"/>\"                                                               ## [17] \"          <\/Option>\"                                                                                                                     ## [18] \"        <\/data_defined_properties>\"                                                                                                      ## [19] \"        <layer locked=\\\"0\\\" class=\\\"SimpleFill\\\" enabled=\\\"1\\\" pass=\\\"0\\\">\"                                                              ## [20] \"          <Option type=\\\"Map\\\">\""},{"path":"/articles/05-subsetting.html","id":"the-conus-network-file","dir":"Articles","previous_headings":"","what":"The CONUS network file","title":"Building your own subset","text":"network file distributed version/type hydrofabric. data access patterns see Data Vignette. schema ’ll see every relationship features current hydrofabric, source hydrofabric, conus hydrolocations, exploded “many--many” table. example, can look flowpath wb-1002 find defined aggregation NHDPlusV2 COMID 1712220, 1712230, 1712238. , terminal outflow ‘HUC12-010100100101’ occurs tnx-1000000569 fed aggregate flowpath made three source flowpaths (hf_id={816563, 816417, 816415})","code":"local   <- \"/Users/mjohnson/hydrofabric\" s3      <- \"s3://lynker-spatial/hydrofabric\" version <-  'v2.1.1' type    <- \"nextgen\" domain  <- \"conus\"   network_path = glue(\"{local}/{version}/{type}/conus_network\") net = open_dataset(network_path) glimpse(filter(net, id == \"wb-1002\")) ## FileSystemDataset with 22 Parquet files (query) ## 3 rows x 18 columns ## $ id                    <string> \"wb-1002\", \"wb-1002\", \"wb-1002\" ## $ toid                  <string> \"nex-1003\", \"nex-1003\", \"nex-1003\" ## $ divide_id             <string> \"cat-1002\", \"cat-1002\", \"cat-1002\" ## $ ds_id                 <double> NA, NA, NA ## $ mainstem              <double> 1816996, 1816996, 1816996 ## $ hl_id                 <string> NA, NA, NA ## $ hydroseq               <int32> 3730, 3730, 3730 ## $ hl_uri                <string> NA, NA, NA ## $ hf_source             <string> \"NHDPlusV2\", \"NHDPlusV2\", \"NHDPlusV2\" ## $ hf_id                 <double> 1712220, 1712230, 1712238 ## $ lengthkm              <double> 4.787772, 4.787772, 4.787772 ## $ areasqkm              <double> 6.36435, 6.36435, 6.36435 ## $ tot_drainage_areasqkm <double> 706.779, 706.779, 706.779 ## $ type                  <string> \"nexus\", \"nexus\", \"nexus\" ## $ hf_areasqkm           <double> 0.7902, 0.1431, 5.4423 ## $ hf_hydroseq            <int32> 2245165, 2245183, 2245201 ## $ topo                  <string> \"fl-nex\", \"fl-nex\", \"fl-nex\" ## $ vpuid                 <string> \"01\", \"01\", \"01\" ## Call `print()` for query details glimpse(filter(net, hl_uri == 'HUC12-010100100101')) ## FileSystemDataset with 22 Parquet files (query) ## 3 rows x 18 columns ## $ id                    <string> \"wb-280\", \"wb-280\", \"wb-280\" ## $ toid                  <string> \"tnx-1000000569\", \"tnx-1000000569\", \"tnx-100000… ## $ divide_id             <string> \"cat-280\", \"cat-280\", \"cat-280\" ## $ ds_id                 <double> NA, NA, NA ## $ mainstem              <double> 1780414, 1780414, 1780414 ## $ hl_id                 <string> \"01236\", \"01236\", \"01236\" ## $ hydroseq               <int32> 18917, 18917, 18917 ## $ hl_uri                <string> \"HUC12-010100100101\", \"HUC12-010100100101\", \"HU… ## $ hf_source             <string> \"NHDPlusV2\", \"NHDPlusV2\", \"NHDPlusV2\" ## $ hf_id                 <double> 816563, 816417, 816415 ## $ lengthkm              <double> 5.135779, 5.135779, 5.135779 ## $ areasqkm              <double> 13.2813, 13.2813, 13.2813 ## $ tot_drainage_areasqkm <double> 51.68745, 51.68745, 51.68745 ## $ type                  <string> \"terminal\", \"terminal\", \"terminal\" ## $ hf_areasqkm           <double> 9.3258, 1.9071, 2.0484 ## $ hf_hydroseq            <int32> 2243683, 2243682, 2243689 ## $ topo                  <string> \"fl-nex\", \"fl-nex\", \"fl-nex\" ## $ vpuid                 <string> \"01\", \"01\", \"01\" ## Call `print()` for query details"},{"path":[]},{"path":"/articles/05-subsetting.html","id":"by-known-comid","dir":"Articles","previous_headings":"Finding an Origin","what":"By known COMID","title":"Building your own subset","text":"","code":"findOrigin(network_path, comid = 101) ## # A tibble: 1 × 4 ##   id         vpuid topo   hydroseq ##   <chr>      <chr> <chr>     <int> ## 1 wb-2430837 12    fl-nex      139"},{"path":"/articles/05-subsetting.html","id":"by-known-id","dir":"Articles","previous_headings":"Finding an Origin","what":"By known ID","title":"Building your own subset","text":"","code":"findOrigin(network_path, id = 'wb-2430837') ## # A tibble: 1 × 4 ##   id         vpuid topo   hydroseq ##   <chr>      <chr> <chr>     <int> ## 1 wb-2430837 12    fl-nex      139"},{"path":"/articles/05-subsetting.html","id":"by-location-xy","dir":"Articles","previous_headings":"Finding an Origin","what":"By location (XY)","title":"Building your own subset","text":"","code":"here = AOI::geocode(\"National Water Center, Alabama\")  findOrigin(network_path, xy = c(here$x, here$y)) ## # A tibble: 1 × 4 ##   id        vpuid topo   hydroseq ##   <chr>     <chr> <chr>     <int> ## 1 wb-489658 03W   fl-nex     4118"},{"path":"/articles/05-subsetting.html","id":"by-hydrolocation-uri","dir":"Articles","previous_headings":"Finding an Origin","what":"By Hydrolocation URI","title":"Building your own subset","text":"","code":"# For a gage in Calfornia findOrigin(network_path, hl_uri = \"Gages-11123000\") ## # A tibble: 1 × 4 ##   id         vpuid topo   hydroseq ##   <chr>      <chr> <chr>     <int> ## 1 wb-3314811 18    fl-nex    28597 # For the HUC12 of Atascadero Creek in Santa Barbara: findOrigin(network_path, hl_uri = \"HUC12-180600130201\") ## # A tibble: 1 × 4 ##   id         vpuid topo   hydroseq ##   <chr>      <chr> <chr>     <int> ## 1 wb-3315273 18    fl-nex    16028 # For the dam on Horsetooth Reservoir findOrigin(network_path, hl_uri = \"NID-CO01659-1\") ## # A tibble: 1 × 4 ##   id         vpuid topo   hydroseq ##   <chr>      <chr> <chr>     <int> ## 1 wb-1560663 10L   fl-nex    50415"},{"path":"/articles/05-subsetting.html","id":"by-nldi-feature","dir":"Articles","previous_headings":"Finding an Origin","what":"By NLDI Feature","title":"Building your own subset","text":"","code":"# For a gage in Calfornia findOrigin(network_path,             nldi_feature  = list(featureSource = \"nwissite\",                                  featureID = \"USGS-05428500\")) ## # A tibble: 1 × 4 ##   id         vpuid topo   hydroseq ##   <chr>      <chr> <chr>     <int> ## 1 wb-1089011 07    fl-nex    33345"},{"path":"/articles/05-subsetting.html","id":"hfsubetr","dir":"Articles","previous_headings":"","what":"hfsubetR","title":"Building your own subset","text":"hfsubsetR library core module NOAA-OWP/hydrofabric suite. expedites process (1) finding origin (2) traversing network (3) extracting relevant features requested. example, lets get basic subset network upstream comid=101 complete divides, nexus locations flowlines: request can appended request attribute information enrich network. example, can grab precomputed divide attributes forcing weights needed NGIAB.","code":"subset101 = get_subset(comid = 101,                         lyrs = c(\"divides\", \"nexus\", \"flowlines\"),                        source   = \"/Users/mjohnson/hydrofabric\",                        hf_version =  '2.1.1',                        type    = \"nextgen\")  mapview::mapview(subset101) subset101_enhanced = get_subset(comid = 101,             lyrs = c(\"divides\", \"nexus\", \"flowlines\", \"forcing-weights\", \"model-attributes\"),            source   = \"/Users/mjohnson/hydrofabric\",            hf_version =  '2.1.1',            type    = \"nextgen\",            domain  = \"conus\")  subset101_enhanced$`model-attributes` ## # A tibble: 12 × 44 ##    divide_id  elevation_mean slope_mean impervious_mean aspect_c_mean twi_dist_4 ##    <chr>               <dbl>      <dbl>           <dbl>         <dbl> <chr>      ##  1 cat-24308…           75.2      0.467          2.55            163. \"[{\\\"v\\\":… ##  2 cat-24308…           57.8      0.476          1.75            185. \"[{\\\"v\\\":… ##  3 cat-24308…           48.4      0.392          0.965           173. \"[{\\\"v\\\":… ##  4 cat-24308…           42.5      0.268          0.0194          177. \"[{\\\"v\\\":… ##  5 cat-24308…           40.9      0.273          0.254           109. \"[{\\\"v\\\":… ##  6 cat-24308…           79.3      0.467          1.22            163. \"[{\\\"v\\\":… ##  7 cat-24308…           58.2      0.460          1.20            210. \"[{\\\"v\\\":… ##  8 cat-24308…           50.1      0.672          0.0122          204. \"[{\\\"v\\\":… ##  9 cat-24308…           61.0      0.402          0.845           147. \"[{\\\"v\\\":… ## 10 cat-24308…           46.5      0.285          0.364           150. \"[{\\\"v\\\":… ## 11 cat-24308…           50.1      0.503          0.594           189. \"[{\\\"v\\\":… ## 12 cat-24308…           75.6      0.508          0.818           208. \"[{\\\"v\\\":… ## # ℹ 38 more variables: X <dbl>, Y <dbl>, gw_Coeff <dbl>, gw_Zmax <dbl>, ## #   gw_Expon <dbl>, `bexp_soil_layers_stag=1` <dbl>, ## #   `bexp_soil_layers_stag=2` <dbl>, `bexp_soil_layers_stag=3` <dbl>, ## #   `bexp_soil_layers_stag=4` <dbl>, ISLTYP <int>, IVGTYP <int>, ## #   `dksat_soil_layers_stag=1` <dbl>, `dksat_soil_layers_stag=2` <dbl>, ## #   `dksat_soil_layers_stag=3` <dbl>, `dksat_soil_layers_stag=4` <dbl>, ## #   `psisat_soil_layers_stag=1` <dbl>, `psisat_soil_layers_stag=2` <dbl>, … subset101_enhanced$`forcing-weights` ## # A tibble: 328 × 5 ##    divide_id       cell coverage_fraction grid_id                    vpuid ##    <chr>          <dbl>             <dbl> <chr>                      <chr> ##  1 cat-2430835 13282774             0.262 medium_range.forcing.conus 12    ##  2 cat-2430835 13282775             0.603 medium_range.forcing.conus 12    ##  3 cat-2430835 13282776             0.582 medium_range.forcing.conus 12    ##  4 cat-2430835 13282777             0.112 medium_range.forcing.conus 12    ##  5 cat-2430835 13287382             0.145 medium_range.forcing.conus 12    ##  6 cat-2430835 13287383             0.980 medium_range.forcing.conus 12    ##  7 cat-2430835 13287384             1     medium_range.forcing.conus 12    ##  8 cat-2430835 13287385             0.945 medium_range.forcing.conus 12    ##  9 cat-2430835 13287386             0.308 medium_range.forcing.conus 12    ## 10 cat-2430835 13291990             0.397 medium_range.forcing.conus 12    ## # ℹ 318 more rows"},{"path":"/articles/05-subsetting.html","id":"rest-service-beta","dir":"Articles","previous_headings":"","what":"REST Service (BETA)","title":"Building your own subset","text":"workflows regardless programming language, offer -beta REST API. API wraps hfsubsetR library provide subsetting capabilities across web. Currently, API offers one endpoint /subset. query endpoint, can use tool like cURL: Running outputs GeoPackage subset v2.1.1 NextGen hydrofabric, containing following layers upstream features COMID 101: Additionally, can also subset forcing weights two ways: subset pre-computed NextGen layer compute weight grid -demand (1), can accomplish explicitly setting layer query parameter: (2), can set weights query parameter:","code":"API_URL=\"https://www.lynker-spatial.com/hydrofabric/hfsubset\" curl -o hydrofabric.gpkg \"${API_URL}/subset?identifier=101&identifier_type=comid&version=2.1.1&subset_type=nextgen\" layer_name     geometry_type features fields             crs_name 1    divides           Polygon       20     10 NAD83 / Conus Albers 2  flowlines Multi Line String       20     11 NAD83 / Conus Albers 3      nexus             Point        8      6 NAD83 / Conus Albers 4    network                NA       86     18                 <NA> curl -o hydrofabric.gpkg \"${API_URL}/subset?identifier=101&identifier_type=comid&version=2.1.1&subset_type=nextgen&layer=divides&layer=forcing-weights\" curl -o hydrofabric.gpkg \"${API_URL}/subset?identifier=101&identifier_type=comid&version=2.1.1&subset_type=nextgen&layer=divides&weights=medium_range\""},{"path":"/articles/05-subsetting.html","id":"cli-option","dir":"Articles","previous_headings":"","what":"CLI Option","title":"Building your own subset","text":"interested using NOAA NextGen fabric, without directly needing R, within non-interactive pipeline, provide pre-built binaries Go-based CLI tool creates forwards requests REST API, preventing need construct URLs use cURL examples . help output tool follows:","code":"hfsubset - Hydrofabric Subsetter  Usage:   hfsubset [OPTIONS] identifiers...   hfsubset (-h | --help)  Examples:   hfsubset -o ./divides_nexus.gpkg \\            -r \"2.2\"                \\            -t hl                   \\            \"Gages-06752260\"    hfsubset -o ./poudre.gpkg -t hl \"Gages-06752260\"    # Using network-linked data index identifiers   hfsubset -o ./poudre.gpkg -t nldi \"nwissite:USGS-08279500\"      # Specifying hydrofabric version and subset type   hfsubset -o ./divides_nexus.gpkg -l divides,flowlines,nexus -r \"2.1.1\" -s \"nextgen\" -t hl \"Gages-06752260\"      # Finding data around a coordinate point   hfsubset -o ./sacramento_flowlines.gpkg -l flowlines -t xy -121.494400,38.581573  Environment Variables:   ${HFSUBSET_ENDPOINT} - Endpoint to use for subsetting,                          defaults to 'https://www.lynker-spatial.com/hydrofabric/hfsubset/'.                          Note: the endpoint must end with a trailing slash.  Details:   * Finding POI identifiers can be done visually     through https://www.lynker-spatial.com/hydrolocations.html    * When using identifier type 'xy', the coordinates are in OGC:CRS84 order,     which is the same reference system as EPSG:4326 (WGS84), but uses     longitude-latitude axis order rather than latitude-longitude.    * When using identifier type 'nldi', the identifiers follow the syntax        <featureSource>:<featureID>      For example, USGS-08279500 is accessed with featureSource 'nwissite',     so this gives the form 'nwissite:USGS-08279500'  Options:   -debug         Run in debug mode   -dryrun         Perform a dry run, only outputting the request that will be sent   -l string         Comma-delimited list of layers to subset. (default \"divides,flowlines,network,nexus\")   -o string         Output file name (default \"hydrofabric.gpkg\")   -quiet         Disable logging   -s string         Hydrofabric type, only \"reference\" is supported (default \"reference\")   -t string         One of: \"hf\", \"comid\", \"hl\", \"poi\", \"nldi\", or \"xy\" (default \"hf\")   -v string         Hydrofabric version (NOTE: omit the preceeding v) (default \"2.2\")   -verify         Verify that endpoint is available (default true)   -w string         Comma-delimited list of weights to generate over the subset."},{"path":"/articles/06-attribute-access.html","id":"precomputed-data","dir":"Articles","previous_headings":"","what":"1. Precomputed Data","title":"Attribute Access and Creation","text":"intention NextGen provide suite precomputed, useful information related release hydrofabric. date include attributes needed run CFE/NOAH-OWP, eventually include attributes found CAMELS dataset. Precomputed data live directory released hydrofabric artifacts follow VPU segmentation. , can see extract information CFE Poudre subset.","code":""},{"path":"/articles/06-attribute-access.html","id":"set-up","dir":"Articles","previous_headings":"1. Precomputed Data","what":"Set up","title":"Attribute Access and Creation","text":"","code":"library(arrow)  # read network x = read_sf(\"cihro-data/poudre.gpkg\", \"network\")  # define variable set attr = 'cfe_noahowp'  # define path  p = glue(\"s3://lynker-spatial/pre-release/nextgen_{x$vpu[1]}_{attr}.parquet\")"},{"path":"/articles/06-attribute-access.html","id":"access-and-join","dir":"Articles","previous_headings":"1. Precomputed Data","what":"Access and Join","title":"Attribute Access and Creation","text":"","code":"divides = read_sf(\"cihro-data/poudre.gpkg\", \"divides\")  # Open dataset and Join to divides divides = open_dataset(p) %>%    filter(divide_id %in% divides$divide_id) %>%    collect() %>%    right_join(divides, by = \"divide_id\") %>%    st_as_sf()"},{"path":"/articles/06-attribute-access.html","id":"explore","dir":"Articles","previous_headings":"","what":"Explore","title":"Attribute Access and Creation","text":"","code":"glimpse(divides) ## Rows: 419 ## Columns: 45 ## $ divide_id                   <chr> \"cat-278672\", \"cat-278673\", \"cat-278674\", … ## $ gw_Coeff                    <dbl> 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, … ## $ gw_Zmax                     <dbl> 247.42465, 247.42465, 247.42465, 247.42465… ## $ gw_Expon                    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … ## $ `bexp_soil_layers_stag=1`   <dbl> 6.905784, 6.905784, 6.905784, 6.905784, 6.… ## $ `bexp_soil_layers_stag=2`   <dbl> 6.905784, 6.905784, 6.905784, 6.905784, 6.… ## $ `bexp_soil_layers_stag=3`   <dbl> 6.905784, 6.905784, 6.905784, 6.905784, 6.… ## $ `bexp_soil_layers_stag=4`   <dbl> 6.905784, 6.905784, 6.905784, 6.905784, 6.… ## $ ISLTYP                      <int> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, … ## $ IVGTYP                      <int> 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14… ## $ `dksat_soil_layers_stag=1`  <dbl> 1.605749e-07, 1.560944e-07, 2.424650e-07, … ## $ `dksat_soil_layers_stag=2`  <dbl> 1.605749e-07, 1.560944e-07, 2.424650e-07, … ## $ `dksat_soil_layers_stag=3`  <dbl> 1.605749e-07, 1.560944e-07, 2.424650e-07, … ## $ `dksat_soil_layers_stag=4`  <dbl> 1.605749e-07, 1.560944e-07, 2.424650e-07, … ## $ `psisat_soil_layers_stag=1` <dbl> 0.09665685, 0.11262189, 0.16652204, 0.0334… ## $ `psisat_soil_layers_stag=2` <dbl> 0.09665685, 0.11262189, 0.16652204, 0.0334… ## $ `psisat_soil_layers_stag=3` <dbl> 0.09665685, 0.11262189, 0.16652204, 0.0334… ## $ `psisat_soil_layers_stag=4` <dbl> 0.09665685, 0.11262189, 0.16652204, 0.0334… ## $ cwpvt                       <dbl> 0.09246867, 0.09224170, 0.09224170, 0.0922… ## $ mfsno                       <dbl> 3.268730, 3.307741, 3.307741, 3.307741, 3.… ## $ mp                          <dbl> 9.505003, 8.412661, 8.366073, 8.368729, 8.… ## $ `quartz_soil_layers_stag=1` <dbl> 0.6000000, 0.6000000, 0.6000000, 0.6000000… ## $ `quartz_soil_layers_stag=2` <dbl> 0.6000000, 0.6000000, 0.6000000, 0.6000000… ## $ `quartz_soil_layers_stag=3` <dbl> 0.6000000, 0.6000000, 0.6000000, 0.6000000… ## $ `quartz_soil_layers_stag=4` <dbl> 0.6000000, 0.6000000, 0.6000000, 0.6000000… ## $ refkdt                      <dbl> 3.936352, 3.951302, 3.951302, 3.951302, 3.… ## $ slope                       <dbl> 0.7555849542, 0.7692162991, 0.7692162991, … ## $ `smcmax_soil_layers_stag=1` <dbl> 0.4457698, 0.4462140, 0.4462140, 0.4462140… ## $ `smcmax_soil_layers_stag=2` <dbl> 0.4457698, 0.4462140, 0.4462140, 0.4462140… ## $ `smcmax_soil_layers_stag=3` <dbl> 0.4457698, 0.4462140, 0.4462140, 0.4462140… ## $ `smcmax_soil_layers_stag=4` <dbl> 0.4457698, 0.4462140, 0.4462140, 0.4462140… ## $ `smcwlt_soil_layers_stag=1` <dbl> 0.04700000, 0.04700000, 0.04700000, 0.0470… ## $ `smcwlt_soil_layers_stag=2` <dbl> 0.04700000, 0.04700000, 0.04700000, 0.0470… ## $ `smcwlt_soil_layers_stag=3` <dbl> 0.04700000, 0.04700000, 0.04700000, 0.0470… ## $ `smcwlt_soil_layers_stag=4` <dbl> 0.04700000, 0.04700000, 0.04700000, 0.0470… ## $ vcmx25                      <dbl> 65.49842, 69.17342, 69.32784, 69.31904, 69… ## $ toid                        <chr> \"nex-278673\", \"nex-278674\", \"nex-278675\", … ## $ type                        <chr> \"network\", \"network\", \"network\", \"network\"… ## $ ds_id                       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ areasqkm                    <dbl> 20.081244, 13.325397, 1.141646, 7.440300, … ## $ id                          <chr> \"wb-278672\", \"wb-278673\", \"wb-278674\", \"wb… ## $ lengthkm                    <dbl> 9.249722, 5.541113, 1.122110, 6.340693, 5.… ## $ tot_drainage_areasqkm       <dbl> 20.08124, 51.43679, 87.73334, 186.33094, 2… ## $ has_flowline                <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … ## $ geom                        <MULTIPOLYGON [m]> MULTIPOLYGON (((-823365 197..…"},{"path":"/articles/06-attribute-access.html","id":"unique-use-cases","dir":"Articles","previous_headings":"","what":"2. Unique Use Cases","title":"Attribute Access and Creation","text":"Now, may want use (limited) data defined. ok ! part enterprise hydrofabric utilities/aspirations, provide tools access 100,000 different datasets without requiring download find data!","code":""},{"path":[]},{"path":"/articles/06-attribute-access.html","id":"single-day","dir":"Articles","previous_headings":"2. Unique Use Cases > Gridmet solar radiation on 2020-10-29","what":"Single Day","title":"Attribute Access and Creation","text":"","code":"r = getGridMET(AOI = divides, varname = \"srad\", startDate = \"2020-10-29\")  plot(r$daily_mean_shortwave_radiation_at_surface) srad = execute_zonal(r, geom = divides, fun = \"mean\", ID = \"divide_id\")  plot(srad['mean.srad_2020.10.29'])"},{"path":"/articles/06-attribute-access.html","id":"through-time","dir":"Articles","previous_headings":"2. Unique Use Cases > Gridmet solar radiation on 2020-10-29","what":"Through time","title":"Attribute Access and Creation","text":"","code":"p = getGridMET(AOI = divides, varname = \"pr\", startDate = \"2023-05-10\", endDate = \"2023-05-13\")  plot(p$precipitation_amount) pr = execute_zonal(p, geom = divides, fun = \"mean\", ID = \"divide_id\")  plot(pr[grep('pr', names(pr), value = TRUE)], border = FALSE)"},{"path":"/articles/06-attribute-access.html","id":"on-the-fly-exploration","dir":"Articles","previous_headings":"2. Unique Use Cases > Gridmet solar radiation on 2020-10-29","what":"On the fly exploration","title":"Attribute Access and Creation","text":"want rank map NextGen Catchments amount rain received last days","code":"pr$cumpr = rank(st_drop_geometry(pr[grep('pr', names(pr), value = TRUE)]) %>% rowSums())  plot(pr['cumpr'])"},{"path":"/articles/06-attribute-access.html","id":"beyond-gridmet","dir":"Articles","previous_headings":"2. Unique Use Cases > Gridmet solar radiation on 2020-10-29","what":"Beyond Gridmet","title":"Attribute Access and Creation","text":"climateR provides range short cut functions common datasets. simply shortcuts make access faster:","code":"grep(\"get\", ls(\"package:climateR\"), value = TRUE) ##  [1] \"dap_get\"             \"get_data\"            \"get3DEP\"             ##  [4] \"getBCCA\"             \"getCHIRPS\"           \"getDaymet\"           ##  [7] \"getDodsrcPath\"       \"getGLDAS\"            \"getGridMET\"          ## [10] \"getLCMAP\"            \"getLivneh\"           \"getLivneh_fluxes\"    ## [13] \"getLOCA\"             \"getLOCA_hydro\"       \"getMACA\"             ## [16] \"getMODIS\"            \"getNASADEM\"          \"getNetrcPath\"        ## [19] \"getNLCD\"             \"getNLDAS\"            \"getPRISM\"            ## [22] \"getTerraClim\"        \"getTerraClimNormals\" \"getVIC\"              ## [25] \"getWorldClim\"        \"go_get_dap_data\"     \"vrt_crop_get\""},{"path":"/articles/06-attribute-access.html","id":"mean-monthly-normals","dir":"Articles","previous_headings":"2. Unique Use Cases > Gridmet solar radiation on 2020-10-29 > Beyond Gridmet","what":"Mean Monthly Normals","title":"Attribute Access and Creation","text":"","code":"ppt = getTerraClimNormals(AOI = divides,  varname = \"ppt\") %>%    execute_zonal(geom = divides, ID = \"divide_id\")  plot(ppt[grep(\"ppt\", names(ppt), value = TRUE)], border = NA) ## Warning: plotting the first 10 out of 12 attributes; use max.plot = 12 to plot ## all"},{"path":"/articles/06-attribute-access.html","id":"beyond-shortcut-functions","dir":"Articles","previous_headings":"2. Unique Use Cases > Gridmet solar radiation on 2020-10-29","what":"Beyond shortcut functions","title":"Attribute Access and Creation","text":"climateR-catalogs provide vast catalog resources can accessed. can find catalog element want, can passed general dap utilities.","code":"glimpse(read_live_catalog()) ## Rows: 37,010 ## Columns: 29 ## $ id          <fct> bcca, bcca, bcca, bcca, bcca, bcca, bcca, bcca, bcca, bcca… ## $ asset       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ URL         <chr> \"https://cida.usgs.gov/thredds/dodsC/cmip5_bcca/future\", \"… ## $ type        <fct> opendap, opendap, opendap, opendap, opendap, opendap, open… ## $ varname     <chr> \"BCCA_0-125deg_pr_day_ACCESS1-0_rcp45_r1i1p1\", \"BCCA_0-125… ## $ variable    <fct> pr, pr, pr, pr, pr, pr, pr, pr, pr, pr, pr, pr, pr, pr, pr… ## $ description <chr> \"Precipitation\", \"Precipitation\", \"Precipitation\", \"Precip… ## $ units       <chr> \"mm/d\", \"mm/d\", \"mm/d\", \"mm/d\", \"mm/d\", \"mm/d\", \"mm/d\", \"m… ## $ model       <chr> \"ACCESS1-0\", \"ACCESS1-0\", \"bcc-csm1-1\", \"bcc-csm1-1\", \"bcc… ## $ ensemble    <chr> \"r1i1p1\", \"r1i1p1\", \"r1i1p1\", \"r1i1p1\", \"r1i1p1\", \"r1i1p1\"… ## $ scenario    <chr> \"rcp45\", \"rcp85\", \"rcp26\", \"rcp45\", \"rcp60\", \"rcp85\", \"rcp… ## $ T_name      <chr> \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"t… ## $ duration    <chr> \"2006-01-01 12:00:00/2100-12-31 12:00:00\", \"2006-01-01 12:… ## $ interval    <chr> \"1 days\", \"1 days\", \"1 days\", \"1 days\", \"1 days\", \"1 days\"… ## $ nT          <int> 34698, 34698, 34698, 34698, 34698, 34698, 34698, 34698, 34… ## $ X_name      <chr> \"longitude\", \"longitude\", \"longitude\", \"longitude\", \"longi… ## $ Y_name      <chr> \"latitude\", \"latitude\", \"latitude\", \"latitude\", \"latitude\"… ## $ X1          <dbl> -124.6875, -124.6875, -124.6875, -124.6875, -124.6875, -12… ## $ Xn          <dbl> -67.0625, -67.0625, -67.0625, -67.0625, -67.0625, -67.0625… ## $ Y1          <dbl> 25.1875, 25.1875, 25.1875, 25.1875, 25.1875, 25.1875, 25.1… ## $ Yn          <dbl> 52.8125, 52.8125, 52.8125, 52.8125, 52.8125, 52.8125, 52.8… ## $ resX        <dbl> 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.… ## $ resY        <dbl> 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.… ## $ ncols       <int> 462, 462, 462, 462, 462, 462, 462, 462, 462, 462, 462, 462… ## $ nrows       <int> 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222… ## $ crs         <chr> \"+proj=longlat +a=6378137 +f=0.00335281066474748 +pm=0 +no… ## $ toptobottom <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE… ## $ tiled       <fct> T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T… ## $ dim_order   <fct> TYX, TYX, TYX, TYX, TYX, TYX, TYX, TYX, TYX, TYX, TYX, TYX…"},{"path":"/articles/06-attribute-access.html","id":"polaris-soils","dir":"Articles","previous_headings":"2. Unique Use Cases > Gridmet solar radiation on 2020-10-29","what":"POLARIS Soils","title":"Attribute Access and Creation","text":"","code":"cat = filter(catalog, id == \"polaris\", grepl(\"mean alpha\", variable))  alpha = dap(catalog = cat, AOI = divides) names(alpha) = paste0(\"layer\", 1:nlyr(alpha))  plot(alpha) soil = execute_zonal(alpha, geom = divides, fun = \"mean\", ID = \"divide_id\")  plot(soil[grepl('mean.layer', names(soil))], border = NA)"},{"path":"/articles/06-attribute-access.html","id":"usgs-dems","dir":"Articles","previous_headings":"2. Unique Use Cases > Gridmet solar radiation on 2020-10-29","what":"USGS DEMs","title":"Attribute Access and Creation","text":"","code":"(cat = catalog %>%  filter(asset == \"30m CONUS DEM\")) ## # A tibble: 1 × 29 ##   id        asset  URL   type  varname variable description units model ensemble ##   <fct>     <chr>  <chr> <fct> <chr>   <fct>    <chr>       <chr> <chr> <chr>    ## 1 USGS 3DEP 30m C… /vsi… vrt   elevat… elevati… 30m CONUS … mete… NA    NA       ## # ℹ 19 more variables: scenario <chr>, T_name <chr>, duration <chr>, ## #   interval <chr>, nT <int>, X_name <chr>, Y_name <chr>, X1 <dbl>, Xn <dbl>, ## #   Y1 <dbl>, Yn <dbl>, resX <dbl>, resY <dbl>, ncols <int>, nrows <int>, ## #   crs <chr>, toptobottom <lgl>, tiled <fct>, dim_order <fct> dem = dap(catalog = cat, AOI = divides)  plot(dem[[1]])"},{"path":"/articles/06-attribute-access.html","id":"beyond-r","dir":"Articles","previous_headings":"2. Unique Use Cases > Gridmet solar radiation on 2020-10-29","what":"Beyond R","title":"Attribute Access and Creation","text":"USGS gdptools provides similar climateR/zonal capabilities data catalog Python","code":""},{"path":"/articles/06-attribute-access.html","id":"legacy-of-usgs-based-comid-data","dir":"Articles","previous_headings":"","what":"3. Legacy of USGS based COMID data","title":"Attribute Access and Creation","text":"wide range legacy new products produced USGS rigorously summarize 1,000’s attributes NHDPlusV2 catchment network. One particular interest NextGen TWI. TOPMODEL requires distribution, quick dirty way get NextGen catchment TWI estimates immense value.","code":"knitr::include_graphics(\"../man/figures/usgs-twi.png\")"},{"path":"/articles/06-attribute-access.html","id":"twi-joined-to-the-poudre-river-network","dir":"Articles","previous_headings":"3. Legacy of USGS based COMID data","what":"TWI joined to the Poudre River Network","title":"Attribute Access and Creation","text":"","code":"net = read_sf(\"cihro-data/poudre.gpkg\", \"network\")   twi = data.frame(comid = unique(net$hf_id)) %>%    left_join(get_vaa('areasqkm'), by = \"comid\") %>%    left_join(read_parquet('cihro-data/56f97be4e4b0a6037df06b70_tot.parquet'), by = c(\"comid\"=\"COMID\")) %>%    select(hf_id = comid, s_areasqkm = areasqkm, TOT_TWI)"},{"path":"/articles/06-attribute-access.html","id":"reference-fabric-data","dir":"Articles","previous_headings":"3. Legacy of USGS based COMID data","what":"Reference fabric data","title":"Attribute Access and Creation","text":"","code":"ref = get_fabric(VPU = \"10L\", base_s3 = 's3://lynker-spatial/01_reference/', cache_dir  = \"cihro-data\") %>%    read_sf(\"reference_catchment\") %>%    filter(FEATUREID %in% twi$hf_id) %>%    left_join(twi, by = c(\"FEATUREID\"=\"hf_id\"))  plot(ref['TOT_TWI'], border = NA, main = paste(nrow(ref), \" reference catchments\"))"},{"path":"/articles/06-attribute-access.html","id":"area-averaging-reference-fabric-to-nextgen","dir":"Articles","previous_headings":"3. Legacy of USGS based COMID data","what":"Area averaging reference fabric to NextGen","title":"Attribute Access and Creation","text":"limited just TWI. nhdplusTools package provides archive NHDPlusV2 based catchment datasets can used: Lynker provides reformatted archive EPA streamcat data:","code":"full = net %>%    select(divide_id, hf_id, areasqkm) %>%    distinct() %>%    left_join(twi, by = \"hf_id\")   f1 = aggregate_zones(data = full,                       geom = NULL,                        crosswalk = select(full, hf_id, divide_id, areasqkm, s_areasqkm),                      ID = \"divide_id\") %>%    right_join(divides,               by = \"divide_id\") %>%    st_as_sf()   plot(f1['TOT_TWI'], border = NA, main = paste(nrow(f1), \"nextgen catchments\")) xx = discover_nldi_characteristics(\"all\")   lapply(xx, nrow) ## $local ## [1] 126 ##  ## $total ## [1] 127 ##  ## $divergence_routed ## [1] 126 xx$total$characteristic_id[1:10] ##  [1] \"TOT_BFI\"        \"TOT_PET\"        \"TOT_CONTACT\"    \"TOT_EWT\"        ##  [5] \"TOT_IEOF\"       \"TOT_RECHG\"      \"TOT_SATOF\"      \"TOT_TWI\"        ##  [9] \"TOT_WB5100_ANN\" \"TOT_FUNGICIDE\" xx = aws.s3::get_bucket_df(bucket = 's3://nextgen-hydrofabric', prefix = 'streamcats') %>%    filter(!grepl(\"old|data\", Key))  nrow(xx) ## [1] 139 xx$Key[2:11] ##  [1] \"streamcats/streamcat_AgriculturalNitrogen_cat.parquet\"    ##  [2] \"streamcats/streamcat_Aquifers_cat.parquet\"                ##  [3] \"streamcats/streamcat_BFI_cat.parquet\"                     ##  [4] \"streamcats/streamcat_CanalDensity_cat.parquet\"            ##  [5] \"streamcats/streamcat_CoalMines_cat.parquet\"               ##  [6] \"streamcats/streamcat_Dams_cat.parquet\"                    ##  [7] \"streamcats/streamcat_EPA_FRSRipBuf100_cat.parquet\"        ##  [8] \"streamcats/streamcat_EPA_FRS_cat.parquet\"                 ##  [9] \"streamcats/streamcat_Elevation_cat.parquet\"               ## [10] \"streamcats/streamcat_FirePerimetersRipBuf100_cat.parquet\""},{"path":"/articles/06-attribute-access.html","id":"summary","dir":"Articles","previous_headings":"3. Legacy of USGS based COMID data","what":"Summary","title":"Attribute Access and Creation","text":"NOAA-OWP/hydrofabric provides network subsetting function preloads number software tools critical enterprise effort reference fabric built NHDPlusV2 allows minimal, improved network can manipulate refactoring aggregation meet needs variety modeling tasks NHDPlusV2 current, just possible reference, however, NHDPlusV2 legacy data Web infrastructure available. NextGen data fabrics one form refactored/aggregated network extensions modeling application. “just” want use data created, Go based API (runs hydrofab::subset_network) available want make , tools available open also provide tools start enhancing data fabrics information helps guide scientific choices, model options, understanding","code":""},{"path":"/articles/07-channel-geometry.html","id":"a-ml-approach-to-estimate-channel-geometry","dir":"Articles","previous_headings":"","what":"A ML approach to estimate channel geometry","title":"Channel FHG - Machine Learning Model","text":"Check website provides details approach.","code":""},{"path":"/articles/07-channel-geometry.html","id":"what-is-fhg","dir":"Articles","previous_headings":"A ML approach to estimate channel geometry","what":"What is FHG?","title":"Channel FHG - Machine Learning Model","text":"feature hydraulic geometry (FHG) extension work Leopold Maddock, 1953 apply learned hydraulic geometry relations locations holistic hydrologic feature. hydraulic geometry relations suggest measured hydraulic characteristics channel cross-section including width, depth, velocity vary discharge simple power-law function. relations present opportunity develop time-varying representation channel depth width turn, can determine shape channel.","code":""},{"path":"/articles/07-channel-geometry.html","id":"why-build-a-machine-learning-model","dir":"Articles","previous_headings":"A ML approach to estimate channel geometry","what":"Why build a machine learning model?","title":"Channel FHG - Machine Learning Model","text":"Currently, Digital Elevation Model’s (DEM) can used extract floodplain topology DEMs penetrate deep water thus missing bathymetry bankfull bankfull conditions. missing bathymetry can modeling efforts accounting missing volume. hydraulic geometry method offers solution capture missing bathymetry resolve issue. Deriving hydraulic geometry relations possible measurements width, depth, velocity different discharge values selected USGS sites locations frequent measurements Acoustic Doppler Current Profiler (ADCP). great source dataset USGS HYDRoacoustic dataset support Surface Water Oceanographic Topography satellite mission HYDRoSWOT. limits applicability approach sites measurements taken place. Office Water Prediction (OWP), hand, mission provide 3D channel geometry dataset support Next Gen Water Modeling Framework Flood Inundation Mapping (FIM). requires 3D representation channel shape field measurements (.e., Lidar, HEC-RAS models, etc.) measurement Reaches across CONUS. Therefore, learn hydraulic geometry sites data available (HYDRoSWOT) using machine learning apply locations data. ML model able predict width, depth, velocity well simplified representation channel shape help reproduce missing bathymetry data data available.","code":""},{"path":[]},{"path":"/articles/07-channel-geometry.html","id":"cloning","dir":"Articles","previous_headings":"A ML approach to estimate channel geometry > Repository","what":"Cloning","title":"Channel FHG - Machine Learning Model","text":"","code":"git clone https://github.com/LynkerIntel/conus-fhg.git"},{"path":"/articles/07-channel-geometry.html","id":"example","dir":"Articles","previous_headings":"A ML approach to estimate channel geometry > Repository","what":"Example","title":"Channel FHG - Machine Learning Model","text":"can run model using following com../mand: : -c name running script generated folder outputs. name. -n number cores used parallel. integer depends number cores. Use -1 utilizing -x apply transformation predictor variables. Options True False -y apply transformation predicted variables. Options True False -r coefficient determination used filter bad measurements ADCP data. Ranges 0.0-1.0","code":"./run_ml.bash -c mymodel -n -1 -x False -y False -r 0.8"},{"path":"/articles/07-channel-geometry.html","id":"overview","dir":"Articles","previous_headings":"A ML approach to estimate channel geometry","what":"Overview","title":"Channel FHG - Machine Learning Model","text":"use USGS “HYDRoacoustic dataset support Surface Water Oceanographic Topography satellite” mission (HYDRoSWOT) : Build time-varying model -channel geometry represents width, depth channel given discharge value. can achieved modeling fitted feature hydraulic geometry (FHG) using climate, catchment, surface, subsurface characteristics. relations can described : TW = \\(. Q ^{b}\\) Y = \\(c . Q ^{f}\\) V = \\(k . Q ^{m}\\) Johnson et al, 2023 provided robust framework get best fits equations maintaining continuity relation. use fitted parameters study build ML model. representation curvature -channel shape DEM penetrate see channel bathymetry. can done using FHG coefficients namely f b related channel depth width relation discharge. According Ding../man (2007), given bankfull maximum depth Ym bankfull width W∗ known, channel cross-sections symmetrical, form can approximated Z = \\(Y_{m} ^{*} . \\big( \\frac{2}{W*} \\big) ^{r} . x^{r}, \\;\\;\\; 0 \\leq x \\leq \\frac{W*}{2}\\) z height bed lowest channel elevation (assumed occur channel center), x horizontal distance center. triangle represented r = 1, “Lane Type B stable channel” r ≈ 1.75, parabola r = 2, forms increasingly flatter bottoms steeper banks increasing values r; limit r → ∞, channel rectangular. Values r < 1 characterize “convex” cross-sections.","code":""},{"path":"/articles/07-channel-geometry.html","id":"input-data","dir":"Articles","previous_headings":"A ML approach to estimate channel geometry","what":"Input data","title":"Channel FHG - Machine Learning Model","text":"ML model establishes relation different attributes aggregated catchment local area FHG confidences namely , b, c, f, k, m. include 1- reference fabric data - streamorde –> Modified Strahler stream order - arbolatesu –> Arbolate sum, sum lengths digitized flowlines upstream downstream end immediate flowline, kilometers - roughness –> ../manning’s roughness - etc. 2- Soil data - clay_mean_0_5 –> % clay - ksat_mean_0_5 –> effective saturated hydraulic conductivity, (cm hr-1) - theta_s_mean_0_5 –> saturated soil water content, (cm3 cm-3) - etc. 3- DEM - elevation –> elevation (m) - slope –> slope - US NED Physiographic Diversity - etc. 4- StreamCat dataset - Base flow index - NLCD - Road density - etc. 5- Land surface features - Leaf area index - Soil moisture - NDVI - etc. 6- Climate data - Precipitation - Evaporation - Temperature - etc. 7- NWM simulations - NWM 2.1 quartiles - NWM 2.1 flood frequencies codes data preprocessing cleaning reside data_processing floder. Codes extracting data reside data_retrieval floder R folder. original cleaned data ML modeling data folder training data ML model Processed_merged_fhg.parquet data validation testing Processed_adcp.parquet.","code":""},{"path":[]},{"path":"/articles/07-channel-geometry.html","id":"reducing-feature-space","dir":"Articles","previous_headings":"A ML approach to estimate channel geometry > ML model","what":"Reducing feature space","title":"Channel FHG - Machine Learning Model","text":"step consists reducing large feature space ~400 variables 60 features. done multiple ways: 1- model trained using features dropping sigle least important feature loop retraining model reach peak model accuracy training. 2- remaining grouped meaningful clusters fed AutoEncoder model lower dimention data lunch autoencoder model navigate directory use com../mand begin autoencoding generating new features","code":"cd auto_encoder ./run_ae.bash"},{"path":"/articles/07-channel-geometry.html","id":"preventing-overfit","dir":"Articles","previous_headings":"A ML approach to estimate channel geometry > ML model","what":"Preventing overfit","title":"Channel FHG - Machine Learning Model","text":"done multiple steps: 1- Splitting training train validation early stopping model improvements validation accuracy. 2- Performing k-fold cross validation 3- Initial bag model evaluation form list 50 different ML models selecting top 10 models hyperparameter tunning 4- Ensamble learning including meta voting models 5- deep learning models also include dropout rates prevent overfitting","code":""},{"path":"/articles/07-channel-geometry.html","id":"ensemble-learning","dir":"Articles","previous_headings":"A ML approach to estimate channel geometry > ML model","what":"Ensemble learning","title":"Channel FHG - Machine Learning Model","text":"first stage box evaluation different models. models hyper parameters set default tuned evaluation means finding robust algorithms problem. output 3 different models namely, 1- best model top model among hyperparameter tuned chosen 8 ML models coming bag model evaluation 2- voting ensemble model build top chosen 8 ML models 3- meta learner model build top chosen 8 ML models","code":""},{"path":"/articles/07-channel-geometry.html","id":"results","dir":"Articles","previous_headings":"A ML approach to estimate channel geometry","what":"Results","title":"Channel FHG - Machine Learning Model","text":"compare model results ADCP measurements using multiple goodness--fit criteria.","code":""},{"path":"/articles/07-channel-geometry.html","id":"feature-importance","dir":"Articles","previous_headings":"A ML approach to estimate channel geometry > Results","what":"Feature importance","title":"Channel FHG - Machine Learning Model","text":"use tree algorithm based game theory determine XGBoost feature importance’s. also allows us look inner interactions variables. example low values long term averaged soil moister associate arid semi-arid regions see lot variability stream flow therefore high rate change river width.","code":""},{"path":"/articles/07-channel-geometry.html","id":"evaluation","dir":"Articles","previous_headings":"A ML approach to estimate channel geometry > Results","what":"Evaluation","title":"Channel FHG - Machine Learning Model","text":"can look different metrics including Normalized Nash-Sutcliffe efficiency (NNSE) check model performs terms predicting river velocity, depth, width different discharge measurements. image shows NNSE values station 50 measurements discharge-depth estimating depth(ft) using parameter f form FHG relations. can also look model parameter f perfor../mance predicting max flow: see error associated larger rivers model seen enough training due limited availbility HYDRoSWOT.","code":""},{"path":"/articles/07-channel-geometry.html","id":"channel-shape","dir":"Articles","previous_headings":"A ML approach to estimate channel geometry","what":"Channel Shape","title":"Channel FHG - Machine Learning Model","text":"Using parameters b f can derive r coefficient describes curvature channel looks like figure CONUS.","code":""},{"path":"/articles/08-nextgen-views.html","id":"tldr","dir":"Articles","previous_headings":"","what":"TL;DR","title":"Realizations and Views","text":"realization -> identification concepts view -> representation operations","code":""},{"path":"/articles/08-nextgen-views.html","id":"intro","dir":"Articles","previous_headings":"","what":"Intro","title":"Realizations and Views","text":"NextGen Hydrofabric Data Model aims support multi-realization view river network landscape using concepts outlined OGC HY Features Standard. data model proposing, enforcing, aimed allow flexible realizations minimal data /O. Defining principle realization, Storing multiple layers data self contained data format. Using opaque identifiers reference realizations hydrologic unit across layers NOTE: layers GPKG realizations hydrologic landscape. Ultimetly one principle realization defines principle unit (e.g. flowpath) hydrologic landscape per model application targeted. Moreover, one viewed realization - - one operated . .concpets definition view - outside HY Features spec - needed applying concrete representations abstract conceptual features. Fundamentally, way world digitally represented dictates types operations, inquires, analysis can done aligning aims analysis, view abstract hydrologic feature, critical efficiency.","code":""},{"path":"/articles/08-nextgen-views.html","id":"nextgen","dir":"Articles","previous_headings":"Intro","what":"NextGen","title":"Realizations and Views","text":"notion HY Feature ready hydrofabric requires ability access number realizations. distinct reference fabric intended support creation data products serve range modeling applications. current state, NextGen requires realizations model execution. currently includes, likely limited , following: , show hydrofabric data model supports tasks clear examples include derivation process. , show divides view comprehensive enough support tasks.","code":""},{"path":"/articles/08-nextgen-views.html","id":"background","dir":"Articles","previous_headings":"Intro","what":"Background","title":"Realizations and Views","text":"NextGen uses flowpath –> nexus topology. requirement aggregating divide complex desired spatial scale avoiding many:1 flowline divide relation. NOTE: possible upcoming work GID FIM, may relax constraint building flowline layer allow many:1 relationship higher resolution flowline network. step might also allow fp –> fp topology consistent core t-route. time, water flows flowpath nexus, one flowpath may contribute one nexus. need store many representations hydrologic landscape, spatial aspatial database challenge. spatial community, well established way store spatial aspatial data layers (tables) single database OGC GeoPackage Format. format provides standard spatial information top SQLite databases. hydrofabric identifiers prefixed make human-readable, parsed within code infer something . exception , may used quickly identify principle realization. R based libraries used example. Python language equivalents.","code":"library(sf)      # spatial data access and manipulation library(mapview) # interactive map creation library(arrow)   # parquet read/write library(dplyr)   # SQL syntax on data.frames  #> Some (R -> Python) equivalents for these packages are: #> - sf      -> geopandas/shapely/Fiona #> - map view -> folio #> - arrow   -> pyarrow #> - dplyr   -> pandas/polar"},{"path":"/articles/08-nextgen-views.html","id":"nextgen-principle-realization","dir":"Articles","previous_headings":"Intro","what":"NextGen Principle Realization","title":"Realizations and Views","text":"Due routing requirements NextGen (Task #3), connectivity flowpath network principle realization landscape thus primary realization hydrologic units. , flowpath identification given theid identifier. Anywhere id found HF Geo Package, reference principle realization - flowpaths. flexibility HY Features standard, implemented data model make possible consider hydrofabric different perspectives, one viewed realization operated . viewed realization essence application based abstraction principle realization. Selecting viewed realization must consider fundamental operations needed - just principle use case. example, flowpath realization principle realization, however need divide geometries forcing (likely rainfall runoff task) dictate divide view product operations. divide realization flowpaths uniquely identified divide_id. NOTE: ids unique. instances divide draining flowpath, thus divides corresponding id property equal NA. can removed using has_flowline boolean flag property desired, part dendritic system.","code":""},{"path":"/articles/08-nextgen-views.html","id":"build-a-subset","dir":"Articles","previous_headings":"Intro","what":"Build a subset","title":"Realizations and Views","text":"help example, create cutout Poudre River Basin using hydrofabric subsetter found extract sample CONUS NextGen Hydrofabric. basin defined upstream area NWIS location Gages=06752260. USGS Next Generation Monitoring Location Page site Geoconnex PID can found ","code":"mkdir poudre cd poudre  hfsubset -l divides,nexus,flowpaths, network,flowpath_attributes,hydrolocations \\          -o ./cihro-data/poudre.gpkg \\          -r \"pre-release\" \\          -t hl \\          \"Gages-06752260\""},{"path":"/articles/08-nextgen-views.html","id":"did-we-create-it","dir":"Articles","previous_headings":"Intro > Build a subset","what":"Did we create it?","title":"Realizations and Views","text":"","code":"(f = list.files(\"cihro-data\", pattern = \"poudre.gpkg\", full.names = TRUE)) ## [1] \"cihro-data/poudre.gpkg\""},{"path":"/articles/08-nextgen-views.html","id":"whats-in-it","dir":"Articles","previous_headings":"Intro > Build a subset","what":"What’s in it?","title":"Realizations and Views","text":"","code":"st_layers(f) ## Driver: GPKG  ## Available layers: ##            layer_name     geometry_type features fields ## 1             divides     Multi Polygon      419      9 ## 2               nexus             Point      171      5 ## 3           flowpaths Multi Line String      419     10 ## 4      hydrolocations             Point       26      6 ## 5               lakes             Point        2     17 ## 6             network                NA     1884     15 ## 7 flowpath_attributes                NA      419     16 ## 8        layer_styles                NA        5     12 ##                                    crs_name ## 1                      NAD83 / Conus Albers ## 2                      NAD83 / Conus Albers ## 3                      NAD83 / Conus Albers ## 4                      NAD83 / Conus Albers ## 5 Undefined Cartesian SRS with unknown unit ## 6                                      <NA> ## 7                                      <NA> ## 8                                      <NA>"},{"path":[]},{"path":"/articles/08-nextgen-views.html","id":"defining-the-network","dir":"Articles","previous_headings":"","what":"Defining the network","title":"Realizations and Views","text":"exhaustive realization set (e.g identification concepts) given network contained network layer. layer spatial information link flowpath, divide, nexus realizations contained within area. Notably, file carries full reference fabric, manipulation, data modeling steps. see “hf_source” (reference fabric) NHDPlusV2. resulting 1884 row table stores needed information 420 divides, 590 flowpaths 342 nexus walk back source hf needed, reduced set can extracted, example:","code":"(net = read_sf(f, \"network\")) ## # A tibble: 1,884 × 15 ##    id     toid  divide_id ds_id mainstem hl_id hydroseq hl_uri hf_source   hf_id ##    <chr>  <chr> <chr>     <dbl>    <int> <chr>    <int> <chr>  <chr>       <dbl> ##  1 wb-27… nex-… cat-2786…    NA   352913 788         NA HUC12… NA             NA ##  2 wb-27… nex-… cat-2786…    NA   352913 788      11238 HUC12… NHDPlusV2 2902759 ##  3 wb-27… nex-… cat-2786…    NA   352913 788      11238 HUC12… NHDPlusV2 2900301 ##  4 wb-27… nex-… cat-2786…    NA   352913 NA          NA NA     NA             NA ##  5 wb-27… nex-… cat-2786…    NA   352913 NA       11247 NA     NHDPlusV2 2900207 ##  6 wb-27… nex-… cat-2786…    NA   352913 NA       11247 NA     NHDPlusV2 2900099 ##  7 wb-27… nex-… cat-2786…    NA   352913 NA       11247 NA     NHDPlusV2 2900757 ##  8 wb-27… nex-… cat-2786…    NA   352913 NA       11247 NA     NHDPlusV2 2900047 ##  9 wb-27… nex-… cat-2786…    NA   352913 NA       11247 NA     NHDPlusV2 2900079 ## 10 wb-27… nex-… cat-2786…    NA   352913 NA          NA NA     NA             NA ## # ℹ 1,874 more rows ## # ℹ 5 more variables: lengthkm <dbl>, areasqkm <dbl>, ## #   tot_drainage_areasqkm <dbl>, type <chr>, vpu <chr> select(net, id, toid, divide_id, hl_uri, vpu, areasqkm) %>%    distinct() ## # A tibble: 606 × 6 ##    id        toid       divide_id  hl_uri             vpu   areasqkm ##    <chr>     <chr>      <chr>      <chr>              <chr>    <dbl> ##  1 wb-278673 nex-278674 cat-278673 HUC12-101900070201 10L      13.3  ##  2 wb-278675 nex-278676 cat-278675 NA                 10L       7.44 ##  3 wb-278676 nex-278677 cat-278676 NA                 10L       8.76 ##  4 wb-278679 nex-278680 cat-278679 NA                 10L       4.52 ##  5 wb-278680 nex-278681 cat-278680 NA                 10L       8.98 ##  6 wb-278681 nex-278682 cat-278681 NA                 10L       6.63 ##  7 wb-278682 nex-278683 cat-278682 NA                 10L      11.1  ##  8 wb-278683 nex-278684 cat-278683 NA                 10L       9.96 ##  9 wb-278684 nex-278685 cat-278684 NA                 10L       8.61 ## 10 wb-278686 nex-278687 cat-278686 NA                 10L      14.7  ## # ℹ 596 more rows"},{"path":"/articles/08-nextgen-views.html","id":"forcing-task-1","dir":"Articles","previous_headings":"","what":"Forcing (Task 1)","title":"Realizations and Views","text":"generate forcing mesh (currently using EMSF) forcing workstream needs divide complex geometries associated divide_id unit. can pulled directly divides layer!","code":"read_sf(f, \"divides\") %>%    select(divide_id) %>%    filter(divide_id %in% net$divide_id) ## Simple feature collection with 419 features and 1 field ## Geometry type: MULTIPOLYGON ## Dimension:     XY ## Bounding box:  xmin: -831675 ymin: 1975605 xmax: -759465 ymax: 2061555 ## Projected CRS: NAD83 / Conus Albers ## # A tibble: 419 × 2 ##    divide_id                                                                geom ##  * <chr>                                                      <MULTIPOLYGON [m]> ##  1 cat-280570 (((-774075 2005635, -774375 2005635, -774345 2005695, -774345 200… ##  2 cat-278676 (((-822075 1993095, -822105 1992825, -822195 1992765, -822375 199… ##  3 cat-278680 (((-818235 2004705, -818265 2004585, -818355 2004585, -818625 200… ##  4 cat-278682 (((-810375 2006985, -810285 2006865, -810015 2006865, -809925 200… ##  5 cat-278683 (((-807825 2008065, -807705 2008005, -807555 2007825, -807495 200… ##  6 cat-278686 (((-794235 2002185, -794295 2002125, -794535 2002125, -794655 200… ##  7 cat-278689 (((-787395 2000865, -787575 2000715, -787575 2000595, -787665 200… ##  8 cat-278692 (((-778785 2002215, -778755 2002395, -778695 2002485, -778695 200… ##  9 cat-278693 (((-773565 1998705, -773625 1998615, -773745 1998585, -773865 199… ## 10 cat-278695 (((-767055 1994895, -767055 1994775, -766965 1994685, -766935 199… ## # ℹ 409 more rows"},{"path":"/articles/08-nextgen-views.html","id":"rainfall-runoff-modeling-task-2","dir":"Articles","previous_headings":"","what":"Rainfall Runoff Modeling (Task 2)","title":"Realizations and Views","text":"NextGen rainfall runoff modeling tasks require ability identify unit divide complex, associated draining flowpath. , configuration files can used assign /build model formulations associated given divide_id. NextGen remains primarily lumped basin model, operating divide scale, divide view ideal viewed realization. However, since explicitly interested geometries , drop . NOTE: used SQLite directly access layer, rather reading complete layer sf, avoided reading geometry column entirely.","code":"read_sf(f, \"divides\") %>%   select(divide_id, id) %>%   st_drop_geometry() ## # A tibble: 419 × 2 ##    divide_id  id        ##  * <chr>      <chr>     ##  1 cat-280570 wb-280570 ##  2 cat-278676 wb-278676 ##  3 cat-278680 wb-278680 ##  4 cat-278682 wb-278682 ##  5 cat-278683 wb-278683 ##  6 cat-278686 wb-278686 ##  7 cat-278689 wb-278689 ##  8 cat-278692 wb-278692 ##  9 cat-278693 wb-278693 ## 10 cat-278695 wb-278695 ## # ℹ 409 more rows read_sf(f, query = \"SELECT divide_id, id FROM divides\") ## # A tibble: 419 × 2 ##    divide_id  id        ##    <chr>      <chr>     ##  1 cat-280570 wb-280570 ##  2 cat-278676 wb-278676 ##  3 cat-278680 wb-278680 ##  4 cat-278682 wb-278682 ##  5 cat-278683 wb-278683 ##  6 cat-278686 wb-278686 ##  7 cat-278689 wb-278689 ##  8 cat-278692 wb-278692 ##  9 cat-278693 wb-278693 ## 10 cat-278695 wb-278695 ## # ℹ 409 more rows"},{"path":"/articles/08-nextgen-views.html","id":"working-across-model-formulations","dir":"Articles","previous_headings":"Rainfall Runoff Modeling (Task 2)","what":"Working across model formulations","title":"Realizations and Views","text":"divides located, models assigned, often need populate configuration file pre-computed information. One example operating NOAH OWP Modular CFE models require suite divide-summarized data. data lives adjacent core hydrofabric GPKG’s can accessed using set divide_id(s). example, let’s say want CFE NOAH OWP data cat-280570, can use naming convention files, network based VPU distinction, general parquet/s3 access patterns.","code":"base = 's3://nextgen-hydrofabric/pre-release'  open_dataset(glue(\"{base}/nextgen_{unique(net$vpu)}_cfe_noahowp.parquet\")) %>%   filter(divide_id == \"cat-280570\") %>%   collect() ## # A tibble: 1 × 36 ##   divide_id  gw_Coeff gw_Zmax gw_Expon `bexp_soil_layers_stag=1` ##   <chr>         <dbl>   <dbl>    <dbl>                     <dbl> ## 1 cat-280570    0.005    10.9        7                      9.01 ## # ℹ 31 more variables: `bexp_soil_layers_stag=2` <dbl>, ## #   `bexp_soil_layers_stag=3` <dbl>, `bexp_soil_layers_stag=4` <dbl>, ## #   ISLTYP <int>, IVGTYP <int>, `dksat_soil_layers_stag=1` <dbl>, ## #   `dksat_soil_layers_stag=2` <dbl>, `dksat_soil_layers_stag=3` <dbl>, ## #   `dksat_soil_layers_stag=4` <dbl>, `psisat_soil_layers_stag=1` <dbl>, ## #   `psisat_soil_layers_stag=2` <dbl>, `psisat_soil_layers_stag=3` <dbl>, ## #   `psisat_soil_layers_stag=4` <dbl>, cwpvt <dbl>, mfsno <dbl>, mp <dbl>, …"},{"path":"/articles/08-nextgen-views.html","id":"routing-task-3","dir":"Articles","previous_headings":"","what":"Routing (Task 3)","title":"Realizations and Views","text":"Routing based flowpath nexus connection described background section requires water move flowpaths, nexuses, flowpaths. one flowpath can contribute nexus, however one nexus can contribute flowpath. hard requirement ngen network remains dendritic (e.g DAG). can ensure resultant flowpath topology, extracted divides view, compliant: Much like NOAH-OWP/CFE example, knowing connectivity flowpath network half challenge. successful route water , range attributes need supplied. Currently, provided within flowpath_attributes layer hydrofabric data model: id can used extract complete/partial flowpath view needed:","code":"library(igraph); library(visNetwork) ##  ## Attaching package: 'igraph' ## The following objects are masked from 'package:dplyr': ##  ##     as_data_frame, groups, union ## The following objects are masked from 'package:stats': ##  ##     decompose, spectrum ## The following object is masked from 'package:base': ##  ##     union g = select(net, id, toid) %>%     distinct() %>%      graph_from_data_frame(directed = TRUE)   is.dag(g) ## [1] TRUE visIgraph(g) read_sf(f, \"flowpath_attributes\") %>%   filter(id %in% unique(net$id)) ## # A tibble: 419 × 16 ##    id       rl_gages rl_NHDWaterbodyComID    Qi  MusK  MusX      n      So ChSlp ##    <chr>    <chr>    <chr>                <dbl> <dbl> <dbl>  <dbl>   <dbl> <dbl> ##  1 wb-2786… NA       NA                       0  3600   0.2 0.06   0.0197  0.517 ##  2 wb-2786… NA       NA                       0  3600   0.2 0.06   0.0214  0.438 ##  3 wb-2786… NA       NA                       0  3600   0.2 0.055  0.0167  0.402 ##  4 wb-2786… NA       NA                       0  3600   0.2 0.055  0.0193  0.365 ##  5 wb-2786… NA       NA                       0  3600   0.2 0.0563 0.0489  0.452 ##  6 wb-2786… NA       NA                       0  3600   0.2 0.055  0.0407  0.348 ##  7 wb-2786… NA       NA                       0  3600   0.2 0.055  0.0340  0.329 ##  8 wb-2786… NA       NA                       0  3600   0.2 0.055  0.0286  0.328 ##  9 wb-2786… NA       NA                       0  3600   0.2 0.0556 0.0148  0.459 ## 10 wb-2786… NA       NA                       0  3600   0.2 0.055  0.00464 0.316 ## # ℹ 409 more rows ## # ℹ 7 more variables: BtmWdth <dbl>, time <dbl>, Kchan <dbl>, nCC <dbl>, ## #   TopWdthCC <dbl>, TopWdth <dbl>, length_m <dbl> fp = read_sf(f, \"flowpaths\") %>%    filter(id == net$id[1])   div = read_sf(f, \"divides\") %>%    filter(divide_id == net$divide_id[1])  mapview(div) + fp"},{"path":"/articles/08-nextgen-views.html","id":"reporting-task-4","dir":"Articles","previous_headings":"","what":"Reporting (Task 4)","title":"Realizations and Views","text":"last task one well facilitated existing NWM find locations known Points Interest (POIs). example, lets say wanted find USGS gages present Poudre Basin. search hydrolocations view instances type Gages. total 15 gages Poudre River basin. want map , contributing flowpaths divides, simply need walk across layers:","code":"(gages = filter(net, grepl(\"Gages\", hl_uri))) ## # A tibble: 64 × 15 ##    id     toid  divide_id ds_id mainstem hl_id hydroseq hl_uri hf_source   hf_id ##    <chr>  <chr> <chr>     <dbl>    <int> <chr>    <int> <chr>  <chr>       <dbl> ##  1 wb-27… nex-… cat-2786…    NA   352913 4447        NA Gages… NA             NA ##  2 wb-27… nex-… cat-2786…    NA   352913 4447     11598 Gages… NHDPlusV2 2899479 ##  3 wb-27… nex-… cat-2786…    NA   352913 4447     11598 Gages… NHDPlusV2 2900683 ##  4 wb-27… nex-… cat-2786…    NA   352913 4447     11598 Gages… NHDPlusV2 2899495 ##  5 wb-27… nex-… cat-2786…    NA   352913 4447     11598 Gages… NHDPlusV2 2900705 ##  6 wb-27… nex-… cat-2786…    NA   352913 4447     11598 Gages… NHDPlusV2 2900709 ##  7 wb-28… nex-… cat-2805…    NA   376874 7845        NA Gages… NA             NA ##  8 wb-28… nex-… cat-2805…    NA   376874 7845     11527 Gages… NHDPlusV2 2898115 ##  9 wb-28… nex-… cat-2805…    NA   376874 7845     11527 Gages… NHDPlusV2 2898115 ## 10 wb-28… nex-… cat-2805…    NA   376874 7845     11527 Gages… NHDPlusV2 2898115 ## # ℹ 54 more rows ## # ℹ 5 more variables: lengthkm <dbl>, areasqkm <dbl>, ## #   tot_drainage_areasqkm <dbl>, type <chr>, vpu <chr> # Divides are indexed by divide_id (div = read_sf(f, \"divides\") %>%    filter(divide_id %in% gages$divide_id)) ## Simple feature collection with 13 features and 9 fields ## Geometry type: MULTIPOLYGON ## Dimension:     XY ## Bounding box:  xmin: -828975 ymin: 1987995 xmax: -759465 ymax: 2027385 ## Projected CRS: NAD83 / Conus Albers ## # A tibble: 13 × 10 ##    divide_id  toid     type  ds_id areasqkm id    lengthkm tot_drainage_areasqkm ##  * <chr>      <chr>    <chr> <dbl>    <dbl> <chr>    <dbl>                 <dbl> ##  1 cat-278693 nex-278… netw…    NA     8.55 wb-2…     7.47               2734.   ##  2 cat-296532 nex-280… netw…    NA     8.40 wb-2…     5.21                 23.5  ##  3 cat-307431 nex-280… netw…    NA     4.40 wb-3…     3.89                  4.40 ##  4 cat-307433 nex-280… netw…    NA    14.0  wb-3…     1.94                 14.0  ##  5 cat-280564 nex-280… netw…    NA     5.81 wb-2…     5.30                918.   ##  6 cat-280569 nex-280… netw…    NA     2.69 wb-2…     3.20               1395.   ##  7 cat-286396 nex-286… netw…    NA     6.35 wb-2…     5.34                240.   ##  8 cat-288037 nex-288… netw…    NA     6.88 wb-2…     2.64                 18.0  ##  9 cat-296529 nex-280… netw…    NA     4.38 wb-2…     3.45                 19.9  ## 10 cat-315473 nex-280… netw…    NA     4.36 wb-3…     2.23                  4.36 ## 11 cat-331488 nex-286… netw…    NA     3.38 wb-3…     2.72                  3.38 ## 12 cat-331480 nex-278… netw…    NA     3.10 wb-3…     3.40                  3.10 ## 13 cat-278698 nex-278… netw…    NA     6.67 wb-2…     1.89               2966.   ## # ℹ 2 more variables: has_flowline <int>, geom <MULTIPOLYGON [m]> # flowpaths are indexed by id (fps = read_sf(f, \"flowpaths\") %>%    filter(id %in% gages$id)) ## Simple feature collection with 13 features and 10 fields ## Geometry type: MULTILINESTRING ## Dimension:     XY ## Bounding box:  xmin: -828149.9 ymin: 1989138 xmax: -759847.8 ymax: 2026467 ## Projected CRS: NAD83 / Conus Albers ## # A tibble: 13 × 11 ##    id      toid  mainstem order hydroseq lengthkm areasqkm tot_drainage_areasqkm ##  * <chr>   <chr>    <int> <dbl>    <int>    <dbl>    <dbl>                 <dbl> ##  1 wb-278… nex-…   352913     5    11598     7.47     8.55               2734.   ##  2 wb-280… nex-…   376874     4    11527     5.30     5.81                918.   ##  3 wb-280… nex-…   376874     4    11586     3.20     2.69               1395.   ##  4 wb-286… nex-…   461512     3    11338     5.34     6.35                240.   ##  5 wb-288… nex-…   486535     2    11215     2.64     6.88                 18.0  ##  6 wb-296… nex-…   622759     2    11404     5.21     8.40                 23.5  ##  7 wb-307… nex-…   785921     1    11405     3.89     4.40                  4.40 ##  8 wb-296… nex-…   622754     2    11409     3.45     4.38                 19.9  ##  9 wb-315… nex-…   911271     1    11410     2.23     4.36                  4.36 ## 10 wb-307… nex-…   785928     1    11585     1.94    14.0                  14.0  ## 11 wb-331… nex-…  1223251     1    11337     2.72     3.38                  3.38 ## 12 wb-331… nex-…  1223233     1    11597     3.40     3.10                  3.10 ## 13 wb-278… nex-…   352913     5    11627     1.89     6.67               2966.   ## # ℹ 3 more variables: has_divide <int>, divide_id <chr>, ## #   geom <MULTILINESTRING [m]> # Nexus locations are indexed by toid (hl = read_sf(f, \"nexus\") %>%    filter(id %in% gages$toid)) ## Simple feature collection with 6 features and 5 fields ## Geometry type: POINT ## Dimension:     XY ## Bounding box:  xmin: -826682 ymin: 1989138 xmax: -760037.4 ymax: 2023777 ## Projected CRS: NAD83 / Conus Albers ## # A tibble: 6 × 6 ##   id         toid      hl_id hl_uri              type                 geom ## * <chr>      <chr>     <chr> <chr>               <chr>         <POINT [m]> ## 1 nex-278694 wb-278694 4447  Gages-06752000      poi   (-771344.1 1998680) ## 2 nex-278699 wb-278699 8118  Gages-06752260      poi   (-760037.4 1989138) ## 3 nex-280565 wb-280565 7845  HUC12-101900070701… poi     (-779224 2023777) ## 4 nex-280570 wb-280570 8150  Gages-06751490      poi   (-773201.3 2012891) ## 5 nex-286397 wb-286397 7908  Gages-06748600      poi   (-794801.3 1999190) ## 6 nex-288038 wb-288038 8198  Gages-06746110      poi     (-826682 1992863) mapview() + hl + div + fps"},{"path":"/articles/08-nextgen-views.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Realizations and Views","text":"many layers presented hydrofabric, views can extracted combination network layer, “viewed” layer . supplies everything needed run ngen start finish, allow introspection results! able clear implementation HY Features concepts, within detailed yet flexible data model. Taking advantage requires understanding : principle view data set flowpath network due topology requirements ngen t-route. means flowpaths nexus locations uniquely identified id, divides uniquely identified divide_id. viewing divide “view” data still provides ability access flowpath nexus realizations identifiers, auxiliary data can built relation appropriate realization (e.g. id, divide_id) providing ability larger data system scaffold.","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"/articles/data.html","id":"examples","dir":"Articles","previous_headings":"","what":"Examples","title":"Cloud Native Hydrofabric Data","text":"","code":"# CONUS Network Parquet s3://lynker-spatial/hydrofabric/{version}/{type}/{domain}_network   # Model Attributes s3://lynker-spatial/hydrofabric/{version}/{type}/{domain}s_model-attributes/"},{"path":"/articles/data.html","id":"syncing-to-local","dir":"Articles","previous_headings":"","what":"Syncing to Local","title":"Cloud Native Hydrofabric Data","text":"AWS CLI tools can used sync remote s3 directory local archive ensuring local data date remote, assuming want work locally. current v2.2/reference directory 3.0 GB current v2.1.1/nextgen directory 8.0 GB","code":"local   <- \"/Users/mjohnson/hydrofabric\" s3      <- \"s3://lynker-spatial/hydrofabric\" version <-  'v2.1.1' type    <- \"nextgen\" domain  <- \"conus\"  (sys <- glue::glue(\"aws s3 sync {s3}/{version}/{type} {local}/{version}/{type}\")) #> aws s3 sync s3://lynker-spatial/hydrofabric/v2.1.1/nextgen /Users/mjohnson/hydrofabric/v2.1.1/nextgen"},{"path":"/articles/data.html","id":"interactive-viewer-v2-1-1nextgen","dir":"Articles","previous_headings":"","what":"Interactive Viewer (v2.1.1/nextgen)","title":"Cloud Native Hydrofabric Data","text":"","code":"#> Warning in doTryCatch(return(expr), name, parentenv, handler): NAs introduced #> by coercion"},{"path":"/articles/devcon2024-background.html","id":"background","dir":"Articles","previous_headings":"","what":"Background","title":"Background","text":"Last year, shared concept hydrofabric current NextGen data structures. hydrofabric describes landscape flow network discretizations, essential connectivity network features, key reporting locations known nexus points. Combined feature serve geospatail computational elements allow NextGen modeling infrastructure syncronious different models, formulations, domains cohert simulation set outputs.","code":""},{"path":"/articles/devcon2024-background.html","id":"key-highlights","dir":"Articles","previous_headings":"Background","what":"Key Highlights","title":"Background","text":"Design Philosophy: adopt OGC HY Feature conceptual model custom modifications NextGen applications define explicit data model. fundamental data model evolving mode delevery tailored modeling web infrastructure applications, emphasizing efficiency accuracy use modern geospatial data science formats. included seven spatial two -spatial layers, future plans additional layer water bodies cross sections. NOAA enterprise hydrofabric made 5 modular components, touched today. include seen : Enterprise Hydrofabric System NHGF: core, federally consistent data product grounded common topology, reference fabric, set community POIs. Collectively, define shared NOAA/USGS National Hydrologic Geospatial Fabric (NHGF). Network Manipulation: -depth exploration two network manipulation processes, refactoring aggregating, crucial optimizing data usage. Egress Free Community Hydrofabric Data: Lynker-Spatial provide efficient, free access hydrofabric hydrofabric-adjacent data. last year, system ~78,500 requests 2,306 unique IPs month month trend nearing exponential. Data Subsetting: demonstrated methods extract data subsets multi-scale modeling tasks using R Go-based CLI. Since , R version underlying data stores overhauled, CLI implementation transitioned (beta) REST API, Python implementation forthcoming. Enriching hydrofabric: core hydrofabric respects data model demontrated hoe enhance te addtioon catchment attributes (precomputed custom), flowpath attributes, forcing weights. Since , partnership ESIP extended climateR catalog host access endpoints 100,000 unique data resources, developed e machine learning models estimating river bathymety roughness, tools extract high resolution bathymetry informed ross sections, applid across CONUS - provided egress free cloud resources!","code":""},{"path":"/articles/devcon2024-background.html","id":"software","dir":"Articles","previous_headings":"Background","what":"Software","title":"Background","text":"primary output system constantly evolving FAIR, cloud native, data products complete services, predicated suite research (hydrofab) publication ready (nhdplusTools, climateR) software. suite software bundled together NOAA-OWP/hydrofabric provides collection R packages designed hydroscience data development access. packages share underlying design philosophy, grammar, data structures, making easier apply together. packages cover wide range data manipulation tasks, importing cleaning data, building custom hydrofabrics, accessing summarizing data 100,000’s data resources. Assuming already running R, RStudio, hydrofabric, can attach library working session: library(hydrofabric) load core packages (alphabetical): climateR accessing federated data stores parameter attributes estimation hfsubsetR cloud-based hydrofabric subsetting hydrofab tool set “fabricating” multiscale hydrofabrics ngen.hydrofab NextGen extensions hydrofab nhdplusTools network manipulation zonal catchment parameter estimation Additionally load key geospatial data science libraries: dplyr (data.frames) sf (vector) terra (raster)","code":"library(hydrofabric)"},{"path":"/articles/devcon2024-background.html","id":"benefits-of-using-hydrofabric","dir":"Articles","previous_headings":"Background > Software","what":"Benefits of Using hydrofabric","title":"Background","text":"Consistency: Packages designed work seamlessly together - Lynker-Spatial data stores - making workflows efficient. Readability: Syntax designed human-readable expressive, helps writing clean understandable code. Efficiency: Functions optimized performance, making data manipulation tasks faster.","code":""},{"path":"/articles/devcon2024-background.html","id":"lynker-spatial-data","dir":"Articles","previous_headings":"Background","what":"Lynker-Spatial Data","title":"Background","text":"Hydrofabric artifacts generated set federally consistent reference datasets built collaboration NOAA, USGS, Lynker federal water modeling efforts. artifacts designed easily updated, manipulated, quality controlled meet needs wide range modeling tasks leveraging best possible input data. Cloud-native (modified structure format) artifacts refactored aggregated, NextGen ready resources publicly available lynker-spatial ODbL license. use data, please ensure (1) Attribute Lynker-Spatial, (2) keep data open, (3) works produced data offer adapted database ODbL. Hydrofabric data lynker-spatial follows general s3 URI pattern access: : source local s3 location version release number (e.g. v2.2) type type fabric (e.g. reference, nextgen, etc) domain region interest (e.g. conus, hawaii, alaska) layer layer hydrofabric (e.g. divides, flowlines, network, attributes, etc.)","code":"\"{source}/{version}/{type}/{domain}_{layer}\""},{"path":"/articles/devcon2024-background.html","id":"high-level-technical-overview","dir":"Articles","previous_headings":"","what":"High level Technical Overview","title":"Background","text":"provide context data formats technology rely toe help make data FAIR, easy use, ","code":""},{"path":"/articles/devcon2024-background.html","id":"data-storage","dir":"Articles","previous_headings":"High level Technical Overview","what":"Data Storage","title":"Background","text":"use s3 (via aws) storage easy sync locally, access remotely. design data structure makes versioning easier track, offer parity local remote access:","code":"version <- \"v2.2\" type <- \"reference\" domain <- \"conus\"  local_source <- \"/Users/mjohnson/hydrofabric\" s3_source <- \"s3://lynker-spatial/hydrofabric\"  # Sync s3 with your local archive (glue(\"aws s3 sync {s3_source}/{version}/{type} {local_source}/{version}/{type}\")) ## aws s3 sync s3://lynker-spatial/hydrofabric/v2.2/reference /Users/mjohnson/hydrofabric/v2.2/reference"},{"path":[]},{"path":"/articles/devcon2024-background.html","id":"gpkg","dir":"Articles","previous_headings":"High level Technical Overview > Data Formats","what":"GPKG","title":"Background","text":"Geopackages/SQLITE open, standards-based, platform-independent, data format spatial . designed universal format geospatial data storage, enabling sharing exchange spatial data across different systems software.","code":"gpkg <- \"tutorial/poudre.gpkg\"  # See Layers st_layers(gpkg) ## Driver: GPKG  ## Available layers: ##   layer_name geometry_type features fields             crs_name ## 1    divides       Polygon     1122      5 NAD83 / Conus Albers ## 2  flowlines   Line String     1129     19 NAD83 / Conus Albers ## 3    network            NA     1145     23                 <NA> # Read Complete Layer (divides = read_sf(gpkg, \"divides\")) ## Simple feature collection with 1122 features and 5 fields ## Geometry type: POLYGON ## Dimension:     XY ## Bounding box:  xmin: -831675 ymin: 1975605 xmax: -757545 ymax: 2061555 ## Projected CRS: NAD83 / Conus Albers ## # A tibble: 1,122 × 6 ##    divide_id areasqkm has_flowline      id vpuid                            geom ##        <dbl>    <dbl> <lgl>          <dbl> <chr>                   <POLYGON [m]> ##  1   2896607   10.2   TRUE         2896607 10L   ((-779895 2037405, -779835 203… ##  2   2896609    5.08  TRUE         2896609 10L   ((-777075 2041155, -777255 204… ##  3   2897621    0.806 TRUE         2897621 10L   ((-789255 2035395, -789255 203… ##  4   2897627    2.52  TRUE         2897627 10L   ((-802665 2036685, -802755 203… ##  5   2897631    3.23  TRUE         2897631 10L   ((-796005 2034945, -795855 203… ##  6   2897671    1.42  TRUE         2897671 10L   ((-780525 2033175, -780435 203… ##  7   2897731    1.78  TRUE         2897731 10L   ((-776655 2032545, -776775 203… ##  8   2897785    2.93  TRUE         2897785 10L   ((-774765 2032095, -774855 203… ##  9   2897855    1.44  TRUE         2897855 10L   ((-783765 2029515, -783735 202… ## 10   2897893    2.86  TRUE         2897893 10L   ((-774105 2028195, -773985 202… ## # ℹ 1,112 more rows"},{"path":"/articles/devcon2024-background.html","id":"arrowparquet","dir":"Articles","previous_headings":"High level Technical Overview > Data Formats","what":"Arrow/Parquet","title":"Background","text":"Apache Arrow open-source project provides columnar memory format flat hierarchical data. proviees fast data transfer processing across different programming languages platforms without needing serialize deserialize data, making particularly useful big data high-performance applications. (geo)parquet disc data format storing columar data. GeoParquet emerging standard storing geospatial data within Apache Parquet file format. Parquet columnar storage file format highly efficient storage retrieval, particularly suited big data analytics applications. distribute hydrofabric layers VPU-based hive partitioned (geo)parquet stores. can accessed lynker-spatial, , synced (see ) local directory. Hive partitioning partitioning strategy used split table multiple files based partition keys. files organized folders. complete v2.2/reference/ directory ~3.0GB v2.1.1/nextgen dirctory ~ 9.0GB (including xs, flowpath/model attributes, forcing weights routelink)","code":""},{"path":"/articles/devcon2024-background.html","id":"parquet-store","dir":"Articles","previous_headings":"High level Technical Overview > Data Formats > Arrow/Parquet","what":"Parquet store","title":"Background","text":"","code":"(x <- glue(\"{local_source}/{version}/{type}/{domain}_network\")) ## /Users/mjohnson/hydrofabric/v2.2/reference/conus_network (x2 <- open_dataset(x)) ## FileSystemDataset with 22 Parquet files ## divide_id: double ## areasqkm: double ## id: double ## toid: double ## terminalpa: double ## mainstemlp: double ## reachcode: string ## frommeas: double ## tomeas: double ## lengthkm: double ## streamorde: double ## totdasqkm: double ## hydroseq: double ## dnhydroseq: double ## outlet_X: double ## outlet_Y: double ## hf_id: double ## topo: string ## poi_id: int32 ## hl_link: string ## hl_reference: string ## hl_uri: string ## vpuid: string glimpse(x2) ## FileSystemDataset with 22 Parquet files ## 2,691,455 rows x 23 columns ## $ divide_id    <double> 869, 881, 885, 897, 899, 903, 905, 907, 911, 923, 925, 9… ## $ areasqkm     <double> 9.8500444, 2.3957955, 3.7908014, 0.8784026, 3.7737083, 1… ## $ id           <double> 869, 881, 885, 897, 899, 903, 905, 907, 911, 923, 925, 9… ## $ toid         <double> 1277, 1383, 1281, 1415, 1371, 901, 909, 1403, 929, 933, … ## $ terminalpa   <double> 1815586, 1815586, 1815586, 1815586, 1815586, 1815586, 18… ## $ mainstemlp   <double> 1819868, 1820217, 1819864, 1820207, 1820178, 1819352, 18… ## $ reachcode    <string> \"01020003000346\", \"01020003000574\", \"01020003000149\", \"0… ## $ frommeas     <double> 0.00000, 0.00000, 0.00000, 0.00000, 2.07552, 0.00000, 0.… ## $ tomeas       <double> 100.00000, 100.00000, 100.00000, 100.00000, 100.00000, 5… ## $ lengthkm     <double> 6.2446074, 1.9348602, 4.5941482, 1.1105714, 2.1912820, 1… ## $ streamorde   <double> 1, 1, 2, 2, 1, 3, 1, 3, 3, 1, 1, 2, 1, 1, 1, 3, 1, 3, 1,… ## $ totdasqkm    <double> 9.8379, 5.5125, 32.8410, 4.7736, 3.7440, 46.1160, 4.8789… ## $ hydroseq     <double> 1819868, 1820218, 1819864, 1820208, 1820179, 1820188, 18… ## $ dnhydroseq   <double> 1819867, 1820217, 1819863, 1820207, 1820178, 1820185, 18… ## $ outlet_X     <double> 2122874, 2106010, 2123427, 2101033, 2107853, 2105622, 21… ## $ outlet_Y     <double> 2890039, 2884833, 2889282, 2881567, 2885469, 2882792, 28… ## $ hf_id        <double> 869, 881, 885, 897, 899, 903, 905, 907, 911, 923, 925, 9… ## $ topo         <string> \"fl-fl\", \"fl-fl\", \"fl-fl\", \"fl-fl\", \"fl-fl\", \"fl-fl\", \"f… ## $ poi_id        <int32> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4, NA, NA, N… ## $ hl_link      <string> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"01020003010… ## $ hl_reference <string> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"HUC12\", NA,… ## $ hl_uri       <string> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"HUC12-01020… ## $ vpuid        <string> \"01\", \"01\", \"01\", \"01\", \"01\", \"01\", \"01\", \"01\", \"01\", \"0… # > Remote parity > # open_dataset(glue('{s3_source}/{version}/{type}/{domain}_network/'))"},{"path":"/articles/devcon2024-background.html","id":"geoparquet-store","dir":"Articles","previous_headings":"High level Technical Overview > Data Formats > Arrow/Parquet","what":"Geoparquet store","title":"Background","text":"","code":"(x <- glue(\"{local_source}/{version}/{type}/{domain}_divides\")) ## /Users/mjohnson/hydrofabric/v2.2/reference/conus_divides open_dataset(x) ## FileSystemDataset with 21 Parquet files ## divide_id: double ## areasqkm: double ## geom: binary ## has_flowline: bool ## id: double ## vpuid: string ##  ## See $metadata for additional Schema metadata # > Renote parity > # arrow::open_dataset(glue::glue('{s3_source}/{version}/{type}/conus_divides'))"},{"path":"/articles/devcon2024-background.html","id":"parquet-schema","dir":"Articles","previous_headings":"High level Technical Overview > Data Formats","what":"Parquet Schema","title":"Background","text":"pqrs library offers command line tool inspecting Parquet files","code":"pqrs schema /Users/mjohnson/hydrofabric/v2.2/reference/conus_flowlines/vpuid=01/part-0.parquet"},{"path":"/articles/devcon2024-background.html","id":"virtual-access-to-gridded-data-primary-cog-netcdf-zarr","dir":"Articles","previous_headings":"High level Technical Overview > Data Formats","what":"Virtual Access to Gridded Data (Primary COG, NetCDF, Zarr)","title":"Background","text":"amount gridded data needed suite supported applications (let alone) - GDAL VSI","code":"\"/vsis3/lynker-spatial/gridded-resources/medium_range.forcing.tif\" |>     dap(AOI = divides) |>     plot()"},{"path":"/articles/devcon2024-background.html","id":"lazy-evaluation","dir":"Articles","previous_headings":"High level Technical Overview","what":"Lazy Evaluation","title":"Background","text":"datasets distributed domain level (e.g. conus, hawaii, alaska). Lazy evaluation can help get just data need, memory local remote locations.","code":""},{"path":"/articles/devcon2024-background.html","id":"local-gpkg","dir":"Articles","previous_headings":"High level Technical Overview > Lazy Evaluation","what":"Local GPKG","title":"Background","text":"","code":"as_sqlite(gpkg, \"divides\") %>%     filter(divide_id == 2896607) ## # Source:   SQL [1 x 7] ## # Database: sqlite 3.45.2 [/Users/mjohnson/github/hydrofabric/vignettes/tutorial/poudre.gpkg] ##     fid          geom divide_id areasqkm has_flowline      id vpuid ##   <int>        <blob>     <dbl>    <dbl>        <int>   <dbl> <chr> ## 1     1 <raw 2.21 kB>   2896607     10.2            1 2896607 10L as_sqlite(gpkg, \"divides\") %>%     filter(divide_id == 2896607) %>%     read_sf_dataset_sqlite() ## Simple feature collection with 1 feature and 6 fields ## Geometry type: POLYGON ## Dimension:     XY ## Bounding box:  xmin: -780615 ymin: 2037165 xmax: -777075 ymax: 2044425 ## Projected CRS: NAD83 / Conus Albers ## # A tibble: 1 × 7 ##     fid                        geom divide_id areasqkm has_flowline     id vpuid ## * <int>               <POLYGON [m]>     <dbl>    <dbl>        <int>  <dbl> <chr> ## 1     1 ((-779895 2037405, -779835…   2896607     10.2            1 2.90e6 10L"},{"path":"/articles/devcon2024-background.html","id":"localremote-parquet-store","dir":"Articles","previous_headings":"High level Technical Overview > Lazy Evaluation","what":"Local/Remote Parquet Store","title":"Background","text":"","code":"open_dataset(glue(\"{local_source}/{version}/{type}/conus_network/\")) %>%     filter(id == 101) %>%     select(id, toid) %>%     collect() ## # A tibble: 1 × 2 ##      id    toid ##   <dbl>   <dbl> ## 1   101 1078719 # > # arrow::open_dataset(glue::glue('{s3_source}/{version}/{type}/conus_network/')) # %>% > dplyr::filter(id == 101) %>% > dplyr::select(id, # toid) %>% > dplyr::collect()"},{"path":"/articles/devcon2024-background.html","id":"extracting-a-vpu","dir":"Articles","previous_headings":"","what":"Extracting a VPU","title":"Background","text":"Last year highlighted system built largely around VPU level gpkgs. longer distribute files, utility function hfsubsetR::get_vpu_fabric extract VPU level GPKG outfile choice.","code":"get_vpu_fabric(\"01\", type = \"reference\", hf_version = \"2.2\",     outfile = \"/Users/mjohnson/Downloads/01_ref_2.2.gpkg\") ## [1] \"/Users/mjohnson/Downloads/01_ref_2.2.gpkg\""},{"path":"/articles/devcon2024-background.html","id":"oconus-domains","dir":"Articles","previous_headings":"","what":"oCONUS domains","title":"Background","text":"slowly building oCONIS (Ontario, HI, PRVI, AK) domains. become avaialble, logic apply. example get Hawaii divides:","code":"open_dataset(glue(\"{local_source}/{version}/{type}/hawaii_flowlines\")) %>%     read_sf_dataset() %>%     mapview::mapview()"},{"path":"/articles/devcon2024-setup.html","id":"do-you-already-have-r-installed","dir":"Articles","previous_headings":"","what":"Do you already have R installed?","title":"Getting Started","text":"older versions R/RStudio installed, recommend updating. can check version R running typing version console RStudio. check RStudio version Windows, click RStudio menu option Help menu. check Mac, click RStudio menu option RStudio menu. don’t least R 4.4.XXX RStudio 2023.6.0.XXXX. suggest upgrading.","code":"version$version.string ## [1] \"R version 4.4.0 (2024-04-24)\""},{"path":"/articles/devcon2024-setup.html","id":"getting-r-and-rstudio","dir":"Articles","previous_headings":"","what":"1. Getting R and RStudio","title":"Getting Started","text":"R programming language free software environment statistical computing graphics supported R Foundation Statistical Computing. R language widely used developing statistical software data analysis. R also provides unparalleled opportunities analyzing spatial data spatial modeling. RStudio integrated development environment (IDE) R. Combined R language RStudio IDE provide open-source, free, toolset course.","code":""},{"path":[]},{"path":"/articles/devcon2024-setup.html","id":"install-r","dir":"Articles","previous_headings":"1. Getting R and RStudio > MacOS Install","what":"Install R","title":"Getting Started","text":"Download latest release (“R-version.pkg”) R save .pkg file. Double-click open, follow installation instructions. Note different version Intel chip (e.g. R-4.1.0.pkg) Apple M1 chip (e.g. R-4.1.0-arm64.pkg) Now R installed, can download install RStudio.","code":""},{"path":"/articles/devcon2024-setup.html","id":"install-rstudio","dir":"Articles","previous_headings":"1. Getting R and RStudio > MacOS Install","what":"Install RStudio","title":"Getting Started","text":"Download RStudio Mac. downloading, double-click file open , make sure ends applications folder.","code":""},{"path":[]},{"path":"/articles/devcon2024-setup.html","id":"install-r-1","dir":"Articles","previous_headings":"1. Getting R and RStudio > Windows Install","what":"Install R","title":"Getting Started","text":"Download latest R installer (.exe) Windows. Install downloaded file windows app. Now R installed, can download install RStudio.","code":""},{"path":"/articles/devcon2024-setup.html","id":"install-rstudio-1","dir":"Articles","previous_headings":"1. Getting R and RStudio > Windows Install","what":"Install RStudio","title":"Getting Started","text":"Download RStudio version Windows. Run installer (.exe file) follow instructions.","code":""},{"path":"/articles/devcon2024-setup.html","id":"launch-rstudio","dir":"Articles","previous_headings":"","what":"2. Launch RStudio","title":"Getting Started","text":"R RStudio installed, can find click RStudio icon open program. RStudio icon looks like :  Opening RStudio launch workplace. something like image appears , set!  spend session working IDE layout features become clear go. things note now : session linked project (pink box). Environment tab shows active objects session files tab shows files folders default (project) workplace plots tab show graphs start visualizing data. red window write code open new/existing scripts markdown files. output printed console (yellow box). Code prompts can directly entered console saved executing. layout theme may look like (elements arranged differently). want change theme layout got RStudio –> Preferences. can adjust “Appearance” “Pane Layout”. want look like mine, see :","code":""},{"path":"/articles/devcon2024-setup.html","id":"install-noaa-owphydrofabric","dir":"Articles","previous_headings":"","what":"3. Install NOAA-OWP/hydrofabric","title":"Getting Started","text":"R comes loaded many base packages tools. also many additional tools make life easier. Throughout session, ’ll use packages exist aggregate hydrofabric package. hydrofabric contains collection useful packages play nicely together data exploration, manipulation, wrangling visualization (among things). Packages can installed CRAN (Comprehensive R Archive Network) using following pattern typed console (yellow box): development package (yay DevCon!) can installed Github using remotes package (installed ): ’s installed, can ensure everything worked loading/attaching hydrofabric libray using library call: got something similar ’ve successfully installed R, RStudio, hydrofabric package! really want make sure ready, ensure get TRUE :","code":"install.packages('powerjoin') install.packages(\"remotes\") remotes::install_github(\"NOAA-OWP/hydrofabric\") library(hydrofabric) ## ── Attaching packages ───────────────────────────────────── hydrofabric 0.1.0 ── ## ✔ dplyr         1.1.4      ✔ hfsubsetR     0.0.9  ## ✔ climateR      0.3.5      ✔ ngen.hydrofab 0.0.4  ## ✔ nhdplusTools  1.2.0      ✔ sf            1.0.17 ## ✔ hydrofab      0.5.2      ✔ terra         1.7.78 ## ✔ zonal         0.0.3 ## ── Conflicts ──────────────────────────────────────── hydrofabric_conflicts() ── ## ✖ dplyr::group_rows() masks kableExtra::group_rows() ## ✖ terra::plot()       masks climateR::plot() ##  ## Attaching package: 'hydrofabric' ## The following objects are masked _by_ 'package:hydrofab': ##  ##     append_style, hf_dm hydrofabric_packages() %in% rownames(installed.packages()) ##  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [16] TRUE TRUE"},{"path":"/articles/devcon2024-setup.html","id":"quick-r-notes","dir":"Articles","previous_headings":"3. Install NOAA-OWP/hydrofabric","what":"Quick R Notes","title":"Getting Started","text":"","code":"## NOTE: What is glue? x <- \"Welcome to DevCon\" y <- \"2024\" z <- c('2023', '2024', '2025', '...')  # single string glue(\"{x} {y}\") ## Welcome to DevCon 2024 # multiple strings from vectors glue(\"{x} {z}\") ## Welcome to DevCon 2023 ## Welcome to DevCon 2024 ## Welcome to DevCon 2025 ## Welcome to DevCon ... ?read_hydrofabric"},{"path":"/articles/devcon2024-setup.html","id":"visit-lynker-spatial","dir":"Articles","previous_headings":"","what":"4. Visit Lynker Spatial","title":"Getting Started","text":"Lynker spatial provides open data software services aimed improving user experience hydrofabric allowing rapid access, subsetting, integration cloud native resources. Lynker-spatial Data offerings hydrofabric can found Lynker-spatial Services typically provided Github . ’s suggested install latest version hfsubsetCLI release page specific operation system.","code":""},{"path":"/articles/devcon2024-setup.html","id":"optional-review-technical-background","dir":"Articles","previous_headings":"","what":"5. (Optional) Review Technical Background","title":"Getting Started","text":"interested technical tools use, structured, application please review Background document. talk session, familiarity help move (quickly) .","code":""},{"path":"/articles/devcon2024-setup.html","id":"optional-install-qgis","dir":"Articles","previous_headings":"","what":"6. (Optional) Install QGIS","title":"Getting Started","text":"QGIS free open-source geographic information system (GIS) software allows users visualize, analyze, manage spatial data. can install binaries system directly website. using following package managers.","code":""},{"path":"/articles/devcon2024-setup.html","id":"macos","dir":"Articles","previous_headings":"6. (Optional) Install QGIS","what":"MacOS","title":"Getting Started","text":"","code":"brew install qgis"},{"path":"/articles/devcon2024-setup.html","id":"ubuntudebian","dir":"Articles","previous_headings":"6. (Optional) Install QGIS","what":"Ubuntu/Debian","title":"Getting Started","text":"","code":"sudo apt update sudo apt install qgis"},{"path":"/articles/devcon2024-tutorial.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting Started","title":"End to End Hydrofabric Workflows","text":"","code":"# Install ----------------------------------------------------------------- # install.packages(\"remotes\")  # install.packages(\"powerjoin\")  remotes::install_github(\"NOAA-OWP/hydrofabric\")"},{"path":"/articles/devcon2024-tutorial.html","id":"attach-package","dir":"Articles","previous_headings":"Getting Started","what":"Attach Package","title":"End to End Hydrofabric Workflows","text":"","code":"library(hydrofabric) library(powerjoin) # helper function to use throughout tutorial make_map = function(file, pois) {   hf = read_hydrofabric(file)   mapview::mapview(hf$catchments) + hf$flowpaths + pois }  ### ---- Sample out files and source for today ---- ### fs::dir_create(\"tutorial\")  source    <- '/Users/mjohnson/hydrofabric/'  reference_file  <- \"tutorial/poudre.gpkg\" refactored_file <- \"tutorial/refactored.gpkg\" aggregated_file <- \"tutorial/aggregated.gpkg\"  nextgen_file       <- \"tutorial/poudre_ng.gpkg\" model_atts_file    <- \"tutorial/poudre_ng_attributes.parquet\" model_weights_file <- \"tutorial/poudre_ng_weights.parquet\""},{"path":[]},{"path":"/articles/devcon2024-tutorial.html","id":"get-reference-fabric-subsetting","dir":"Articles","previous_headings":"Building a NextGen Hydrofabric","what":"Get Reference Fabric (subsetting)","title":"End to End Hydrofabric Workflows","text":"example, want prepare NextGen hydrofabric associated products area upstream NWIS 06752260 sits Cache La Poudre River Fort Collins, Colorado. Feel free use particular location desire (relevant subsetting tools), ’ve set Lynker-Spatial Hydrolocation Viewer make finding appropriate starting reference point interest (POI) easier POI define downstream point network, ’ll need pull save (subset) reaches drain point order collect network needed model domain. lynker-spatial hydrolocation inventory subset superset community POI set. Meaning, use subset community POIs, add selection needed NextGen modeling. include (limited ) NWS LIDs, Coastal/Terrestrail interactions, NWM reservoirs lakes, coastal gages, ! focus R-based subsetter (hfsubsetR) integrates hydrofabric packages , also provide CLI tool calledhfsubsetCLI (beta) REST API. Python implementation also forthcoming. can learn subsetting tools/options !","code":"## ---  Define starting feature by source and ID ## https://waterdata.usgs.gov/monitoring-location/06752260 ## https://reference.geoconnex.us/collections/gages/items?provider_id=06752260 # Use get_subset to build a reference subset  get_subset(   hl_uri = \"Gages-06752260\",   source  = using_local_example,   type = \"reference\",   hf_version = \"2.2\",   lyrs = c(\"divides\", \"flowlines\", \"network\"),   outfile = reference_file,   overwrite = TRUE ) st_layers(reference_file) ## Driver: GPKG  ## Available layers: ##   layer_name geometry_type features fields             crs_name ## 1    divides       Polygon     1122      5 NAD83 / Conus Albers ## 2  flowlines   Line String     1129     19 NAD83 / Conus Albers ## 3    network            NA     1145     23                 <NA>"},{"path":"/articles/devcon2024-tutorial.html","id":"get-some-points-of-interest","dir":"Articles","previous_headings":"Building a NextGen Hydrofabric","what":"Get some Points of Interest","title":"End to End Hydrofabric Workflows","text":"many locations network (e.g. dams, gages, etc.) want ensure preserved network manipulation. means matter fabric refactored aggregated, key hydrolocations persist. critical ensuring cross dataset interoperability, consistent data streams assimilation model coupling, persistent nexus locations. example well read hydrolocations community POI set (GFv20), convert spatial points keep within reference subset domain.","code":"hf = read_hydrofabric(reference_file)  pois = open_dataset(glue(\"{source}/v2.2/conus_hl\")) %>%   filter(hl_source == 'GFv20',           vpuid %in% unique(hf$flowpaths$vpuid),          hf_id %in% hf$flowpaths$id) %>%   collect() %>%   st_as_sf(coords = c(\"X\", \"Y\"), crs = 5070) make_map(reference_file, pois)"},{"path":"/articles/devcon2024-tutorial.html","id":"build-a-refactored-fabric","dir":"Articles","previous_headings":"Building a NextGen Hydrofabric","what":"Build a Refactored Fabric","title":"End to End Hydrofabric Workflows","text":"reference network provides minimal discretization landscape river network offered system. Derived traditional cartographic product, need remove small river segments short stable routing calculations split long narrow catchments long flow paths. process known refactoring describe detail refactoring section ","code":"refactored = refactor(   reference_file,   split_flines_meters = 10000,   collapse_flines_meters = 1000,   collapse_flines_main_meters = 1000,   pois = pois,   fac = '/vsis3/lynker-spatial/gridded-resources/fac.vrt',   fdr = '/vsis3/lynker-spatial/gridded-resources/fdr.vrt',   outfile = refactored_file ) make_map(refactored_file, pois)"},{"path":"/articles/devcon2024-tutorial.html","id":"build-an-aggregated-network","dir":"Articles","previous_headings":"Building a NextGen Hydrofabric","what":"Build an Aggregated Network","title":"End to End Hydrofabric Workflows","text":"next set steps run aggregation tools refactored network. process aggregating Uniform Distribution. first step remap hydrolocations enforces refactored fabric. refactor execution hydrofabric::refactor lookup table produced relates original hydrofabric IDs new identifiers became. quick join can provide mapping hydrolocations refactored network. Passing aggregate_* functions ensure aggregated processing.","code":"hydrolocations = read_sf(refactored_file, 'lookup_table') %>%   inner_join(pois, by = c(\"NHDPlusV2_COMID\" = \"hf_id\")) %>%   select(poi_id, NHDPlusV2_COMID, id = reconciled_ID) %>%   distinct()  head(hydrolocations) ## # A tibble: 6 × 3 ##   poi_id NHDPlusV2_COMID    id ##    <int>           <dbl> <int> ## 1  37345         2899997     2 ## 2  37014         2899553    10 ## 3  36913         2900669    15 ## 4  36920         2900581    24 ## 5  36914         2900571    28 ## 6  36664         2898115    44 aggregate_to_distribution(   gpkg = refactored_file,   hydrolocations = hydrolocations,   ideal_size_sqkm = 10,   min_length_km = 1,   min_area_sqkm = 3,   outfile = aggregated_file,   overwrite = TRUE ) make_map(aggregated_file, pois)"},{"path":"/articles/devcon2024-tutorial.html","id":"generate-a-nextgen-network","dir":"Articles","previous_headings":"Building a NextGen Hydrofabric","what":"Generate a NextGen Network","title":"End to End Hydrofabric Workflows","text":"order make hydrofabric compliant NextGen flowline--nexus topology mapping, ’ll run following aggregated network. ! minimal set information needed NextGen hydrofabric!","code":"unlink(nextgen_file) apply_nexus_topology(aggregated_file, export_gpkg = nextgen_file) ## [1] \"tutorial/poudre_ng.gpkg\" hf = read_hydrofabric(nextgen_file)                        make_map(nextgen_file, read_sf(nextgen_file, \"nexus\"))"},{"path":"/articles/devcon2024-tutorial.html","id":"enriching-the-network-divides","dir":"Articles","previous_headings":"","what":"Enriching the Network: Divides","title":"End to End Hydrofabric Workflows","text":"lot divide level information can useful running hydrologic models, training validating machine learning models (e.g. LSTM, roughness, 3D hydrofabric). sort data typically includes things like soil type, average basin slope, land cover. Divide level spatial information needs summarized one unit divide level one following ways: Grid –> POLYGON (appropriate grid cell weighting) Smaller POLYGON –> Bigger POLYGON Bigger POLYGON –> Smaller POLYGON easiest way accomplish use use use climateR package access data, zonal rapidly summarize gridded data POLYGON scale. core components NOAA-OWP/hydrofabric meta package already loaded! summarizations can simple deriving mean value, complex user-defined summaries. highlight walk steps needed build divide-level data needed run CFE, NOM, PET, generate forcing’s.","code":""},{"path":"/articles/devcon2024-tutorial.html","id":"derive-the-divide-level-data-needed-for-cfenompet","dir":"Articles","previous_headings":"Enriching the Network: Divides","what":"Derive the divide-level data needed for CFE/NOM/PET","title":"End to End Hydrofabric Workflows","text":"start, define principle lynker-spatial gridded resources end point, extract divides nextgen_file:","code":"vsi <- \"/vsis3/lynker-spatial/gridded-resources\" div <- read_sf(nextgen_file, \"divides\")"},{"path":"/articles/devcon2024-tutorial.html","id":"noah-owp-varibables","dir":"Articles","previous_headings":"Enriching the Network: Divides","what":"NOAH OWP Varibables","title":"End to End Hydrofabric Workflows","text":"used NWM data ’ll know data distributed NetCDF domain files packed unconventionally, lacks spatial information, optimized piecemeal access. , relevant layers extracted turned Cloud Optimized GeoTiffs (COG) distributed egress free. ’ll demonstrate different ways can summerise next example. grid –> POLYGON summaries utilize mode, mean, geometric mean summaries.","code":"# Desired variables nom_vars <- c(\"bexp\", \"dksat\", \"psisat\", \"smcmax\", \"smcwlt\")  # Each of these is four layers, we only want the top layer of each r = rast(glue(\"{vsi}/nwm/conus/{nom_vars}.tif\"), lyrs = seq(1,length(nom_vars)*4, by = 4))  # Get Mode Beta parameter modes = execute_zonal(r[[1]],                      fun = mode,                     div, ID = \"divide_id\",                      join = FALSE)  %>%      setNames(gsub(\"fun.\", \"\", names(.)))  # Get Geometric Mean of Saturated soil hydraulic conductivity, and matric potential gm = execute_zonal(r[[2:3]],                      fun = geometric_mean,                     div, ID = \"divide_id\",                      join = FALSE)  %>%      setNames(gsub(\"fun.\", \"\", names(.)))  # Get Mean Saturated value of soil moisture and Wilting point soil moisture m = execute_zonal(r[[4:5]],                      fun = \"mean\",                     div, ID = \"divide_id\",                      join = FALSE)  %>%      setNames(gsub(\"mean.\", \"\", names(.)))  # Merge all tables into one d1 <- power_full_join(list(modes, gm, m),  by = \"divide_id\")"},{"path":"/articles/devcon2024-tutorial.html","id":"gw-routing-parameters","dir":"Articles","previous_headings":"","what":"GW Routing Parameters","title":"End to End Hydrofabric Workflows","text":"Aspects base model formulations include representation groundwater discharge/baseflow simulation require parameters characterize bucket models. include Coeff bucket model coefficient, Expon bucket model exponent, Zmax conceptual maximum depth bucket. GW data stored conus_routelink parquet store (sourced GWBUCKPARM_CONUS_FullRouting.nc latest NWM). assumption area reference features substituted NHDPlus based GWBUCKPARM_CONUS_FullRouting.nc variables. Given nature divide restructuring, acceptable generalization. POLYGON –> POLYGON summaries area weight respective values NHDPlus scale aggregated NextGen network. NOTE lazy join prior data collection!","code":"crosswalk <- as_sqlite(nextgen_file, \"network\") |>     select(hf_id, divide_id) |>     collect()  d2 <- open_dataset(glue(\"{source}/v2.2/reference/conus_routelink\")) |>     select(hf_id , starts_with(\"gw_\")) |>     inner_join(mutate(crosswalk, hf_id = as.integer(hf_id)), by = \"hf_id\") |>     group_by(divide_id) |>     collect() |>     summarize(       gw_Coeff = round(weighted.mean(gw_Coeff, w = gw_Area_sqkm, na.rm = TRUE), 9),       gw_Zmax_mm  = round(weighted.mean(gw_Zmax_mm,  w = gw_Area_sqkm, na.rm = TRUE), 9),       gw_Expon = mode(floor(gw_Expon))     )"},{"path":"/articles/devcon2024-tutorial.html","id":"forcing-downscaling-base-data","dir":"Articles","previous_headings":"GW Routing Parameters","what":"Forcing Downscaling Base Data","title":"End to End Hydrofabric Workflows","text":"Outside populating model formulations, key catchment attributes required replicate forcing engine implemented WRF-Hydro NWM models. hydrofabric provides means downscale data using attributes like catchment centroid, mean elevation slope, circular mean aspect.","code":""},{"path":"/articles/devcon2024-tutorial.html","id":"centroid","dir":"Articles","previous_headings":"GW Routing Parameters > Forcing Downscaling Base Data","what":"Centroid","title":"End to End Hydrofabric Workflows","text":"","code":"d3 <- st_centroid(div) |>   st_transform(4326) |>   st_coordinates() |>   data.frame() |>   mutate(divide_id = div$divide_id)"},{"path":"/articles/devcon2024-tutorial.html","id":"elevation-derived-inputs","dir":"Articles","previous_headings":"GW Routing Parameters > Forcing Downscaling Base Data","what":"Elevation derived inputs","title":"End to End Hydrofabric Workflows","text":"","code":"dem_vars <- c(\"elev\", \"slope\", \"aspect\")  r  <- rast(glue('{vsi}/250m_grids/usgs_250m_{dem_vars}.tif'))  d4 <- execute_zonal(r[[1:2]],                      div, ID = \"divide_id\",                      join = FALSE) |>     setNames(c(\"divide_id\", \"elevation_mean\", \" slope\"))  d5 <- execute_zonal(r[[3]],                       div, ID = \"divide_id\", fun = circular_mean,                       join = FALSE) |>     setNames(c(\"divide_id\", \"aspect_c_mean\")) model_attributes <- power_full_join(list(d1, d2, d3, d4, d5), by = \"divide_id\")"},{"path":"/articles/devcon2024-tutorial.html","id":"forcing-weight-grids","dir":"Articles","previous_headings":"GW Routing Parameters","what":"Forcing Weight Grids","title":"End to End Hydrofabric Workflows","text":"Tools like CIROH ngen-datastream NextGen Box use divide level information downscale data NWM forcing grid, leverage precomputed weights summarize forcing information divide level timestep. efficient manner requires pointing template grid (medium_range.forcing) executing weight_grid function zonal compute percentage cell covered divide. template grid one structure (cell resolution, grid spacing etc.), input data, important. NOTE: using pre generated network, forcing weights subsetable layer subseting tools (e.g {source}/{version}/{type}/{domain}_forcing-weights). can also generated fly REST API queried subset (see docs).","code":"type = \"medium_range.forcing\"  w = weight_grid(rast(glue('{vsi}/{type}.tif')), div, ID = \"divide_id\") |>    mutate(grid_id = type)  head(w)"},{"path":"/articles/devcon2024-tutorial.html","id":"writing-the-data-to-external-files","dir":"Articles","previous_headings":"GW Routing Parameters","what":"Writing the Data to External Files","title":"End to End Hydrofabric Workflows","text":"divide level attribute data forcing weights can written sidecar parquet files hosted alongside nextgen_file GPKG. combination three files ensures basic information needed execute NGIAB simulation. Now ’s easy plugging generated data files NextGen Datastream run NextGen simulation. Checkout “NextGen Simulation Development Tools” tomorrow 1:30 PM room 6619 see action! , primary key divide_id can used relate, join, parse files.","code":"write_parquet(model_attributes, model_atts_file) write_parquet(w, model_weights_file)"},{"path":"/articles/devcon2024-tutorial.html","id":"enriching-the-network-flowpaths","dir":"Articles","previous_headings":"","what":"Enriching the Network: Flowpaths","title":"End to End Hydrofabric Workflows","text":"still experimental, one newest data sets building support hydraulic hydrologic routing methods enhanced FIM support representation channel shape (3D Hydrofabric). finish tutorial ’ll demonstrate access cross section data add flowpath attributes nextgen_file. documentation coming soon related derivation, use, manipulation ; sneak peak, feel free check related background open source software used generate training data published JOSS , machine learning methods used estimating reach level roughness, channel bankfull channel properties.","code":""},{"path":"/articles/devcon2024-tutorial.html","id":"machine-learned-channel-properties","dir":"Articles","previous_headings":"Enriching the Network: Flowpaths","what":"Machine Learned Channel Properties","title":"End to End Hydrofabric Workflows","text":"ML properties estimated using wide range geospatial inputs NWM flow frequencies. estimated reference fabric can accessed conus_routelink parquet store following patterns used {source}/{version}/{type}/{domain}_{layer}. ’ll demonstrate find attributes associated downstream (max hydroseq) POI NextGen file: defined bankfull width, depth r coefficient, can use AHGestimation (part NOAA-OWP/hydrofabric core elaborated ) derive symmetric cross section based foundations Station Hydraulic Geometry (AHG) representations:","code":"crosswalk <- as_sqlite(nextgen_file, \"network\") |>     select(hf_id, hydroseq, poi_id) |>     filter(!is.na(poi_id)) %>%      collect() %>%      slice_max(hydroseq)  # Available ML outputs open_dataset(glue(\"{source}/v2.2/reference/conus_routelink/\")) |>     select(hf_id, starts_with(\"ml_\")) ## FileSystemDataset (query) ## hf_id: int32 ## ml_tw_inchan_m: double ## ml_tw_bf_m: double ## ml_y_inchan_m: double ## ml_y_bf_m: double ## ml_ahg_c: double ## ml_ahg_f: double ## ml_ahg_a: double ## ml_ahg_b: double ## ml_ahg_k: double ## ml_ahg_m: double ## ml_r: double ## ml_bf_channel_area_m2: double ## ml_inchan_channel_area_m2: double ## ml_bf_channel_perimeter_m: double ## ml_inchan_channel_perimeter_m: double ## ml_roughness: double ## ml_hf_source: string ##  ## See $.data for the source Arrow object # Get the cross section for the most downstream POI (cs <- open_dataset(glue(\"{source}/v2.2/reference/conus_routelink/\")) |>     select(hf_id, ml_y_bf_m, ml_tw_bf_m, ml_r) %>%      inner_join(mutate(crosswalk, hf_id = as.integer(hf_id)), by = \"hf_id\") |>     collect() %>%      summarise(TW = mean(ml_tw_bf_m),               r = mean(ml_r),               Y = mean(ml_y_bf_m),               poi_id = poi_id[1])) ## # A tibble: 1 × 4 ##      TW     r     Y poi_id ##   <dbl> <dbl> <dbl> <chr>  ## 1  37.9  24.1  1.39 37014 #remotes::install_github(\"mikejohnson51/AHGestimation\")  bathy = AHGestimation::cross_section(r = cs$r, TW = cs$TW, Ymax = cs$Y)   plot(bathy$x, bathy$Y, type = \"l\",       ylab = \"Releative distance (m)\",       xlab = \"Depth (m)\",       main = glue(\"Average XS at POI: {cs$poi_id}\"))"},{"path":"/articles/devcon2024-tutorial.html","id":"extacting-cross-sections","dir":"Articles","previous_headings":"","what":"Extacting Cross Sections:","title":"End to End Hydrofabric Workflows","text":"Cross sections derived NextGen hydrofabric v2.1.1 (identical v20.1 except restructuring cloud native structure). Cross sections created three steps creating transects perpendicular reference flowlines extended edges 100yr floodplains. 2. DEM elevations extracted along transect locations classified left/right bank, channel, channel bottom ML injected bathymetry (XSml) ensured monotonically decreasing along mainstem junction locations. , stage-varying cross sectional areas, flowpath slopes, wetted perimeter, critical hydraulic parameters can estimated hydro-referenced, interoporable, lightweight dataset can scale reference derived product.","code":"# install.packages(\"plotly\") library(plotly)  crosswalk <- as_sqlite(nextgen_file, \"network\") |>     select(hf_id, id, toid, divide_id, hydroseq, poi_id) |>     collect() %>%      slice_max(hydroseq)  cw = open_dataset(glue('{source}/v2.1.1/nextgen/conus_network')) %>%    semi_join(crosswalk, by = \"hf_id\") %>%    collect()   message(sum(cw$lengthkm), \" kilometers of river\")  (xs = open_dataset(glue('{source}/v2.1.1/nextgen/conus_xs'))) ## FileSystemDataset with 21 Parquet files ## hf_id: string ## cs_id: int32 ## pt_id: int32 ## relative_distance: double ## cs_lengthm: double ## class: string ## point_type: string ## X: double ## Y: double ## Z: double ## Z_source: large_string ## vpuid: string filter(xs, vpuid %in% unique(cw$vpuid), hf_id %in% unique(cw$id)) %>%    group_by(hf_id, cs_id) %>%    collect() %>%    mutate(uid = cur_group_id()) %>%    plot_ly(x = ~X, y = ~Y, z = ~Z,  split = ~as.factor(uid),           type = 'scatter3d', mode = 'markers+lines',           line = list(width = 3), marker = list(size = 2)) %>%    layout(list(aspectmode='manual',               aspectratio = list(x=100, y=100, z=1)),               showlegend = FALSE)"},{"path":"/articles/devcon2024-tutorial.html","id":"populate-flowpath-attributes","dir":"Articles","previous_headings":"","what":"Populate Flowpath Attributes","title":"End to End Hydrofabric Workflows","text":"Slowly ML enhanced DEM-based cross sections used supplement national Routelink file (conus_routelink) complete routing attributes need t-route WRF-Hydro / NWM execute. striving implement routelink file reference fabric level meaning can expended derived product. , length average contribution reference flowline aggregated flowpath needs calculated. can done following way:","code":"add_flowpath_attributes(nextgen_file, source = source) ## [1] \"tutorial/poudre_ng.gpkg\" # Data as_sqlite(nextgen_file, 'flowpath_attributes') %>%    collect() %>%    head() ## # A tibble: 6 × 13 ##     fid id     rl_Qi_m3s rl_MusX   rl_n  rl_So rl_ChSlp rl_BtmWdth_m ##   <int> <chr>      <dbl>   <dbl>  <dbl>  <dbl>    <dbl>        <dbl> ## 1     1 wb-1           0     0.2 0.06   0.0197    0.517         3.91 ## 2     2 wb-10          0     0.2 0.0565 0.0481    0.420         9.14 ## 3     3 wb-100         0     0.2 0.06   0.0971    0.641         2.33 ## 4     4 wb-101         0     0.2 0.06   0.064     0.634         2.39 ## 5     5 wb-102         0     0.2 0.06   0.0726    0.628         2.45 ## 6     6 wb-103         0     0.2 0.06   0.0552    0.679         2.05 ## # ℹ 5 more variables: rl_Kchan_mmhr <dbl>, rl_nCC <dbl>, rl_TopWdthCC_m <dbl>, ## #   rl_TopWdth_m <dbl>, length_m <dbl>"},{"path":"/articles/devcon2024-tutorial.html","id":"adding-gpkg-symbology","dir":"Articles","previous_headings":"","what":"Adding GPKG Symbology","title":"End to End Hydrofabric Workflows","text":"group geographers, feel maps important tired random hodge-podge symbologies created QGIS. , final (optional) touch add symbology layers (QML) generated GPKG append_style function! Let’s open QGIS see final product!  ready experiment, derive, access enriched hydrofabics!","code":"append_style(nextgen_file, layer_names = c(\"divides\", \"flowpaths\", \"nexus\")) ## [1] \"tutorial/poudre_ng.gpkg\""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Mike Johnson. Author, maintainer. . Funder. . Funder. . Funder.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Johnson, J. M. (2022). National Hydrologic Geospatial Fabric (hydrofabric) Next Generation (NextGen) Hydrologic Modeling Framework, HydroShare, http://www.hydroshare.org/resource/129787b468aa4d55ace7b124ed27dbde","code":"@Manual{R-hydrofabric,   title = {National Hydrologic Geospatial Fabric (hydrofabric) for the Next Generation (NextGen) Hydrologic Modeling Framework [software]},   author = {J. Michael Johnson},   year = {2024},   url = {https://www.hydroshare.org/resource/129787b468aa4d55ace7b124ed27dbde}, }"},{"path":"/index.html","id":"hydrofabric-for-next-generation-water-resource-modeling","dir":"","previous_headings":"","what":"Hydrofabric for Next Generation Water Resource Modeling","title":"NOAA's Enterprise Hydrofabric Solution","text":"development repository serves main purposes. Hydrofabric processes intentionally modular. package provides collection R package designed hydroscience. (e.g. tidyverse hydrofabric development) Contains utilites needed manipulating enhancing hydrographic networks. provides utilities subset national dataset regions upstream location (XY), hydrofabric ID, indexed hydrolocation (e.g. NWIS gage, HUC12 NID) NHDPlus COMID. provides wide range documentation including hydrofabric cross section data model, origins development product can found landing page articles.","code":""},{"path":"/index.html","id":"cloud-native-data-archives","dir":"","previous_headings":"","what":"Cloud Native Data Archives","title":"NOAA's Enterprise Hydrofabric Solution","text":"NextGen artifacts generated set national reference datasets built collaboration NOAA, USGS, Lynker federal water modeling efforts. artifacts designed easily updated, manipulated, quality controlled meet needs wide range modeling tasks leveraging best possible input data. NextGen artifacts publicly available lynker-spatial ODbL license. use data, please ensure (1) Attribute Lynker-Spatial, (2) Keep data open, (3) works produced data offer adapted database ODbL.","code":""},{"path":"/index.html","id":"package-installation-and-use","dir":"","previous_headings":"","what":"NOAA's Enterprise Hydrofabric Solution","title":"NOAA's Enterprise Hydrofabric Solution","text":"library(hydrofabric) load core packages (alphabetical): climateR accessing federated data stores parameter attributes estimation hfsubsetR cloud-based hydrofabric subsetting hydrofab tool set “fabricating” multiscale hydrofabrics ngen.hydrofab NextGen extensions hydrofab nhdplusTools network manipulation zonal catchment parameter estimation Additionally load key geospatial data science libraries: dplyr (data.frames) sf (vector) terra (raster)","code":"# install.packages(\"remotes\") remotes::install_github(\"NOAA-OWP/hydrofabric\") library(hydrofabric) ## ── Attaching packages ───────────────────────────────────────────────────────── hydrofabric 0.0.9 ──  ## ✔ dplyr        1.1.4      ✔ zonal        0.0.2  ## ✔ climateR     0.3.5      ✔ hfsubsetR    0.0.9  ## ✔ nhdplusTools 1.1.0      ✔ sf           1.0.17 ## ✔ hydrofab     0.5.2      ✔ terra        1.7.71  ## ── Conflicts ──────────────────────────────────────────────────────────── hydrofabric_conflicts() ── ## ✖ terra::plot() masks climateR::plot()  ##  ## Attaching package: 'hydrofabric'  ## The following objects are masked _by_ 'package:hydrofab': ##  ##     append_style, hf_dm"},{"path":"/index.html","id":"subsetting","dir":"","previous_headings":"","what":"Subsetting","title":"NOAA's Enterprise Hydrofabric Solution","text":"also created CLI cloud based subsetter. Binaries can installed release page. NOTE: Python Implementation coming soon!","code":"# The output directory o = \"vignettes/tutorial/example.gpkg\"  # Build subset hfsubsetR::get_subset(comid = 101, outfile = o, overwrite = FALSE) ## Warning in hfsubsetR::get_subset(comid = 101, outfile = o, overwrite = FALSE): ## vignettes/tutorial/example.gpkg already exists and overwrite is FALSE  ## [1] \"vignettes/tutorial/example.gpkg\""},{"path":"/index.html","id":"hydrofabric-characteristic-data","dir":"","previous_headings":"","what":"Hydrofabric Characteristic Data","title":"NOAA's Enterprise Hydrofabric Solution","text":"wide range data can appended hydrofabric (subsets) resources including NOAA core modules, streamcat, hydroatlas, USGS catchment characteristics, . Preliminary documentation can found . Additionally, open source tools like climateR zonal can used rapidly access summarize data catchment set:","code":"# Read Hydrofabric hf = read_hydrofabric(o)  # Get Daymet Data (tmax = getDaymet(hf$catchments, varname = \"tmax\", startDate = \"2020-10-01\")) ## $tmax ## class       : SpatRaster  ## dimensions  : 21, 19, 1  (nrow, ncol, nlyr) ## resolution  : 1000, 1000  (x, y) ## extent      : 480250, 499250, -1202500, -1181500  (xmin, xmax, ymin, ymax) ## coord. ref. : +proj=lcc +lat_0=42.5 +lon_0=-100 +lat_1=25 +lat_2=60 +x_0=0 +y_0=0 +ellps=WGS84 +units=m +no_defs  ## source(s)   : memory ## name        : tmax_2020-10-01_na_total  ## min value   :                    32.83  ## max value   :                    33.79  ## unit        :                degrees C  ## time        : 2020-10-01 UTC (summary_stats = zonal::execute_zonal(tmax, hf$catchments, ID = \"divide_id\")) ## Simple feature collection with 35 features and 4 fields ## Geometry type: POLYGON ## Dimension:     XY ## Bounding box:  xmin: 113055 ymin: 890715 xmax: 130425 ymax: 911055 ## Projected CRS: NAD83 / Conus Albers ## First 10 features: ##    divide_id areasqkm vpuid mean.tmax_2020.10.01_na_total                           geom ## 1        101   4.5666    12                      33.49731 POLYGON ((130305 890715, 13... ## 2    1078473  12.3156    12                      33.17984 POLYGON ((120345 900615, 12... ## 3    1078475  12.3408    12                      33.21740 POLYGON ((117855 903975, 11... ## 4    1078513   6.4449    12                      33.66863 POLYGON ((114645 895815, 11... ## 5    1078519   1.9197    12                      33.69756 POLYGON ((115515 895755, 11... ## 6    1078525   0.3789    12                      33.70147 POLYGON ((115965 895215, 11... ## 7    1078527   0.3312    12                      33.72665 POLYGON ((114735 895485, 11... ## 8    1078535   0.3582    12                      33.70396 POLYGON ((116445 895155, 11... ## 9    1078545   0.2862    12                      33.70000 POLYGON ((116445 894735, 11... ## 10   1078549   4.6296    12                      33.60812 POLYGON ((117675 894825, 11..."},{"path":"/index.html","id":"background","dir":"","previous_headings":"","what":"Background","title":"NOAA's Enterprise Hydrofabric Solution","text":"NextGen artifacts model application dataset built meet aims NextGen. design, artifacts derived set general authoritative data products outlined figure 1 built close collaboration USGS. Enterprise Hydrofabric System include set base data improves network topology geometry validity defining set community hydrolocations (POIs). 4 data products used build intermediate refactored network one hydrofabric network aggregated set community hydrolocations (minimal network), one aggregated consistent size (3-10 sqkm) enforced POI locations (target distribution). NextGen specifically derived target size aggregated product upcoming developments National Hydrologic Model (NHM) built community minimal network. two aggregations serve wide range federal modeling needs, focus open source software development workflows allow interested parties build networks starting either 4 reference datasets, refactored network!","code":""},{"path":"/index.html","id":"resources","dir":"","previous_headings":"","what":"Resources","title":"NOAA's Enterprise Hydrofabric Solution","text":"hydrofabric builds OGC HY_Features conceptual model, Hydrofabric Logical model, proposed Hydrofabric Data Model. high level introduction resources can found USGS Water Data blog.","code":""},{"path":"/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"NOAA's Enterprise Hydrofabric Solution","text":"Please cite data use : Johnson, J. M. (2022). National Hydrologic Geospatial Fabric (hydrofabric) Next Generation (NextGen) Hydrologic Modeling Framework, HydroShare, http://www.hydroshare.org/resource/129787b468aa4d55ace7b124ed27dbde","code":""},{"path":"/index.html","id":"questions","dir":"","previous_headings":"","what":"Questions:","title":"NOAA's Enterprise Hydrofabric Solution","text":"Mike Johnson (Hydrofabric Lead)  Disclaimer: data preliminary provisional subject revision. provided meet need timely best science. data received final approval National Oceanic Atmospheric Administration (NOAA) U.S. Geological Survey (USGS) provided condition U.S. Government shall held liable damages resulting use data.","code":""},{"path":"/reference/add_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Enhance Hydrofabric Network — add_parameters","title":"Enhance Hydrofabric Network — add_parameters","text":"Enhance Hydrofabric Network","code":""},{"path":"/reference/add_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enhance Hydrofabric Network — add_parameters","text":"","code":"add_parameters(   gpkg = NULL,   lyrs = c(\"forcing_weights\", \"model_attributes\"),   base_s3 = \"s3://lynker-spatial/v20.1\" )"},{"path":"/reference/add_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enhance Hydrofabric Network — add_parameters","text":"gpkg hydrofabric id (relevant nextgen fabrics) lyrs layers extract. Default \"forcing_weights\" \"model_attributes\" base_s3 base hydrofabric directory access Lynker's s3","code":""},{"path":"/reference/add_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Enhance Hydrofabric Network — add_parameters","text":"file path gpkg","code":""},{"path":"/reference/append_style.html","id":null,"dir":"Reference","previous_headings":"","what":"Append style to GPKG — append_style","title":"Append style to GPKG — append_style","text":"Append style GPKG","code":""},{"path":"/reference/append_style.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Append style to GPKG — append_style","text":"","code":"append_style(   gpkg_path,   qml_dir = system.file(\"qml\", package = \"hydrofabric\"),   layer_names )"},{"path":"/reference/append_style.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Append style to GPKG — append_style","text":"gpkg_path GPKG path qml_dir Directory path layer_names layer names populate","code":""},{"path":"/reference/append_style.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Append style to GPKG — append_style","text":"gpkg path","code":""},{"path":"/reference/area_length_filter.html","id":null,"dir":"Reference","previous_headings":"","what":"Area Length Thresholds — area_length_filter","title":"Area Length Thresholds — area_length_filter","text":"Area Length Thresholds","code":""},{"path":"/reference/area_length_filter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Area Length Thresholds — area_length_filter","text":"","code":"area_length_filter(   tmap,   gpkg,   areasqkm = NULL,   pathlengthkm = NULL,   ms_pathlengthkm = NULL )"},{"path":"/reference/area_length_filter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Area Length Thresholds — area_length_filter","text":"tmap Topologic Map gpkg geopackage areasqkm maximum upstream area subset pathlengthkm maximum upstream path length subset ms_pathlengthkm maximum upstream mainstem path length subset","code":""},{"path":"/reference/area_length_filter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Area Length Thresholds — area_length_filter","text":"data.frame","code":""},{"path":"/reference/as_sqlite.html","id":null,"dir":"Reference","previous_headings":"","what":"Read gpkg as SQLite — as_sqlite","title":"Read gpkg as SQLite — as_sqlite","text":"Read gpkg SQLite","code":""},{"path":"/reference/as_sqlite.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read gpkg as SQLite — as_sqlite","text":"","code":"as_sqlite(gpkg, lyr = NULL, ignore = \"gpkg_|rtree_|sqlite_\")"},{"path":"/reference/as_sqlite.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read gpkg as SQLite — as_sqlite","text":"gpkg path lyr layer GPKG. NULL (default database tables printed) ignore pattern layers ignored description","code":""},{"path":"/reference/as_sqlite.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read gpkg as SQLite — as_sqlite","text":"S4 object inherits DBIConnection. object used communicate database engine.","code":""},{"path":"/reference/create_style_row.html","id":null,"dir":"Reference","previous_headings":"","what":"Create style row — create_style_row","title":"Create style row — create_style_row","text":"Create style row","code":""},{"path":"/reference/create_style_row.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create style row — create_style_row","text":"","code":"create_style_row(gpkg_path, layer_name, style_name, style_qml)"},{"path":"/reference/create_style_row.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create style row — create_style_row","text":"gpkg_path GPKG path layer_name layer name style_name style name style_qml style QML","code":""},{"path":"/reference/create_style_row.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create style row — create_style_row","text":"data.frame","code":""},{"path":"/reference/cs_dm.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross Section Data Model — cs_dm","title":"Cross Section Data Model — cs_dm","text":"Cross Section Data Model","code":""},{"path":"/reference/cs_dm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross Section Data Model — cs_dm","text":"","code":"cs_dm"},{"path":"/reference/cs_dm.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Cross Section Data Model — cs_dm","text":"object class list length 3.","code":""},{"path":"/reference/get_fabric.html","id":null,"dir":"Reference","previous_headings":"","what":"Access Hydrofabric Network — get_fabric","title":"Access Hydrofabric Network — get_fabric","text":"Access Hydrofabric Network","code":""},{"path":"/reference/get_fabric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Access Hydrofabric Network — get_fabric","text":"","code":"get_fabric(   VPU,   base_s3 = \"s3://lynker-spatial/v20/\",   cache_dir = NULL,   cache_overwrite = FALSE )"},{"path":"/reference/get_fabric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access Hydrofabric Network — get_fabric","text":"VPU Vector Processing Unit base_s3 base hydrofabric directory access Lynker's s3 cache_dir data cached local directory? speed multiple subsets region cache_overwrite description. cached file overwritten","code":""},{"path":"/reference/get_fabric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Access Hydrofabric Network — get_fabric","text":"file path","code":""},{"path":"/reference/hf_dm.html","id":null,"dir":"Reference","previous_headings":"","what":"Hydrofabric Data Model — hf_dm","title":"Hydrofabric Data Model — hf_dm","text":"Hydrofabric Data Model Hydrofabric Data Model","code":""},{"path":"/reference/hf_dm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hydrofabric Data Model — hf_dm","text":"","code":"hf_dm  hf_dm"},{"path":"/reference/hf_dm.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Hydrofabric Data Model — hf_dm","text":"object class list length 2. object class list length 2.","code":""},{"path":"/reference/hydrofabric-package.html","id":null,"dir":"Reference","previous_headings":"","what":"hydrofabric: Easily Install and Load 'hydrofabric' tools — hydrofabric-package","title":"hydrofabric: Easily Install and Load 'hydrofabric' tools — hydrofabric-package","text":"'hydrofabric' meta package loads set packages work harmony complete hydroscience tasks.","code":""},{"path":[]},{"path":"/reference/hydrofabric-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"hydrofabric: Easily Install and Load 'hydrofabric' tools — hydrofabric-package","text":"Maintainer: Mike Johnson jjohnson@lynker.com contributors: NOAA [funder] USGS [funder] Lynker [funder]","code":""},{"path":"/reference/hydrofabric_conflicts.html","id":null,"dir":"Reference","previous_headings":"","what":"Conflicts between the hydrofabric and other packages — hydrofabric_conflicts","title":"Conflicts between the hydrofabric and other packages — hydrofabric_conflicts","text":"function lists conflicts packages hydrofabric packages loaded.","code":""},{"path":"/reference/hydrofabric_conflicts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conflicts between the hydrofabric and other packages — hydrofabric_conflicts","text":"","code":"hydrofabric_conflicts(only = NULL)"},{"path":"/reference/hydrofabric_conflicts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conflicts between the hydrofabric and other packages — hydrofabric_conflicts","text":"","code":"hydrofabric_conflicts() #> ── Conflicts ──────────────────────────────────────── hydrofabric_conflicts() ── #> ✖ terra::plot() masks climateR::plot()"},{"path":"/reference/hydrofabric_packages.html","id":null,"dir":"Reference","previous_headings":"","what":"List all packages in the hydrofabric — hydrofabric_packages","title":"List all packages in the hydrofabric — hydrofabric_packages","text":"List packages hydrofabric","code":""},{"path":"/reference/hydrofabric_packages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List all packages in the hydrofabric — hydrofabric_packages","text":"","code":"hydrofabric_packages(include_self = TRUE)"},{"path":"/reference/hydrofabric_packages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List all packages in the hydrofabric — hydrofabric_packages","text":"include_self Include hydrofabric list?","code":""},{"path":"/reference/hydrofabric_packages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List all packages in the hydrofabric — hydrofabric_packages","text":"","code":"hydrofabric_packages() #>  [1] \"arrow\"         \"climateR\"      \"DBI\"           \"dplyr\"         #>  [5] \"glue\"          \"grDevices\"     \"hydrofab\"      \"hfsubsetR\"     #>  [9] \"jsonlite\"      \"ngen.hydrofab\" \"nhdplusTools\"  \"RSQLite\"       #> [13] \"sf\"            \"terra\"         \"utils\"         \"zonal\"         #> [17] \"hydrofabric\""},{"path":"/reference/input_to_reference_feature.html","id":null,"dir":"Reference","previous_headings":"","what":"Find a Refernece Feature — input_to_reference_feature","title":"Find a Refernece Feature — input_to_reference_feature","text":"Find Refernece Feature","code":""},{"path":"/reference/input_to_reference_feature.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find a Refernece Feature — input_to_reference_feature","text":"","code":"input_to_reference_feature(net, id, comid, hl_id, poi_id, nldi_feature, xy)"},{"path":"/reference/input_to_reference_feature.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find a Refernece Feature — input_to_reference_feature","text":"id hydrofabric id (relevant nextgen fabrics) comid NHDPlusV2 COMID hl_id hydrolocation URI (relevant nextgen fabrics) poi_id POI identifier nldi_feature list names 'featureSource' 'featureID' 'featureSource' derived \"source\" column response dataRetrieval::get_nldi_sources() 'featureID' known identifier specified 'featureSource'. xy Location given vector XY CRS 4326 (longitude, latitude) network table network file default NULL","code":""},{"path":"/reference/is.url.html","id":null,"dir":"Reference","previous_headings":"","what":"Is URL — is.url","title":"Is URL — is.url","text":"Identifies character string URL searching  www, http, https","code":""},{"path":"/reference/is.url.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Is URL — is.url","text":"","code":"is.url(x)"},{"path":"/reference/is.url.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Is URL — is.url","text":"x character string","code":""},{"path":"/reference/is.url.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Is URL — is.url","text":"boolean","code":""},{"path":"/reference/read_qml.html","id":null,"dir":"Reference","previous_headings":"","what":"Read QML — read_qml","title":"Read QML — read_qml","text":"Reads QML file","code":""},{"path":"/reference/read_qml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read QML — read_qml","text":"","code":"read_qml(qml_file)"},{"path":"/reference/read_qml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read QML — read_qml","text":"qml_file character path","code":""},{"path":"/reference/read_qml.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read QML — read_qml","text":"QML contents","code":""},{"path":"/reference/read_sf_dataset_sqlite.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract spatial data from an SQLite connection — read_sf_dataset_sqlite","title":"Extract spatial data from an SQLite connection — read_sf_dataset_sqlite","text":"Extract spatial data SQLite connection","code":""},{"path":"/reference/read_sf_dataset_sqlite.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract spatial data from an SQLite connection — read_sf_dataset_sqlite","text":"","code":"read_sf_dataset_sqlite(tbl)"},{"path":"/reference/read_sf_dataset_sqlite.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract spatial data from an SQLite connection — read_sf_dataset_sqlite","text":"tbl remote temporary table","code":""},{"path":"/reference/read_sf_dataset_sqlite.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract spatial data from an SQLite connection — read_sf_dataset_sqlite","text":"sf object (data.frame non spatial)","code":""},{"path":"/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. arrow open_dataset, read_parquet, write_parquet glue glue","code":""},{"path":"/reference/subset_bbox.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset a Hydrofabric by Bounding Box — subset_bbox","title":"Subset a Hydrofabric by Bounding Box — subset_bbox","text":"Subset Hydrofabric Bounding Box","code":""},{"path":"/reference/subset_bbox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset a Hydrofabric by Bounding Box — subset_bbox","text":"","code":"subset_bbox(   gpkg,   bbox,   lyrs = c(\"divides\", \"nexus\", \"flowpaths\", \"network\", \"hydrolocations\",     \"reference_flowline\", \"reference_catchment\", \"refactored_flowpaths\",     \"refactored_divides\"),   outfile = NULL,   qml_dir = system.file(\"qml\", package = \"hydrofabric\") )"},{"path":"/reference/subset_bbox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset a Hydrofabric by Bounding Box — subset_bbox","text":"gpkg path gpkg subset bbox numeric vector length four, xmin, ymin, xmax ymax values lyrs layers extract. Default possible hydrofabric GPKG data model outfile file path write . Must \".gpkg\" extension","code":""},{"path":"/reference/subset_bbox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subset a Hydrofabric by Bounding Box — subset_bbox","text":"file path (outfile) list features","code":""},{"path":"/reference/subset_network.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset Hydrofabric Network — subset_network","title":"Subset Hydrofabric Network — subset_network","text":"Subset Hydrofabric Network","code":""},{"path":"/reference/subset_network.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset Hydrofabric Network — subset_network","text":"","code":"subset_network(   id = NULL,   comid = NULL,   hl_uri = NULL,   nldi_feature = NULL,   xy = NULL,   bbox = NULL,   base_s3 = \"s3://lynker-spatial/v20.1/\",   base_dir = NULL,   lyrs = c(\"divides\", \"nexus\", \"flowpaths\", \"network\", \"hydrolocations\",     \"flowpath_attributes\", \"reference_flowline\", \"reference_catchment\",     \"refactored_flowpaths\", \"refactored_divides\"),   areasqkm = NULL,   pathlengthkm = NULL,   ms_pathlengthkm = NULL,   outfile = NULL,   cache_dir = NULL,   qml_dir = system.file(\"qml\", package = \"hydrofabric\"),   cache_overwrite = FALSE )"},{"path":"/reference/subset_network.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset Hydrofabric Network — subset_network","text":"id hydrofabric id (relevant nextgen fabrics) comid NHDPlusV2 COMID nldi_feature list names 'featureSource' 'featureID' 'featureSource' derived \"source\" column response dataRetrieval::get_nldi_sources() 'featureID' known identifier specified 'featureSource'. xy Location given vector XY CRS 4326 (longitude, latitude) bbox numeric vector length four, xmin, ymin, xmax ymax values base_s3 base hydrofabric directory access Lynker's s3 base_dir base hydrofabric directory lyrs layers extract. Default possible hydrofabric GPKG data model areasqkm maximum upstream area subset pathlengthkm maximum upstream path length subset ms_pathlengthkm maximum upstream mainstem path length subset outfile file path write . Must \".gpkg\" extension cache_dir data cached local directory? speed multiple subsets region cache_overwrite description. cached file overwritten","code":""},{"path":"/reference/subset_network.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subset Hydrofabric Network — subset_network","text":"file path (outfile) list features","code":""},{"path":"/reference/subset_reference.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset Hydrofabric Network — subset_reference","title":"Subset Hydrofabric Network — subset_reference","text":"Subset Hydrofabric Network","code":""},{"path":"/reference/subset_reference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset Hydrofabric Network — subset_reference","text":"","code":"subset_reference(   nldi_feature,   gpkg = NULL,   pattern = \"/Volumes/Transcend/ngen/CONUS-hydrofabric/01_reference/reference_{vpu}.gpkg\",   export_gpkg = NULL )"},{"path":"/reference/subset_reference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset Hydrofabric Network — subset_reference","text":"pattern Pattern distributed VPU based GPKGS export_gpkg file path write id hydrofabric id comid NHDPlusV2 COMID hl_id Hydrolocation URI network Network Parquet file lyrs layers extract","code":""},{"path":"/reference/subset_reference.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subset Hydrofabric Network — subset_reference","text":"file path list","code":""}]
